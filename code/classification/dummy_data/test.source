The most commonly encountered models are based on per pixel techniques such as adaptive Gaussian Mixture Models #CITE# , or subspace analysis based methods #CITE# , and both approaches have been used with success in many applications . $SEP$ Detection of unusual objects amongst a highly textured background is a difficult problem , especially when the texture is manifest in the temporal dimension as well . Outdoor scenes involving waving trees or moving water are examples of such a scenario , but are nevertheless frequently encountered in real world vision applications . By defining a simple but rotationally sensitive Local Binary Pattern operator and applying it in a probabilistic sense we present a compact but useful feature for tackling moving textures . But as we demonstrate , this alone is not sufficient for good segmentation in difficult circumstances . Cooccurrence of different features in a pixel 's local neighbourhood provides a powerful mechanism for boosting the reliability of the foreground/background decision task . By using the conditional probabilities yielded by pairwise cooccurrence of 4-connected pixels , and casting the problem as one of Combinatorial Optimization , our results show that useful segmentation is possible from challenging dynamic backgrounds .
The recent work SDH #CITE# on supervised hashing also used idea of regularization method #CITE# . $SEP$ This paper addresses the problem of learning binary hash codes for large scale image search by proposing a novel hashing method based on deep neural network . The advantage of our deep model over previous deep model used in hashing is that our model contains necessary criteria for producing good codes such as similarity preserving , balance and independence . Another advantage of our method is that instead of relaxing the binary constraint of codes during the learning process as most previous works , in this paper , by introducing the auxiliary variable , we reformulate the optimization into two sub-optimization steps allowing us to efficiently solve binary constraints without any relaxation . The proposed method is also extended to the supervised hashing by leveraging the label information such that the learned binary codes preserve the pairwise label of inputs . The experimental results on three benchmark datasets show the proposed methods outperform state-of-the-art hashing methods .
Control of AMoD systems has been addressed in multiple lines of work , including queueing-theoretical approaches #CITE# , network flow approaches #CITE# , integer linear programming and model-predictive control approaches #CITE# , and simulation-based approaches #CITE# , #CITE# . $SEP$ We study the interaction between a fleet of electric self-driving vehicles servicing on-demand transportation requests and the electric power network . We propose a joint model that captures the coupling between the two systems stemming from the vehicles ' charging requirements , capturing time-varying customer demand , battery depreciation , and power transmission constraints . First , we show that the model is amenable to efficient optimization . Then , we prove that the socially optimal solution to the joint problem is a general equilibrium if locational marginal pricing is used for electricity . Finally , we show that the equilibrium can be computed by selfish transportation and generator operators without sharing private information . We assess the performance of the approach and its robustness to stochastic fluctuations in demand through case studies and agent-based simulations . Collectively , these results provide a first-of-a-kind characterization of the interaction between AMoD systems and the power network , and shed additional light on the economic and societal value of AMoD .
Bach & Moulines #CITE# presented averaged stochastic gradient methods for minimizing the expected squared loss and logistic loss without the strong convexity assumption that achieve an O convergence rate . Several works #CITE# also leverage the error bound conditions for achieving fast convergence of other regularized/constrained empirical loss minimization problems without strong convexity assumption . $SEP$ In this paper , we show that a gradient decent method with multiple restarting , named Restarted GD , can achieve a linear convergence rate for a class of non-smooth and non-strongly convex optimization problems where the epigraph of the objective function is a polyhedron . Its applications in machine learning include minimizing 1 constrained or regularized piecewise linear loss . To the best of our knowledge , this is the first result on the linear convergence rate of a stochastic gradient method for non-smooth and non-strongly convex optimization .
A wireless sensor network #CITE# has been attracting many researchers over the past ten years for a variety of its applications #CITE# . Such an issue to minimize the number of active sensor nodes while guaranteeing the required degree of coverage is called coverage problem #CITE# . $SEP$ A coverage problem is one of the important issues to prolong the lifetime of a wireless sensor network while guaranteeing that the target region is monitored by a sufficient number of active nodes . Most of existing protocols use geometric algorithm for each node to estimate the degree of coverage and determine whether to monitor around or sleep . These algorithms require accurate information about the location , sensing area , and sensing state of neighbor nodes . Therefore , they suffer from localization error leading to degradation of coverage and redundancy of active nodes . In addition , they introduce communication overhead leading to energy depletion . In this paper , we propose a novel coverage control mechanism , where each node relies on neither accurate location information nor communication with neighbor nodes . To enable autonomous decision on nodes , we adopt the nonlinear mathematical model of adaptive behavior of biological systems to dynamically changing environment . Through simulation , we show that the proposal outperforms the existing protocol in terms of the degree of coverage per node and the overhead under the influence of localization error .
Besides convex #CITE# and greedy #CITE# methods , sparse Bayesian learning #CITE# - #CITE# is an alternative method of sparse signal estimation , which aims at finding a sparse maximum a posteriori estimateα = argmax α p of the vector α by specifying a priori probability density function p . Instead of working directly with a prior p , SBL typically employs a two-layer hierarchical structure #CITE# that assumes a conditional prior pdf p and a hyperpriori pdf p , so that p = γ ppdγ has a sparsity-inducing nature . Most recently , SBL has been efficiently implemented using belief propagation #CITE# , #CITE# and approximate message passing #CITE# , #CITE# . $SEP$ Abstract-This paper concerns message passing based approaches to sparse Bayesian learning with a linear model corrupted by additive white Gaussian noise with unknown variance . With the conventional factor graph , mean field message passing based algorithms have been proposed in the literature . In this work , instead of using the conventional factor graph , we modify the factor graph by adding some extra hard constraints , which enables the use of combined belief propagation and MF message passing . We then propose a low complexity BP-MF SBL algorithm based on which an approximate BP-MF SBL algorithm is also developed to further reduce the complexity . Thanks to the use of BP , the BP-MF SBL algorithms show their merits compared with state-of-the-art MF SBL algorithms : they deliver even better performance with much lower complexity compared with the vector-form MF SBL algorithm and they significantly outperform the scalar-form MF SBL algorithm with similar complexity . Index Terms-sparse Bayesian learning , message passing , BP-MF .
Examples of feedback controllers include robust control #CITE# , adaptive control #CITE# , #CITE# , optimal control #CITE# , sliding mode control #CITE# , etc . Then , disturbance estimation and attenuation methods through adding a feedforward compensation term #CITE# , #CITE# have been proposed and practiced , such as DOB #CITE# and Extended State Observer #CITE# . $SEP$ Abstract-This paper presents an observer-integrated Reinforcement Learning approach , called Disturbance OBserver Network , for robots operating in environments where disturbances are unknown and time-varying , and may frequently exceed robot control capabilities . The DOBNet integrates a disturbance dynamics observer network and a controller network . Originated from classical DOB mechanisms , the observer is built and enhanced via Recurrent Neural Networks , encoding estimation of past values and prediction of future values of unknown disturbances in RNN hidden state . Such encoding allows the controller generate optimal control signals to actively reject disturbances , under the constraints of robot control capabilities . The observer and the controller are jointly learned within policy optimization by advantage actor critic . Numerical simulations on position regulation tasks have demonstrated that the proposed DOBNet significantly outperforms a canonical feedback controller and classical RL algorithms .
In Role Based Access Control #CITE# , users acquire permissions through their roles rather than that they are assigned permissions directly . In research work #CITE# , roles are assigned to service consumers for service authorization . $SEP$ Web services can be composed of other services in a highly dynamic manner . The existing role based authorization approaches have not adequately taken component services into account when managing access control for composite services . In this paper , we propose a service oriented conceptual model as an extension of role based access control that can facilitate the administration and management of access for service consumers as well as component services in composite web services . Various types of conflict of interest are identified due to the complicated relationships among service consumers and component services . A set of authorization rules are developed to prevent the conflict of interest . This research is a step forward to addressing the challenge in authorization in the context of composite web services .
Based on their work , several applications have appeared that use semantic relations #CITE# , #CITE# , #CITE# , #CITE# , #CITE# . $SEP$ Abstract-The availability of large volumes of Semantic Web data has created the potential of discovering vast amounts of knowledge . Semantic relation discovery is a fundamental technology in analytical domains , such as business intelligence and homeland security . Because of the decentralized and distributed nature of Semantic Web development , semantic data tend to be created and stored independently in different organizations . Under such circumstances , discovering semantic relations faces numerous challenges , such as isolation , scalability , and heterogeneity . This paper proposes an effective strategy to discover semantic relationships over large-scale distributed networks based on a novel hierarchical knowledge abstraction and an efficient discovery protocol . The approach will effectively facilitate the realization of the full potential of harnessing the collective power and utilization of the knowledge scattered over the Internet .
It is shown in that under certain conditions , optimizing the above loss function can lead to a generator that exactly recovers the real data distribution . $SEP$ Generative adversarial networks have shown great promise in generating complex data such as images . A standard practice in GANs is to discard the discriminator after training and use only the generator for sampling . However , this loses valuable information of real data distribution learned by the discriminator . In this work , we propose a collaborative sampling scheme between the generator and discriminator for improved data generation . Guided by the discriminator , our approach refines generated samples through gradient-based optimization , shifting the generator distribution closer to the real data distribution . Additionally , we present a practical discriminator shaping method that can further improve the sample refinement process . Orthogonal to existing GAN variants , our proposed method offers a new degree of freedom in GAN sampling . We demonstrate its efficacy through experiments on synthetic data and image generation tasks .
This type of systems has been widely used in multiple applications , such as robotics #CITE# , economics #CITE# , networked control #CITE# , and epidemiology #CITE# . $SEP$ In this paper , we study state-feedback control of Markov jump linear systems with partial information . In particular , we assume that the controller can only access the mode signals according to a hidden-Markov observation process . Our formulation generalizes various relevant cases previously studied in the literature on Markov jump linear systems , such as the cases with perfect information , no information , and cluster observations of the mode signals . In this context , we propose a Linear Matrix Inequalities formulation to design feedback control laws for stabilization , H 2 , and H∞ control of discrete-time Markov jump linear systems under hidden-Markovian observations of the mode signals . We conclude by illustrating our results with some numerical examples .
As shown by Schuon et al #CITE# , the quality of range images can be improved significantly by super-resolution . $SEP$ Abstract . In the field of image-guided surgery , Time-of-Flight sensors are of interest due to their fast acquisition of 3-D surfaces . However , the poor signal-to-noise ratio and low spatial resolution of today 's ToF sensors require preprocessing of the acquired range data . Superresolution is a technique for image restoration and resolution enhancement by utilizing information from successive raw frames of an image sequence . We propose a super-resolution framework using the graphics processing unit . Our framework enables interactive frame rates , computing an upsampled image from 10 noisy frames of 200×200 px with an upsampling factor of 2 in 109 ms . The root-mean-square error of the super-resolved surface with respect to ground truth data is improved by more than 20 % relative to a single raw frame .
A recent line of work #CITE# , #CITE# developed a simpler algorithm that only involves calculating and thresholding the pairwise cosine distances of data points , and established guarantees similar to SSC #CITE# under the semi-random model using a much simpler algorithm that only involves calculating and thresholding the pairwise cosine distances of data points . $SEP$ Abstract-An important problem in analyzing big data is subspace clustering , ie , to represent a collection of points in a high-dimensional space via the union of low-dimensional subspaces . Sparse subspace clustering and Low-rank representation are the state-of-the-art methods for this task . These two methods are fundamentally similar in that both are based on convex optimization exploiting the intuition of `` Self-Expressiveness '' . The main difference is that the SSC minimizes the vector 1 norm of the representation matrix to induce sparsity while LRR minimizes the nuclear norm to promote a low-rank structure . Because the representation matrix is often simultaneously sparse and lowrank , we propose a new algorithm , termed Low-rank sparse subspace clustering , by the combining SSC and LRR , and develop theoretical guarantees of the success of the algorithm . The results reveal interesting insights into the strengths and the weaknesses of SSC and LRR , and demonstrate how the LRSSC can take advantage of both methods in preserving the `` Self-Expressiveness Property '' and `` Graph Connectivity '' at the same time . A byproduct of our analysis is that it also expands the theoretical guarantee of SSC to handle cases when the subspaces have arbitrarily small canonical angles but are `` nearly independent '' .
Moreover , given the multiplexing and/or diversity gains provided by multiple-input multiple-output techniques , various relaying strategies have been proposed for MIMO relaying systems #CITE# . Most of the existing literature of MIMO AF relaying systems concentrates on the optimization of traditional performance metrics , such as the achievable capacity and the minimum mean square errors of signal detection #CITE# . Traditionally , it is defined as the ratio of the achievable capacity to the total power consumption of signal transmission and circuit hardware dissipation #CITE# . There exist some works in the literature that investigate the EE optimization for MIMO AF relaying systems #CITE# . $SEP$ Abstract-We investigate the energy efficiency of multiple-input-multiple-output amplify-and-forward relaying networks relying on the realistic imperfect channel state information . Specifically , the relay jointly optimizes the source covariance and relay beamforming matrices by maximizing the EE under additive or multiplicative relay-destination CSI errors . The optimal channel-diagonalizing structure is derived for the source covariance and relay beamforming matrices under the spectral-norm constrained additive or multiplicative CSI error . Then , the existence of a saddle point is proved , which shows that the channel-diagonalizing transmission strategy is optimal in the robust EE maximization under these two types of CSI errors , and the original matrix-valued fractional robust EE problem is transformed into a scalar fractional problem . We propose the Dinkelbach method-based alternating optimization scheme for this transformed robust EE problem , which is capable of finding a locally optimal solution of the original robust EE problem efficiently , and show that the semi-closedform solution to each of the two associated subproblems can be obtained . We then prove that the channel-diagonalizing transmission strategy remains optimal when the statistically imperfect source-relay channel is additionally imposed . We also extend our work into multi-hop MIMO relaying scenarios and prove that the channel-diagonalizing structure is optimal for the source covariance matrix and the multiple relay beamforming matrices . Index Terms-Robust energy efficiency optimization , additive and multiplicative CSI errors , channel-diagonalization .
That is why results from one dataset cannot easily be transferred to another , as shown by Torralba and Efros #CITE# . A number of domain adaptation techniques have been proposed in the literature #CITE# that allow for adapting a source classifier to a target domain . $SEP$ Abstract . The goal of domain adaptation is to adapt models learned on a source domain to a particular target domain . Most methods for unsupervised domain adaptation proposed in the literature to date , assume that the set of classes present in the target domain is identical to the set of classes present in the source domain . This is a restrictive assumption that limits the practical applicability of unsupervised domain adaptation techniques in real world settings . Therefore , we relax this constraint and propose a technique that allows the set of target classes to be a subset of the source classes . This way , large publicly available annotated datasets with a wide variety of classes can be used as source , even if the actual set of classes in target can be more limited and , maybe most importantly , unknown beforehand . To this end , we propose an algorithm that orders a set of source subspaces that are relevant to the target classification problem . Our method then chooses a restricted set from this ordered set of source subspaces . As an extension , even starting from multiple source datasets with varied sets of categories , this method automatically selects an appropriate subset of source categories relevant to a target dataset . Empirical analysis on a number of source and target domain datasets shows that restricting the source subspace to only a subset of categories does indeed substantially improve the eventual target classification accuracy over the baseline that considers all source classes .
Most of the approaches , such as throughputbased #CITE# , buffer-based #CITE# and mixed schemes #CITE# employ fixed control rules which determine future video bitrates via carefully tuned strategies and thresholds . $SEP$ Existing reinforcement learning -based adaptive bitrate approaches outperform the previous fixed control rules based methods by improving the Quality of Experience score , as the QoE metric can hardly provide clear guidance for optimization , finally resulting in the unexpected strategies . In this paper , we propose Tiyuntsong , a selfplay reinforcement learning approach with generative adversarial network -based method for ABR video streaming . Tiyuntsong learns strategies automatically by training two agents who are competing against each other . Note that the competition results are determined by a set of rules rather than a numerical QoE score that allows clearer optimization objectives . Meanwhile , we propose GAN Enhancement Module to extract hidden features from the past status for preserving the information without the limitations of sequence lengths . Using testbed experiments , we show that the utilization of GAN significantly improves the Tiyuntsong 's performance . By comparing the performance of ABRs , we observe that Tiyuntsong also betters existing ABR algorithms in the underlying metrics .
There are research compilers which parallelize applications using speculation #CITE# . $SEP$ Automatic parallelization for clusters is a promising alternative to time-consuming , error-prone manual parallelization . However , automatic parallelization is frequently limited by the imprecision of static analysis . Moreover , due to the inherent fragility of static analysis , small changes to the source code can signif cantly undermine performance . By replacing static analysis with speculation and prof ling , automatic parallelization becomes more robust and applicable . A naïve automatic speculative parallelization does not scale for distributed memory clusters , due to the high bandwidth required to validate speculation . This work is the f rst automatic speculative DOALL parallelization system for clusters . We have implemented a prototype automatic parallelization system , called Cluster Spec-DOALL , which consists of a Spec-DOALL parallelizing compiler and a speculative runtime for clusters . Since the compiler optimizes communication patterns , and the runtime is optimized for the cases in which speculation succeeds , Cluster Spec-DOALL minimizes the communication and validation overheads of the speculative runtime . Across 8 benchmarks , Cluster Spec-DOALL achieves a geomean speedup of 43 .8× on a 120-core cluster , whereas DOALL without speculation achieves only 4 .5× speedup . This demonstrates that speculation makes scalable fully-automatic parallelization for clusters possible .
Sensing in water utility networks: Recent research #CITE# , #CITE# have focused on designing a sensing network for water distribution networks at utility scale . There are also research works that identify strategic locations to place sensors in water networks #CITE# , #CITE# , #CITE# . $SEP$ Addressing nonrevenue water , a major issue for water utilities , requires identification of strategic metering locations using calibrated hydraulic models of the water network . However , calibrated hydraulic models use both static and dynamic network data and are often prohibitively expensive . We present an approach to understand water network operations that uses only the static information of the network . Specifically , we analyze water networks using augmented centrality measures . We use readily available static information about network elements rather than calibrated dynamic information , and model each network element appropriately for analysis using customized centrality measures . Our approach identifies : 1 ) pipes carrying higher flows ; 2 ) nodes with higher delivery heads ; and 3 ) pipes with higher failure impact . Each of the above helps in determining strategic instrumentation locations . We validate our analysis by comparison with fully calibrated hydraulic models for three benchmark topologies . Our experimental evaluation shows that centrality analysis yields results which have a match of more than 85 % with those obtained using calibrated hydraulic models on benchmark networks without significant over-provisioning . We also present results from a real-life case study where our approach matched 78 % with locations picked by experts . INDEX TERMS Water networks , centrality metrics , complex network analysis .
Recently , deep learning based methods #CITE# have emerged as a promising alternative avenue by treating the problem as learning an end-to-end mapping from masked input to completed output . These learning-based methods are able to hallucinate novel contents by training on large scale datasets #CITE# . To produce visually realistic results , generative adversarial networks #CITE# are employed to train the inpainting networks . $SEP$ Existing image inpainting methods typically fill holes by borrowing information from surrounding pixels . They often produce unsatisfactory results when the holes overlap with or touch foreground objects due to lack of information about the actual extent of foreground and background regions within the holes . These scenarios , however , are very important in practice , especially for applications such as the removal of distracting objects . To address the problem , we propose a foreground-aware image inpainting system that explicitly disentangles structure inference and content completion . Specifically , our model learns to predict the foreground contour first , and then inpaints the missing region using the predicted contour as guidance . We show that by such disentanglement , the contour completion model predicts reasonable contours of objects , and further substantially improves the performance of image inpainting . Experiments show that our method significantly outperforms existing methods and achieves superior inpainting results on challenging cases with complex compositions .
A number of methods have recently been proposed for action recognition by extracting sparse features #CITE# , correlated features #CITE# , discovering hidden topic models #CITE# , or feature mining #CITE# . Several works address the recognition of planned group activities in football videos by modelling the trajectories of people with Bayesian networks #CITE# , temporal manifold structures #CITE# , and non-stationary kernel hidden Markov models #CITE# . $SEP$ Abstract . We present a coherent , discriminative framework for simultaneously tracking multiple people and estimating their collective activities . Instead of treating the two problems separately , our model is grounded in the intuition that a strong correlation exists between a person 's motion , their activity , and the motion and activities of other nearby people . Instead of directly linking the solutions to these two problems , we introduce a hierarchy of activity types that creates a natural progression that leads from a specific person 's motion to the activity of the group as a whole . Our model is capable of jointly tracking multiple people , recognizing individual activities , the interactions between pairs of people , and finally the behavior of groups of people . We also propose an algorithm for solving this otherwise intractable joint inference problem by combining belief propagation with a version of the branch and bound algorithm equipped with integer programming . Experimental results on challenging video datasets demonstrate our theoretical claims and indicate that our model achieves the best collective activity classification results to date .
Vertex coloring is one of the most studied tasks in distributed network computing in general , and in self-stabilization in particular , as witnessed by numerous contributions: #CITE# . While most previous work about self-stabilizing vertex coloring considered the state model , a few paper considered the message passing model #CITE# . $SEP$ Self-stabilizing protocols enable distributed systems to recover correct behavior starting from any arbitrary configuration . In particular , when processors communicate by message passing , fake messages may be placed in communication links by an adversary . When the number of such fake messages is unknown , self-stabilization may require huge resources : generic solutions require unbounded resources , which makes them unrealistic to deploy , specific solutions require Opn log nq or Op∆ log nq bits of memory per node , where n denotes the network size and ∆ its maximum degree , which may prevent scalability . We investigate the possibility of resource efficient self-stabilizing protocols in this context . Specifically , we present a self-stabilizing protocol for p∆ ` 1q-coloring in any n-node graph , under the asynchronous message-passing model . The problem of p∆ ` 1q-coloring is considered a benchmarking problem for local tasks . Our protocol offers many desirable features . It is deterministic , it converges in Opk∆n 2 log nq message exchanges , where k is the bound of the link capacity in terms of number of messages , and it uses messages on Oplog log n ` log ∆q bits with a memory of Op∆ log ∆ ` log log nq bits at each node . The resource consumption of our protocol is thus almost oblivious to the number of nodes , enabling scalability . Moreover , a striking property of our protocol is that the nodes do not need to know the number , or any bound on the number of messages initially present in each communication link of the initial network configuration . This permits our protocol to handle any future network with unknown message capacity communication links . A key building block of our coloring scheme is a spanning directed acyclic graph construction , that is of independent interest , and can serve as a useful tool for solving other tasks in this challenging setting .
Previously , clonal sequence data were used to construct a multi-variant HCV dynamic model that explained the dynamics of specific telaprevir-resistant variants before and after telaprevir treatment #CITE# . This model was originally developed by fitting viral kinetics from patients treated with telaprevir monotherapy , with clonal sequence data used to quantify the relative fitness of specific telaprevir-resistant mutants #CITE# . The model was then refined in order to predict SVR rates by estimating relative fitness rates of different resistant variants using viral kinetics from Phase 2 telaprevir studies , but in this refinement no additional sequence data beyond the Phase 1 clonal sequence data were used to estimate model parameters #CITE# . First , these prior models #CITE# used clonal sequence data from a Phase 1 study with small numbers of patients . Second , these prior models #CITE# included substantially more mechanistic detail and greater numbers of free parameters than the approach presented here . $SEP$ For patients infected with hepatitis C virus , the combination of the direct-acting antiviral agent telaprevir , pegylatedinterferon alfa , and ribavirin significantly increases the chances of sustained virologic response over treatment with Peg-IFN and RBV alone . If patients do not achieve SVR with telaprevir-based treatment , their viral population is often significantly enriched with telaprevir-resistant variants at the end of treatment . We sought to quantify the evolutionary dynamics of these post-treatment resistant variant populations . Previous estimates of these dynamics were limited by analyzing only population sequence data from 388 patients enrolled in Phase 3 clinical studies . Here we add clonal sequence analysis for a subset of these patients . We developed a computational model which integrates both the qualitative and quantitative sequence data , and which forms a framework for future analyses of drug resistance . The model was qualified by showing that deep-sequence data from a subset of these patients are consistent with model predictions . When determining the median time for viral populations to revert to 20 % resistance in these patients , the model predicts 8 .3 months versus 10 .7 months estimated using solely population sequence data for genotype 1a , and 1 .0 months versus 0 .9 months for genotype 1b . For each individual patient , the time to revert to 20 % resistance predicted by the model was typically comparable to or faster than that estimated using solely population sequence data . Furthermore , the model predicts a median of 11 .0 and 2 .1 months after treatment failure for viral populations to revert to 99 % wild-type in patients with HCV genotypes 1a or 1b , respectively . Our modeling approach provides a framework for projecting accurate , quantitative assessment of HCV resistance dynamics from a data set consisting of largely qualitative information .
Step Search #CITE# , the Simple and Efficient TSS #CITE# , the Four Step Search #CITE# and the Diamond Search #CITE# are some of its well-known examples . This category includes: the Adaptive Rood Pattern Search #CITE# , the Fast Block Matching Using Prediction #CITE# , the Block-based Gradient Descent Search #CITE# and the Neighborhood Elimination algorithm #CITE# . $SEP$ Motion estimation is one of the major problems in developing video coding applications . Among all motion estimation approaches , Block-matching algorithms are the most popular methods due to their effectiveness and simplicity for both software and hardware implementations . A BM approach assumes that the movement of pixels within a defined region of the current frame can be modeled as a translation of pixels contained in the previous frame . In this procedure , the motion vector is obtained by minimizing a certain matching metric that is produced for the current frame over a determined search window from the previous frame . Unfortunately , the evaluation of such matching measurement is computationally expensive and represents the most consuming operation in the BM process . Therefore , BM motion estimation can be viewed as an optimization problem whose goal is to find the best-matching block within a search space . The simplest available BM method is the Full Search Algorithm which finds the most accurate motion vector through an exhaustive computation of all the elements of the search space . Recently , several fast BM algorithms have been proposed to reduce the search positions by calculating only a fixed subset of motion vectors despite lowering its accuracy . On the other hand , the Harmony Search algorithm is a population-based optimization method that is inspired by the music improvisation process in which a musician searches for harmony and continues to polish the pitches to obtain a better harmony . In this paper , a new BM algorithm that combines HS with a fitness approximation model is proposed . The approach E . Cuevas uses motion vectors belonging to the search window as potential solutions . A fitness function evaluates the matching quality of each motion vector candidate . In order to save computational time , the approach incorporates a fitness calculation strategy to decide which motion vectors can be only estimated or actually evaluated . Guided by the values of such fitness calculation strategy , the set of motion vectors is evolved through HS operators until the best possible motion vector is identified . The proposed method has been compared to other BM algorithms in terms of velocity and coding quality . Experimental results demonstrate that the proposed algorithm exhibits the best balance between coding efficiency and computational complexity .
The problem of designing efficient contention management in the context of transactional memory #CITE# has received significant research attention , especially since such systems are already present in hardware by major vendors #CITE# . Several applied papers , eg #CITE# discuss the trade-offs involved in implementing transactional protocols in hardware , and the performance pathologies of such systems . As noted , the contention management problem has been abstracted by #CITE# in the context of software TM , and there is a considerable amount of work on this topic , eg #CITE# . $SEP$ The transactional conflict problem arises in transactional systems whenever two or more concurrent transactions clash on a data item . While the standard solution to such conflicts is to immediately abort one of the transactions , some practical systems consider the alternative of delaying conflict resolution for a short interval , which may allow one of the transactions to commit . The challenge in the transactional conflict problem is to choose the optimal length of this delay interval so as to minimize the overall running time penalty for the conflicting transactions . In this paper , we propose a family of optimal online algorithms for the transactional conflict problem . Specifically , we consider variants of this problem which arise in different implementations of transactional systems , namely `` requestor wins '' and `` requestor aborts '' implementations : in the former , the recipient of a coherence request is aborted , whereas in the latter , it is the requestor which has to abort . Both strategies are implemented by real systems . We show that the requestor aborts case can be reduced to a classic instance of the ski rental problem , while the requestor wins case leads to a new version of this classical problem , for which we derive optimal deterministic and randomized algorithms . Moreover , we prove that , under a simplified adversarial model , our algorithms are constantcompetitive with the offline optimum in terms of throughput . We validate our algorithmic results empirically through a hardware simulation of hardware transactional memory , showing that our algorithms can lead to non-trivial performance improvements for classic concurrent data structures .
Regarding domain adaptation , in representation learning , Blitzer et al propose structural correspondence learning while Huang and Yates attempt to learn a multi-dimensional feature representation . Daumé III proposes an easy adaptation framework which is later extended to a semisupervised version to incorporate unla-beled data . $SEP$ Relation extraction suffers from a performance loss when a model is applied to out-of-domain data . This has fostered the development of domain adaptation techniques for relation extraction . This paper evaluates word embeddings and clustering on adapting feature-based relation extraction systems . We systematically explore various ways to apply word embeddings and show the best adaptation improvement by combining word cluster and word embedding information . Finally , we demonstrate the effectiveness of regularization for the adaptability of relation extractors .
addressed in #CITE# , where the influence of the troposphere has been neglected , being a reasonable assumption due to the small angular range of the considered azimuth bandwidths . $SEP$ Abstract-This paper addresses the performance in the retrieval of 3-D mean deformation maps by exploiting simultaneous or quasi-simultaneous squinted synthetic aperture radar interferometric acquisitions in a repeat-pass scenario . In multisatellite or multibeam low earth observation missions , the availability of two lines of sight allows the simultaneous acquisition of SAR images with different squint angles , hence improving the sensitivity to the northsouth component of the deformation . Due to the simultaneity of the acquisitions , the troposphere will be highly correlated and , therefore , will tend to cancel out when performing the differential measurement between the interferograms obtained with the different LOSs , hence resulting in a practically tropospherefree estimation of the along-track deformation measurement . In practice , however , the atmospheric noise in the differential measurement will increase for increasing angular separations . This paper expounds the mathematical framework to derive the performance by properly considering the correlation of the atmospheric delays between the simultaneous acquisitions . To that aim , the hybrid Cramér-Rao bound is exploited making use of the autocorrelation function of the troposphere . Some performance examples are presented in the frame of future spaceborne SAR missions at C and L band . Index Terms-Atmospheric boundary layer , differential synthetic aperture radar interferometry , hybrid Cramér-Rao bound , squinted synthetic aperture radar acquisitions , synthetic aperture radar , troposphere .
Following this seminal work , a large number of supervised machine learning methods have been developed to infer approximate 3D structures or depth maps from the image using carefully designed models or grammars . $SEP$ Abstract The capacity of automatically modeling photographic composition is valuable for many real-world machine vision applications such as digital photography , image retrieval , image understanding , and image aesthetics assessment . The triangle technique is among those indispensable composition methods on which professional photographers often rely . This paper proposes a system that can identify prominent triangle arrangements in two major categories of photographs : natural or urban scenes , and portraits . For the natural or urban scene pictures , the focus is on the effect of linear perspective . For portraits , we carefully examine the positioning of human subjects in a photo . We show that line analysis is highly advantageous for modeling composition in both categories . Based on the detected triangles , new mathematical descriptors for composition are formulated and used to retrieve similar images . Leveraging the rich source of high aesthetics photos online , similar approaches can potentially be incorporated in future smart cameras to enhance a person 's photo composition skills .
The key idea is to train a deep neural network to estimate the ideal binary mask #CITE# or the ideal ratio mask #CITE# , #CITE# for enhancement . It has been suggested that the resulting separated speech exhibits remarkable speech intelligibility and quality improvements over conventional methods #CITE# , #CITE# . $SEP$ This study proposes a novel all-neural approach for multichannel speech enhancement , where robust speaker localization , acoustic beamforming , post-filtering and spatial filtering are all done using deep learning based time-frequency masking . Our system first performs monaural speech enhancement on each microphone signal to obtain the estimated ideal ratio masks for beamforming and robust time delay of arrival estimation . Then with the estimated TDOA , directional features indicating whether each T-F unit is dominated by the signal coming from the estimated target direction are computed . Next , the directional features are combined with the spectral features extracted from the beamformed signal to achieve further enhancement . Experiments on a twomicrophone setup in reverberant environments with strong diffuse babble noise demonstrate the effectiveness of the proposed approach for multi-channel speech enhancement .
Distributional semantic models , that induce vector-based meaning representations from patterns of co-occurrence of words in corpora , have proven very successful at modeling many lexical relations , such as synonymy , co-hyponomy and analogy . The recent evaluation of Baroni et al suggests that the C-BOW model introduced by Mikolov et al is , consistently , the best across many tasks . 1 Interestingly , C-BOW vectors are estimated with a simple compositional approach: The weights of adjacent words are jointly optimized so that their sum will predict the distribution of their contexts . This is reminiscent of how the parameters of some compositional distributional seman- 1 We refer here not only to the results reported in Baroni et al , but also to the more extensive evaluation that Baroni and colleagues present in the companion website . The experiments there suggest that only the Glove vectors of Pennington et al are competitive with C-BOW , and only when trained on a corpus several orders of magnitude larger than the one used for C-BOW . tic models are estimated by optimizing the prediction of the contexts in which phrases occur in corpora . $SEP$ We introduce C-PHRASE , a distributional semantic model that learns word representations by optimizing context prediction for phrases at all levels in a syntactic tree , from single words to full sentences . C-PHRASE outperforms the state-of-theart C-BOW model on a variety of lexical tasks . Moreover , since C-PHRASE word vectors are induced through a compositional learning objective , when they are summed , they produce sentence representations that rival those generated by ad-hoc compositional models .
In addition , all of the work in #CITE# - #CITE# and #CITE# - #CITE# assume that the link metrics are symmetric , ie , the metrics of the links in two directions are the same . $SEP$ Abstract-In this paper , we propose the Programmable LInk Metric Identification infrastructure for softwaredefined networking networks . ProgLIMI identifies round-trip link metrics from accumulated end-to-end metrics of selected measurement paths by leveraging the flexible routing control capability of SDN networks . ProgLIMI mainly solves three sub-problems : 1 ) monitor placement ; 2 ) linearly independent measurement path construction ; and 3 ) flow rule design . To reduce measurement cost , ProgLIMI tries to minimize the number of required monitors and flow rules . In this paper , we address the three sub-problems for both full and hybrid SDN networks . For full SDN networks , ProgLIMI can achieve full RTLM identification using only one monitor and two flow rules in each SDN switch . In contrast , the RTLM identification in hybrid SDN networks is more complicated due to the routing constraint of hybrid SDN networks . We first prove that the monitor placement problem in hybrid SDN networks is NP-hard . We then formulate the monitor placement and measurement path selection problem in hybrid SDN networks and propose a greedy heuristic algorithm to solve the problem efficiently . Our evaluations on both physical testbed and simulation platform reveal that ProgLIMI can accurately identify the RTLMs . Besides , ProgLIMI is also resource efficient , ie , it only requires two flow rules in each SDN switch and a small number of monitors , and the extra probing traffic load incurred by ProgLIMI is also low . Index Terms-Software-defined networking , link metric identification , round-trip link metric , monitor , measurement path .