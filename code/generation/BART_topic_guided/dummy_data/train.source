2	On the contrary , especially in the field of automated machine learning , combined algorithms selection and hyperparameter optimization problems are considered , where the number of potential candidates is po- * Contact Author tentially infinite #CITE# . $SEP$ Algorithm selection deals with selecting an algorithm from a fixed set of candidate algorithms most suitable for a specific instance of an algorithmic problem , eg , choosing solvers for SAT problems . Benchmark suites for AS usually comprise candidate sets consisting of at most tens of algorithms , whereas in combined algorithm selection and hyperparameter optimization problems the number of candidates becomes intractable , impeding to learn effective meta-models and thus requiring costly online performance evaluations . Therefore , here we propose the setting of extreme algorithm selection where we consider fixed sets of thousands of candidate algorithms , facilitating meta learning . We assess the applicability of state-of-the-art AS techniques to the XAS setting and propose approaches leveraging a dyadic feature representation in which both problem instances and algorithms are described . We find the latter to improve significantly over the current state of the art in various metrics . $SEP$ Many different machine learning algorithms exist ; taking into account each algorithm 's hyperparameters , there is a staggeringly large number of possible alternatives overall . We consider the problem of simultaneously selecting a learning algorithm and setting its hyperparameters , going beyond previous work that attacks these issues separately . We show that this problem can be addressed by a fully automated approach , leveraging recent innovations in Bayesian optimization . Specifically , we consider a wide range of feature selection techniques and all classification approaches implemented in WEKA 's standard distribution , spanning 2 ensemble methods , 10 meta-methods , 27 base classifiers , and hyperparameter settings for each classifier . On each of 21 popular datasets from the UCI repository , the KDD Cup 09 $SEPB$ Many different machine learning algorithms exist ; taking into account each algorithm 's hyperparameters , there is a staggeringly large number of possible alternatives overall . We consider the problem of simultaneously selecting a learning algorithm and setting its hyperparameters , going beyond previous work that attacks these issues separately . We show that this problem can be addressed by a fully automated approach , leveraging recent innovations in Bayesian optimization . Specifically , we consider a wide range of feature selection techniques and all classification approaches implemented in WEKA 's standard distribution , spanning 2 ensemble methods , 10 meta-methods , 27 base classifiers , and hyperparameter settings for each classifier . On each of 21 popular datasets from the UCI repository , the KDD Cup 09
2	To learn an effective filter bank at each convolution stage , a variety of methods have been proposed , such as the restricted Boltzmann machines #CITE# , #CITE# , regularized autoencoders and their variations #CITE# . $SEP$ In this paper , we propose a compact network called compact unsupervised network to address the image classification challenge . Contrasting the usual learning approach of convolutional neural networks , learning is achieved by the simple K-means on diverse image patches . This approach performs well even with scarcely labeled training images , greatly reducing the computational cost , while maintaining high discriminative power . Furthermore , we propose a new weighted pooling method in which different weighting values of adjacent neurons are considered . This strategy leads to improved classification since the network becomes more robust against small image distortions . In the output layer , CUNet integrates feature maps obtained in the last hidden layer , and straightforwardly computes histograms in nonoverlapped blocks . To reduce feature redundancy , we also implement the max-pooling operation on adjacent blocks to select the most competitive features . Comprehensive experiments on wellestablished databases are conducted to validate the classification performances of the introduced CUNet approach . $SEP$ The success of machine learning algorithms generally depends on data representation , and we hypothesize that this is because different representations can entangle and hide more or less the different explanatory factors of variation behind the data . Although specific domain knowledge can be used to help design representations , learning with generic priors can also be used , and the quest for AI is motivating the design of more powerful representation-learning algorithms implementing such priors . This paper reviews recent work in the area of unsupervised feature learning and deep learning , covering advances in probabilistic models , autoencoders , manifold learning , and deep networks . This motivates longer term unanswered questions about the appropriate objectives for learning good representations , for computing representations , and $SEPB$ The success of machine learning algorithms generally depends on data representation , and we hypothesize that this is because different representations can entangle and hide more or less the different explanatory factors of variation behind the data . Although specific domain knowledge can be used to help design representations , learning with generic priors can also be used , and the quest for AI is motivating the design of more powerful representation-learning algorithms implementing such priors . This paper reviews recent work in the area of unsupervised feature learning and deep learning , covering advances in probabilistic models , autoencoders , manifold learning , and deep networks . This motivates longer term unanswered questions about the appropriate objectives for learning good representations , for computing representations , and
2	We could use Convolutional Neural Networks , which are frequently used with high accuracy and quality in the field of computer vision #CITE# , for cloth simulation . $SEP$ Cloth simulation requires a fast and stable method for interactively and realistically visualizing fabric materials using computer graphics . We propose an efficient cloth simulation method using miniature cloth simulation and upscaling Deep Neural Networks . The upscaling DNNs generate the target cloth simulation from the results of physically-based simulations of a miniature cloth that has similar physical properties to those of the target cloth . We have verified the utility of the proposed method through experiments , and the results demonstrate that it is possible to generate fast and stable cloth simulations under various conditions . $SEP$ Despite the breakthroughs in accuracy and speed of single image super-resolution using faster and deeper convolutional neural networks , one central problem remains largely unsolved : how do we recover the finer texture details when we super-resolve at large upscaling factors ? The behavior of optimization-based super-resolution methods is principally driven by the choice of the objective function . Recent work has largely focused on minimizing the mean squared reconstruction error . The resulting estimates have high peak signal-to-noise ratios , but they are often lacking high-frequency details and are perceptually unsatisfying in the sense that they fail to match the fidelity expected at the higher resolution . In this paper , we present SRGAN , a generative adversarial network for image superresolution . To our knowledge , $SEPB$ In recent years , supervised learning with convolutional networks has seen huge adoption in computer vision applications . Comparatively , unsupervised learning with CNNs has received less attention . In this work we hope to help bridge the gap between the success of CNNs for supervised learning and unsupervised learning . We introduce a class of CNNs called deep convolutional generative adversarial networks , that have certain architectural constraints , and demonstrate that they are a strong candidate for unsupervised learning . Training on various image datasets , we show convincing evidence that our deep convolutional adversarial pair learns a hierarchy of representations from object parts to scenes in both the generator and discriminator . Additionally , we use the learned features for novel tasks -demonstrating their applicability $SEPB$ In this work we investigate the effect of the convolutional network depth on its accuracy in the large-scale image recognition setting . Our main contribution is a thorough evaluation of networks of increasing depth , which shows that a significant improvement on the prior-art configurations can be achieved by pushing the depth to 16-19 weight layers . These findings were the basis of our ImageNet Challenge 2014 submission , where our team secured the first and the second places in the localisation and classification tracks respectively . We also show that our representations generalise well to other datasets , where they achieve the stateof-the-art results . Importantly , we have made our two best-performing ConvNet models publicly available to facilitate further research on the use of deep visual $SEPB$ horse zebra zebra horse Summer Winter summer winter winter summer Photograph Van Gogh Cezanne Monet Ukiyo-e Monet Photos Monet photo photo MonetFigure 1 : Given any two unordered image collections X and Y , our algorithm learns to automatically `` translate '' an image from one into the other and vice versa . Example application : using a collection of paintings of a famous artist , learn to render a user 's photograph into their style .Image-to-image translation is a class of vision and graphics problems where the goal is to learn the mapping between an input image and an output image using a training set of aligned image pairs . However , for many tasks , paired training data will not be available . We present an
1	In recent years , accurate and efficient flow estimators based on convolutional neural networks emerged . $SEP$ We present a self-supervised approach to estimate flow in camera image and top-view grid map sequences using fully convolutional neural networks in the domain of automated driving . We extend existing approaches for self-supervised optical flow estimation by adding a regularizer expressing motion consistency assuming a static environment . However , as this assumption is violated for other moving traffic participants we also estimate a mask to scale this regularization . Adding a regularization towards motion consistency improves convergence and flow estimation accuracy . Furthermore , we scale the errors due to spatial flow inconsistency by a mask that we derive from the motion mask . This improves accuracy in regions where the flow drastically changes due to a better separation between static and dynamic environment . We apply our approach to optical flow estimation from camera image sequences , validate on odometry estimation and suggest a method to iteratively increase optical flow estimation accuracy using the generated motion masks . Finally , we provide quantitative and qualitative results based on the KITTI odometry and tracking benchmark for scene flow estimation based on grid map sequences . We show that we can improve accuracy and convergence when applying motion and $SEP$ Convolutional neural networks $FULLTEXT$ Convolutional neural networks have become the method of choice in many fields of computer vision . They are classically applied to classification , but recently presented architectures also allow for per-pixel predictions like semantic segmentation or depth estimation from single images . In this paper , we propose training CNNs endto-end to learn predicting the optical flow field from a pair of images .While optical flow estimation needs precise per-pixel localization , it also requires finding correspondences between two input images . This involves not only learning image feature representations , but also learning to match them at different locations in the two images . In this respect , optical flow estimation fundamentally differs from previous applications of CNNs . * These authors contributed $SEPB$ We present a compact but effective CNN model for optical flow , called PWC-Net . PWC-Net has been designed according to simple and well-established principles : pyramidal processing , warping , and the use of a cost volume . Cast in a learnable feature pyramid , PWC-Net uses the current optical flow estimate to warp the CNN features of the second image . It then uses the warped features and features of the first image to construct a cost volume , which is processed by a CNN to estimate the optical flow . PWC-Net is 17 times smaller in size and easier to train than the recent FlowNet2 model . Moreover , it outperforms all published optical flow methods on the MPI Sintel final pass and KITTI 2015
0	For finding bug-triggering interleavings in multithreaded code , numerous techniques have been proposed , including static #CITE# and dynamic approaches #CITE# , and their combination #CITE# , #CITE# . Randomized thread scheduling and statistical fault localization have also shown promise in testing parallel code #CITE# - #CITE# . $SEP$ Abstract-Testing multithreaded code is hard and expensive . A multithreaded unit test creates two or more threads , each executing one or more methods on shared objects of the class under test . Such unit tests can be generated at random , but basic random generation produces tests that are either slow or do not trigger concurrency bugs . Worse , such tests have many false alarms , which require human effort to filter out . We present BALLERINA , a novel technique for automated random generation of efficient multithreaded tests that effectively trigger concurrency bugs . BALLERINA makes tests efficient by having only two threads , each executing a single , randomly selected method . BALLERINA increases chances that such simple parallel code finds bugs by appending it to more complex , randomly generated sequential code . We also propose a clustering technique to reduce the manual effort in inspecting failures of automatically generated multithreaded tests . We evaluate BALLERINA on 14 real-world bugs from six popular codebases : Groovy , JDK , JFreeChart , Apache Log4j , Apache Lucene , and Apache Pool . The experiments show that tests generated by BALLERINA find bugs on average 2X-10X faster $SEP$ We present a novel technique for static race detection in Java programs , comprised of a series of stages that employ a combination of static analyses to successively reduce the pairs of memory accesses potentially involved in a race . We have implemented our technique and applied it to a suite of multi-threaded Java programs . Our experiments show that it is precise , scalable , and useful , reporting tens to hundreds of serious and previously unknown concurrency bugs in large , widely-used programs with few false alarms . $FULLTEXT$ A multi-threaded program contains a race if two threads can access the same memory location without ordering constraints enforced between them and at least one access is a write . A race often implies a violation of $SEPB$ Model checkers search the space of possible program behaviors to detect errors and to demonstrate their absence . Despite major advances in reduction and optimization techniques , state-space search can still become cost-prohibitive as program size and complexity increase . In this paper , we present a technique for dramatically improving the costeffectiveness of state-space search techniques for error detection using parallelism . Our approach can be composed with all of the reduction and optimization techniques we are aware of to amplify their benefits . It was developed based on insights gained from performing a large empirical study of the cost-effectiveness of randomization techniques in state-space analysis . We explain those insights and our technique , and then show through a focused empirical study that our technique speeds
1	Earlier approaches for image captioning are rule-/template-based #CITE# . Recently , attention-based neural encoder-decoder models prevail #CITE# . Attention mechanisms have been operated on uniform spatial grids #CITE# , semantic metadata #CITE# , and object-level regions #CITE# . Although attention mechanisms are generally shown to improve caption quality , some quantitative analyses #CITE# show that the "correctness" of the attention is far from satisfactory . Lu et al #CITE# proposed a slot-and-fill framework for image captioning that can produce natural language explicitly grounded in entities . In #CITE# , attention module is explicitly supervised . $SEP$ Visual attention not only improves the performance of image captioners , but also serves as a visual interpretation to qualitatively measure the caption rationality and model transparency . Specifically , we expect that a captioner can fix its attentive gaze on the correct objects while generating the corresponding words . This ability is also known as grounded image captioning . However , the grounding accuracy of existing captioners is far from satisfactory . To improve the grounding accuracy while retaining the captioning quality , it is expensive to collect the word-region alignment as strong supervision . To this end , we propose a Part-of-Speech enhanced image-text matching model : POS-SCAN , as the effective knowledge distillation for more grounded image captioning . The benefits are two-fold : 1 ) given a sentence and an image , POS-SCAN can ground the objects more accurately than SCAN ; 2 ) POS-SCAN serves as a word-region alignment regularization for the captioner 's visual attention module . By showing benchmark experimental results , we demonstrate that conventional image captioners equipped with POS-SCAN can significantly improve the grounding accuracy without strong supervision . Last but not the least , we explore the indispensable Self-Critical Sequence $SEP$ Abstract-We present a system to automatically generate natural language descriptions from images . This system consists of two parts . The first part , content planning , smooths the output of computer vision-based detection and recognition algorithms with statistics mined from large pools of visually descriptive text to determine the best content words to use to describe an image . The second step , surface realization , chooses words to construct natural language sentences based on the predicted content and general statistics from natural language . We present multiple approaches for the surface realization step and evaluate each using automatic measures of similarity to human generated reference descriptions . We also collect forced choice human evaluations between descriptions from the proposed generation system and descriptions from competing approaches $SEPB$ This paper introduces a novel generation system that composes humanlike descriptions of images from computer vision detections . By leveraging syntactically informed word co-occurrence statistics , the generator filters and constrains the noisy detections output from a vision system to generate syntactic trees that detail what the computer vision system sees . Results show that the generation system outperforms state-of-the-art systems , automatically generating some of the most natural image descriptions to date . $FULLTEXT$ It is becoming a real possibility for intelligent systems to talk about the visual world . New ways of mapping computer vision to generated language have emerged in the past few years , with a focus on pairing detections in an image to words . The goal in connecting vision to language has $SEPB$ Studying natural language , and especially how people describe the world around them can help us better understand the visual world . In turn , it can also help us in the quest to generate natural language that describes this world in a human manner . We present a simple yet effective approach to automatically compose image descriptions given computer vision based inputs and using web-scale n-grams . Unlike most previous work that summarizes or retrieves pre-existing text relevant to an image , our method composes sentences entirely from scratch . Experimental results indicate that it is viable to generate simple textual descriptions that are pertinent to the specific content of an image , while permitting creativity in the description -making for more human-like annotations than previous approaches $SEPB$ Attention-based neural encoder-decoder frameworks have been widely adopted for image captioning . Most methods force visual attention to be active for every generated word . However , the decoder likely requires little to no visual information from the image to predict non-visual words such as `` the '' and `` of '' . Other words that may seem visual can often be predicted reliably just from the language model eg , `` sign '' after `` behind a red stop '' or `` phone '' following `` talking on a cell '' . In this paper , we propose a novel adaptive attention model with a visual sentinel . At each time step , our model decides whether to attend to the image or to the visual sentinel $SEPB$ Visual attention has been successfully applied in structural prediction tasks such as visual captioning and question answering . Existing visual attention models are generally spatial , ie , the attention is modeled as spatial probabilities that re-weight the last conv-layer feature map of a CNN encoding an input image . However , we argue that such spatial attention does not necessarily conform to the attention mechanism -a dynamic feature extractor that combines contextual fixations over time , as CNN features are naturally spatial , channel-wise and multi-layer . In this paper , we introduce a novel convolutional neural network dubbed SCA-CNN that incorporates Spatial and Channelwise Attentions in a CNN . In the task of image captioning , SCA-CNN dynamically modulates the sentence generation context in multi-layer feature $SEPB$ Abstract . It is always well believed that modeling relationships between objects would be helpful for representing and eventually describing an image . Nevertheless , there has not been evidence in support of the idea on image description generation . In this paper , we introduce a new design to explore the connections between objects for image captioning under the umbrella of attention-based encoder-decoder framework . Specifically , we present Graph Convolutional Networks plus Long Short-Term Memory architecture that novelly integrates both semantic and spatial object relationships into image encoder . Technically , we build graphs over the detected objects in an image based on their spatial and semantic connections . The representations of each region proposed on objects are then refined by leveraging graph structure through GCN $SEPB$ Many vision-language tasks can be reduced to the problem of sequence prediction for natural language output . In particular , recent advances in image captioning use deep reinforcement learning to alleviate the `` exposure bias '' during training : ground-truth subsequence is exposed in every step prediction , which introduces bias in test when only predicted subsequence is seen . However , existing RL-based image captioning methods only focus on the language policy while not the visual policy , and thus fail to capture the visual context that are crucial for compositional reasoning such as visual relationships and comparisons . To fill the gap , we propose a Context-Aware Visual Policy network for sequence-level image captioning . At every time step , CAVP explicitly accounts for the previous $SEPB$ We do not speak word by word from scratch ; our brain quickly structures a pattern like STH DO STH AT SOME-PLACE and then fills in the detailed descriptions . To render existing encoder-decoder image captioners such humanlike reasoning , we propose a novel framework : learning to Collocate Neural Modules , to generate the `` inner pattern '' connecting visual encoder and language decoder . Unlike the widely-used neural module networks in visual Q & A , where the language is fully observable , CNM for captioning is more challenging as the language is being generated and thus is partially observable . To this end , we make the following technical contributions for CNM training : 1 ) compact module design -one for function words and three $SEPB$ Attention-based neural encoder-decoder frameworks have been widely adopted for image captioning . Most methods force visual attention to be active for every generated word . However , the decoder likely requires little to no visual information from the image to predict non-visual words such as `` the '' and `` of '' . Other words that may seem visual can often be predicted reliably just from the language model eg , `` sign '' after `` behind a red stop '' or `` phone '' following `` talking on a cell '' . In this paper , we propose a novel adaptive attention model with a visual sentinel . At each time step , our model decides whether to attend to the image or to the visual sentinel $SEPB$ Automatically generating a natural language description of an image has attracted interests recently both because of its importance in practical applications and because it connects two major artificial intelligence fields : computer vision and natural language processing . Existing approaches are either top-down , which start from a gist of an image and convert it into words , or bottom-up , which come up with words describing various aspects of an image and then combine them . In this paper , we propose a new algorithm that combines both approaches through a model of semantic attention . Our algorithm learns to selectively attend to semantic concept proposals and fuse them into hidden states and outputs of recurrent neural networks . The selection and fusion form a feedback connecting $SEPB$ We propose Scene Graph Auto-Encoder that incorporates the language inductive bias into the encoderdecoder image captioning framework for more human-like captions . Intuitively , we humans use the inductive bias to compose collocations and contextual inference in discourse . For example , when we see the relation `` person on bike '' , it is natural to replace `` on '' with `` ride '' and infer `` person riding bike on a road '' even the `` road '' is not evident . Therefore , exploiting such bias as a language prior is expected to help the conventional encoder-decoder models less likely overfit to the dataset bias and focus on reasoning . Specifically , we use the scene graph -a directed graph where an object node is $SEPB$ Image captioning attempts to generate a sentence composed of several linguistic words , which are used to describe objects , attributes , and interactions in an image , denoted as visual semantic units in this paper . Based on this view , we propose to explicitly model the object interactions in semantics and geometry based on Graph Convolutional Networks , and fully exploit the alignment between linguistic words and visual semantic units for image captioning . Particularly , we construct a semantic graph and a geometry graph , where each node corresponds to a visual semantic unit , ie , an object , an attribute , or a semantic interaction between two objects . Accordingly , the semantic context-aware embeddings for each unit are obtained through the corresponding $SEPB$ Top-down visual attention mechanisms have been used extensively in image captioning and visual question answering to enable deeper image understanding through fine-grained analysis and even multiple steps of reasoning . In this work , we propose a combined bottom-up and topdown attention mechanism that enables attention to be calculated at the level of objects and other salient image regions . This is the natural basis for attention to be considered . Within our approach , the bottom-up mechanism proposes image regions , each with an associated feature vector , while the top-down mechanism determines feature weightings . Applying this approach to image captioning , our results on the MSCOCO test server establish a new state-of-the-art for the task , improving the best published result in terms of CIDEr $SEPB$ Attention mechanisms are widely used in current encoder/decoder frameworks of image captioning , where a weighted average on encoded vectors is generated at each time step to guide the caption decoding process . However , the decoder has little idea of whether or how well the attended vector and the given attention query are related , which could make the decoder give misled results . In this paper , we propose an `` Attention on Attention '' module , which extends the conventional attention mechanisms to determine the relevance between attention results and queries . AoA first generates an `` information vector '' and an `` attention gate '' using the attention result and the current context , then adds another attention by applying element-wise multiplication to them $SEPB$ Abstract . It is always well believed that modeling relationships between objects would be helpful for representing and eventually describing an image . Nevertheless , there has not been evidence in support of the idea on image description generation . In this paper , we introduce a new design to explore the connections between objects for image captioning under the umbrella of attention-based encoder-decoder framework . Specifically , we present Graph Convolutional Networks plus Long Short-Term Memory architecture that novelly integrates both semantic and spatial object relationships into image encoder . Technically , we build graphs over the detected objects in an image based on their spatial and semantic connections . The representations of each region proposed on objects are then refined by leveraging graph structure through GCN $SEPB$ Abstract-With the maturity of visual detection techniques , we are more ambitious in describing visual content with open-vocabulary , fine-grained and free-form language , ie , the task of image captioning . In particular , we are interested in generating longer , richer and more fine-grained sentences and paragraphs as image descriptions . Image captioning can be translated to the task of sequential language prediction given visual content , where the output sequence forms natural language description with plausible grammar . However , existing image captioning methods focus only on language policy while not visual policy , and thus fail to capture visual context that is crucial for compositional reasoning such as object relationships and visual comparisons cat '' ) . This issue is especially severe when generating $SEPB$ Attention mechanisms have recently been introduced in deep learning for various tasks in natural language processing and computer vision . But despite their popularity , the `` correctness '' of the implicitly-learned attention maps has only been assessed qualitatively by visualization of several examples . In this paper we focus on evaluating and improving the correctness of attention in neural image captioning models . Specifically , we propose a quantitative evaluation metric for how well the attention maps align with human judgment , using recently released datasets with alignment between regions in images and entities in captions . We then propose novel models with different levels of explicit supervision for learning attention maps during training . The supervision can be strong when alignment between regions and caption entities $SEPB$ When generating a sentence description for an image , it frequently remains unclear how well the generated caption is grounded in the image or if the model hallucinates based on priors in the dataset and/or the language model . The most common way of relating image regions with words in caption models is through an attention mechanism over the regions that is used as input to predict the next word . The model must therefore learn to predict the attention without knowing the word it should localize . In this work , we propose a novel cyclical training regimen that forces the model to localize each word in the image after the sentence decoder generates it and then reconstruct the sentence from the localized image region to match $SEPB$ We introduce a novel framework for image captioning that can produce natural language explicitly grounded in entities that object detectors find in the image . Our approach reconciles classical slot filling approaches with modern neural captioning approaches . Our approach first generates a sentence 'template ' with slot locations explicitly tied to specific image regions . These slots are then filled in by visual concepts identified in the regions by object detectors . The entire architecture is end-to-end differentiable . We verify the effectiveness of our proposed model on different image captioning tasks . On standard image captioning and novel object captioning , our model reaches state-of-the-art on both COCO and Flickr30k datasets . We also demonstrate that our model has unique advantages when the train and test $SEPB$ Attention mechanisms have recently been introduced in deep learning for various tasks in natural language processing and computer vision . But despite their popularity , the `` correctness '' of the implicitly-learned attention maps has only been assessed qualitatively by visualization of several examples . In this paper we focus on evaluating and improving the correctness of attention in neural image captioning models . Specifically , we propose a quantitative evaluation metric for how well the attention maps align with human judgment , using recently released datasets with alignment between regions in images and entities in captions . We then propose novel models with different levels of explicit supervision for learning attention maps during training . The supervision can be strong when alignment between regions and caption entities $SEPB$ Abstract $FULLTEXT$ Image and video description models are frequently not well grounded which can increase their bias and lead to hallucination of objects , i .e . the model mentions objects which are not in the image or video e .g . because they might have appeared in similar contexts during training . This makes models less accountable and trustworthy , which is important if we hope such models will eventually assist people in need . Additionally , grounded models can help to explain the model 's decisions to humans and allow humans to diagnose them . While researchers have started to discover and study these problems for image description , 1 they are even more pronounced 1 We use description instead of captioning as captioning is often
1	To better capture subtle visual difference among sub-ordinate categories , a series works #CITE# were also proposed to leverage extra supervision of bounding boxes and parts to locate discriminative regions . $SEP$ Object categories inherently form a hierarchy with different levels of concept abstraction , especially for fine-grained categories . For example , birds can be categorized according to a four-level hierarchy of order , family , genus , and species . This hierarchy encodes rich correlations among various categories across different levels , which can effectively regularize the semantic space and thus make prediction less ambiguous . However , previous studies of finegrained image recognition primarily focus on categories of one certain level and usually overlook this correlation information . In this work , we investigate simultaneously predicting categories of different levels in the hierarchy and integrating this structured correlation information into the deep neural network by developing a novel Hierarchical Semantic Embedding framework . Specifically , the HSE framework sequentially predicts the category score vector of each level in the hierarchy , from highest to lowest . At each level , it incorporates the predicted score vector of the higher level as prior knowledge to learn finer-grained feature representation . During training , the predicted score vector of the higher level is also employed to regularize label prediction by using it as soft targets of corresponding sub-categories . To evaluate $SEP$ In the context of fine-grained visual categorization , the ability to interpret models as human-understandable visual manuals is sometimes as important as achieving high classification accuracy . In this paper , we propose a novel Part-Stacked CNN architecture that explicitly explains the finegrained recognition process by modeling subtle differences from object parts . Based on manually-labeled strong part annotations , the proposed architecture consists of a fully convolutional network to locate multiple object parts and a two-stream classification network that encodes object-level and part-level cues simultaneously . By adopting a set of sharing strategies between the computation of multiple object parts , the proposed architecture is very efficient running at 20 frames/sec during inference . Experimental results on the CUB-200-2011 dataset reveal the effectiveness of the proposed architecture $SEPB$ Abstract . Semantic part localization can facilitate fine-grained categorization by explicitly isolating subtle appearance differences associated with specific object parts . Methods for pose-normalized representations have been proposed , but generally presume bounding box annotations at test time due to the difficulty of object detection . We propose a model for fine-grained categorization that overcomes these limitations by leveraging deep convolutional features computed on bottom-up region proposals . Our method learns whole-object and part detectors , enforces learned geometric constraints between them , and predicts a fine-grained category from a pose-normalized representation . Experiments on the Caltech-UCSD bird dataset confirm that our method outperforms state-of-the-art fine-grained categorization methods in an end-to-end evaluation without requiring a bounding box at test time . $FULLTEXT$ The problem of visual fine-grained categorization
0	In CSF #CITE# , TNRD #CITE# , and UNET #CITE# , similar parametric formulation has been adopted to model natural image prior , and discriminative learning is employed to boost restoration performance . $SEP$ Most existing non-blind restoration methods are based on the assumption that a precise degradation model is known . As the degradation process can only partially known or inaccurately modeled , images may not be well restored . Rain streak removal and image deconvolution with inaccurate blur kernels are two representative examples of such tasks . For rain streak removal , although an input image can be decomposed into a scene layer and a rain streak layer , there exists no explicit formulation for modeling rain streaks and the composition with scene layer . For blind deconvolution , as estimation error of blur kernel is usually introduced , the subsequent non-blind deconvolution process does not restore the latent image well . In this paper , we propose a principled algorithm within the maximum a posterior framework to tackle image restoration with a partially known or inaccurate degradation model . Specifically , the residual caused by a partially known or inaccurate degradation model is spatially dependent and complexly distributed . With a training set of degraded and ground-truth image pairs , we parameterize and learn the fidelity term for a degradation model in a task-driven manner . Furthermore , the regularization term $SEP$ Abstract-Image restoration is a long-standing problem in low-level computer vision with many interesting applications . We describe a flexible learning framework based on the concept of nonlinear reaction diffusion models for various image restoration problems . By embodying recent improvements in nonlinear diffusion models , we propose a dynamic nonlinear reaction diffusion model with time-dependent parameters . In contrast to previous nonlinear diffusion models , all the parameters , including the filters and the influence functions , are simultaneously learned from training data through a loss based approach . We call this approach TNRD-Trainable Nonlinear Reaction Diffusion . The TNRD approach is applicable for a variety of image restoration tasks by incorporating appropriate reaction force . We demonstrate its capabilities with three representative applications , Gaussian image denoising $SEPB$ We design a novel network architecture for learning discriminative image models that are employed to efficiently tackle the problem of grayscale and color image denoising . Based on the proposed architecture , we introduce two different variants . The first network involves convolutional layers as a core component , while the second one relies instead on non-local filtering layers and thus it is able to exploit the inherent non-local self-similarity property of natural images . As opposed to most of the existing deep network approaches , which require the training of a specific model for each considered noise level , the proposed models are able to handle a wide range of noise levels using a single set of learned parameters , while they are very robust when the
2	Large Convolutional Neural Networks and automatic Neural Architecture Search based networks Liu et al , 2018; Real et al , 2018) have evolved to show remarkable accuracy on various tasks such as image classification , object detection , benefitted from huge learnable parameters and computations . $SEP$ Some conventional transforms such as Discrete Walsh-Hadamard Transform and Discrete Cosine Transform have been widely used as feature extractors in image processing but rarely applied in neural networks . However , we found that these conventional transforms have the ability to capture the crosschannel correlations without any learnable parameters in DNNs . This paper firstly proposes to apply conventional transforms to pointwise convolution , showing that such transforms significantly reduce the computational complexity of neural networks without accuracy performance degradation . Especially for DWHT , it requires no floating point multiplications but only additions and subtractions , which can considerably reduce computation overheads . In addition , its fast algorithm further reduces complexity of floating point addition from O to O . These nice properties construct extremely efficient networks in the number parameters and operations , enjoying accuracy gain . Our proposed DWHT-based model gained 1 .49 % accuracy increase with 79 .1 % reduced parameters and 48 .4 % reduced FLOPs compared with its baseline model on the CIFAR 100 dataset . $SEP$ We trained a large , deep convolutional neural network to classify the 1 .2 million high-resolution images in the ImageNet LSVRC-2010 contest into the 1000 different classes . On the test data , we achieved top-1 and top-5 error rates of 37 .5 % and 17 .0 % , respectively , which is considerably better than the previous state-of-the-art . The neural network , which has 60 million parameters and 650 ,000 neurons , consists of five convolutional layers , some of which are followed by max-pooling layers , and three fully connected layers with a final 1000-way softmax . To make training faster , we used nonsaturating neurons and a very efficient GPU implementation of the convolution operation . To reduce overfitting in the fully connected layers $SEPB$ In this work we investigate the effect of the convolutional network depth on its accuracy in the large-scale image recognition setting . Our main contribution is a thorough evaluation of networks of increasing depth , which shows that a significant improvement on the prior-art configurations can be achieved by pushing the depth to 16-19 weight layers . These findings were the basis of our ImageNet Challenge 2014 submission , where our team secured the first and the second places in the localisation and classification tracks respectively . We also show that our representations generalise well to other datasets , where they achieve the stateof-the-art results . Importantly , we have made our two best-performing ConvNet models publicly available to facilitate further research on the use of deep visual $SEPB$ Deeper neural networks are more difficult to train . We present a residual learning framework to ease the training of networks that are substantially deeper than those used previously . We explicitly reformulate the layers as learning residual functions with reference to the layer inputs , instead of learning unreferenced functions . We provide comprehensive empirical evidence showing that these residual networks are easier to optimize , and can gain accuracy from considerably increased depth . On the ImageNet dataset we evaluate residual nets with a depth of up to 152 layers-8× deeper than VGG nets but still having lower complexity . An ensemble of these residual nets achieves 3 .57 % error on the ImageNet test set . This result won the 1st place on the ILSVRC $SEPB$ Convolutional networks are at the core of most stateof-the-art computer vision solutions for a wide variety of tasks . Since 2014 very deep convolutional networks started to become mainstream , yielding substantial gains in various benchmarks . Although increased model size and computational cost tend to translate to immediate quality gains for most tasks , computational efficiency and low parameter count are still enabling factors for various use cases such as mobile vision and big-data scenarios . Here we are exploring ways to scale up networks in ways that aim at utilizing the added computation as efficiently as possible by suitably factorized convolutions and aggressive regularization . We benchmark our methods on the ILSVRC 2012 classification challenge validation set demonstrate substantial gains over the state of the art $SEPB$ Abstract . We propose a new method for learning the structure of convolutional neural networks that is more efficient than recent state-of-the-art methods based on reinforcement learning and evolutionary algorithms . Our approach uses a sequential model-based optimization strategy , in which we search for structures in order of increasing complexity , while simultaneously learning a surrogate model to guide the search through structure space . Direct comparison under the same search space shows that our method is up to 5 times more efficient than the RL method of Zoph et al . in terms of number of models evaluated , and 8 times faster in terms of total compute . The structures we discover in this way achieve state of the art classification accuracies on CIFAR-10 and $SEPB$ The effort devoted to hand-crafting neural network image classifiers has motivated the use of architecture search to discover them automatically . Although evolutionary algorithms have been repeatedly applied to neural network topologies , the image classifiers thus discovered have remained inferior to human-crafted ones . Here , we evolve an image classifierAmoebaNet-A-that surpasses hand-designs for the first time .To do this , we modify the tournament selection evolutionary algorithm by introducing an age property to favor the younger genotypes . Matching size , AmoebaNet-A has comparable accuracy to current state-of-the-art ImageNet models discovered with more complex architecture-search methods . Scaled to larger size , AmoebaNet-A sets a new state-of-theart 83 .9 % top-1 / 96 .6 % top-5 ImageNet accuracy . In a controlled comparison against a well $SEPB$ Abstract-We present a new dataset with the goal of advancing the state-of-the-art in object recognition by placing the question of object recognition in the context of the broader question of scene understanding . This is achieved by gathering images of complex everyday scenes containing common objects in their natural context . Objects are labeled using per-instance segmentations to aid in precise object localization . Our dataset contains photos of 91 objects types that would be easily recognizable by a 4 year old . With a total of 2 .5 million labeled instances in 328k images , the creation of our dataset drew upon extensive crowd worker involvement via novel user interfaces for category detection , instance spotting and instance segmentation . We present a detailed statistical analysis of
1	Several techniques such as lowrank approximation #CITE# or deep learning #CITE# are used to capture the representative features of normal entities . $SEP$ ABSTRACT Abnormal testing data can severely reduce model performance if not processed properly . In this paper , we propose a preprocessing system to handle different types of commonly seen abnormal testing data . The system consists of an aberrant data detector and an aberrant data corrector . The aberrant data detector is responsible for classifying the type of incoming data . Based on the data type , the aberrant data corrector will take different actions to amend testing data . Users can then apply their preferred prediction methods on the corrected testing data . Specifically , corrupted and adversarial images are used as examples of abnormal data . We show that corrupted data can be reconstructed through a Gaussian locally linear mappings method , and the prediction performance of adversarial samples can be improved by using the nearest neighbors as a surrogate . We compare the proposed aberrant data detector and corrector with existing and well-recognized alternatives . These approaches are published individually and do not put two components together as a pre-processing system . The numerical outcomes show that our proposed components , standing alone , are competitive . The proposed system is a generic method that can $SEP$ Abstract-This paper presents a remarkably simple , yet powerful , algorithm termed Coherence Pursuit to robust Principal Component Analysis . As inliers lie in a lowdimensional subspace and are mostly correlated , an inlier is likely to have strong mutual coherence with a large number of data points . By contrast , outliers either do not admit low dimensional structures or form small clusters . In either case , an outlier is unlikely to bear strong resemblance to a large number of data points . Given that , CoP sets an outlier apart from an inlier by comparing their coherence with the rest of the data points . The mutual coherences are computed by forming the Gram matrix of the normalized data points . Subsequently , the sought $SEPB$ In this paper , we introduce autoencoder ensembles for unsupervised outlier detection . One problem with neural networks is that they are sensitive to noise and often require large data sets to work robustly , while increasing data size makes them slow . As a result , there are only a few existing works in the literature on the use of neural networks in outlier detection . This paper shows that neural networks can be a very competitive technique to other existing methods . The basic idea is to randomly vary on the connectivity architecture of the autoencoder to obtain significantly better performance . Furthermore , we combine this technique with an adaptive sampling method to make our approach more efficient and effective . Experimental results comparing the
0	In controlled systems , there exist several works that perform the sampling in relation to the stability of the system based on a Lyapunov function #CITE# . $SEP$ Abstract : For the problem of pose estimation of an autonomous vehicle using networked external sensors , the processing capacity and battery consumption of these sensors , as well as the communication channel load should be optimized . Here , we report an event-based state estimator consisting of an unscented Kalman filter that uses a triggering mechanism based on the estimation error covariance matrix to request measurements from the external sensors . This EBSE generates the events of the estimator module on-board the vehicle and , thus , allows the sensors to remain in stand-by mode until an event is generated . The proposed algorithm requests a measurement every time the estimation distance root mean squared error value , obtained from the estimator 's covariance matrix , exceeds a threshold value . This triggering threshold can be adapted to the vehicle 's working conditions rendering the estimator even more efficient . An example of the use of the proposed EBSE is given , where the autonomous vehicle must approach and follow a reference trajectory . By making the threshold a function of the distance to the reference location , the estimator can halve the use of the sensors with a $SEP$ Abstract-In this technical note , a universal formula is proposed for event-based stabilization of general nonlinear systems affine in the control . The feedback is derived from the original one proposed by E . Sontag in the case of continuous time stabilization . Under the assumption of the existence of a smooth Control Lyapunov Function , it is proved that an event-based static feedback , smooth everywhere except at the origin , can be designed so to ensure the global asymptotic stability of the origin . Moreover , the inter-sampling time can be proved not to contract at the origin . More precisely , it is proved that for any initial condition within any given closed set the minimal inter-sampling time is proved to be below bounded avoiding $SEPB$ Abstract-In this note , we revisit the problem of scheduling stabilizing control tasks on embedded processors . We start from the paradigm that a real-time scheduler could be regarded as a feedback controller that decides which task is executed at any given instant . This controller has for objective guaranteeing that software tasks meet their deadlines and that stabilizing control tasks asymptotically stabilize the plant . We investigate a simple event-triggered scheduler based on this feedback paradigm and show how it leads to guaranteed performance thus relaxing the more traditional periodic execution requirements . $FULLTEXT$ Small embedded microprocessors are quickly becoming an essential part of the most diverse applications . A particularly interesting example are physically distributed sensor/actuator networks responsible for collecting and processing information , and to
2	D EEP neural networks have provided state-of-theart performance in various fields such as image classification #CITE# , #CITE# , semantic modeling #CITE# , #CITE# , visual quality evaluation #CITE# , object detection #CITE# , #CITE# , and segmentation #CITE# . $SEP$ Abstract-Deep convolutional neural networks have been widely used in numerous applications , but their demanding storage and computational resource requirements prevent their applications on mobile devices . Knowledge distillation aims to optimize a portable student network by taking the knowledge from a well-trained heavy teacher network . Traditional teacher-student based methods used to rely on additional fully-connected layers to bridge intermediate layers of teacher and student networks , which brings in a large number of auxiliary parameters . In contrast , this paper aims to propagate information from teacher to student without introducing new variables which need to be optimized . We regard the teacher-student paradigm from a new perspective of feature embedding . By introducing the locality preserving loss , the student network is encouraged to generate the low-dimensional features which could inherit intrinsic properties of their corresponding high-dimensional features from teacher network . The resulting portable network thus can naturally maintain the performance as that of the teacher network . Theoretical analysis is provided to justify the lower computation complexity of the proposed method . Experiments on benchmark datasets and well-trained networks suggest that the proposed algorithm is superior to state-of-the-art teacher-student learning methods in terms of computational $SEP$ In this work we investigate the effect of the convolutional network depth on its accuracy in the large-scale image recognition setting . Our main contribution is a thorough evaluation of networks of increasing depth , which shows that a significant improvement on the prior-art configurations can be achieved by pushing the depth to 16-19 weight layers . These findings were the basis of our ImageNet Challenge 2014 submission , where our team secured the first and the second places in the localisation and classification tracks respectively . We also show that our representations generalise well to other datasets , where they achieve the stateof-the-art results . Importantly , we have made our two best-performing ConvNet models publicly available to facilitate further research on the use of deep visual $SEPB$ We trained a large , deep convolutional neural network to classify the 1 .2 million high-resolution images in the ImageNet LSVRC-2010 contest into the 1000 different classes . On the test data , we achieved top-1 and top-5 error rates of 37 .5 % and 17 .0 % , respectively , which is considerably better than the previous state-of-the-art . The neural network , which has 60 million parameters and 650 ,000 neurons , consists of five convolutional layers , some of which are followed by max-pooling layers , and three fully connected layers with a final 1000-way softmax . To make training faster , we used nonsaturating neurons and a very efficient GPU implementation of the convolution operation . To reduce overfitting in the fully connected layers $SEPB$ Several variants of the Long Short-Term Memory architecture for recurrent neural networks have been proposed since its inception in 1995 . In recent years , these networks have become the state-of-the-art models for a variety of machine learning problems . This has led to a renewed interest in understanding the role and utility of various computational components of typical LSTM variants . In this paper , we present the first large-scale analysis of eight LSTM variants on three representative tasks : speech recognition , handwriting recognition , and polyphonic music modeling . The hyperparameters of all LSTM variants for each task were optimized separately using random search and their importance was assessed using the powerful fANOVA framework . In total , we summarize the results of 5400 experimental $SEPB$ Convolutional networks are powerful visual models that yield hierarchies of features . We show that convolutional networks by themselves , trained end-to-end , pixelsto-pixels , exceed the state-of-the-art in semantic segmentation . Our key insight is to build `` fully convolutional '' networks that take input of arbitrary size and produce correspondingly-sized output with efficient inference and learning . We define and detail the space of fully convolutional networks , explain their application to spatially dense prediction tasks , and draw connections to prior models . We adapt contemporary classification networks into fully convolutional networks and transfer their learned representations by fine-tuning to the segmentation task . We then define a skip architecture that combines semantic information from a deep , coarse layer with appearance information from a
2	More recent work has investigated other types of reranking models , such as hierarchical syntactic language models , discriminative models trained to replicate user ratings of utterance quality , or language models trained on speaker-specific corpora to model linguistic alignment . $SEP$ Most previous work on trainable language generation has focused on two paradigms : using a statistical model to rank a set of pre-generated utterances , or Interestingly , human judges find the system sampling from the n-best list to be more natural than a system always returning the first-best utterance . The judges are also more willing to interact with the n-best system in the future . These results suggest that capturing the large variation found in human language using data-driven methods is beneficial for dialogue interaction . $SEP$ Previous stochastic approaches to generation do not include a tree-based representation of syntax . While this may be adequate or even advantageous for some applications , other applications profit from using as much syntactic knowledge as is available , leaving to a stochastic model only those issues that are not determined by the grammar . We present initial resuits showing that a tree-based model derived from a tree-annotated corpus improves on a tree model derived from an unannotated corpus , and that a tree-based stochastic model with a handcrafted grammar outpertbrms both . $FULLTEXT$ For many apt ) lications in natural language gen~ eration , the range of linguistic expressions that must be generated is quite restricted , and a grammar tbr generation can be fltlly specified by $SEPB$ We present a hybrid natural language generation system that consolidates macro and micro planning and surface realization tasks into one statistical learning process . Our novel approach is based on deriving a template bank automatically from a corpus of texts from a target domain . First , we identify domain specific entity tags and Discourse Representation Structures on a per sentence basis . Each sentence is then organized into semantically similar groups by k-means clustering . After this semi-automatic processing , a number of corpus-level statistics are compiled and used as features by a ranking SVM to develop model weights from a training corpus . At generation time , a set of input data , the collection of semantically organized templates , and the model weights are used
0	This effort has been extended by Murray et al #CITE# , exploiting Prony's method for localized sources in order to estimate the locations in space and time of multiple sources . In a very recent work , they extended their method to distributed sensor networks #CITE# ,and to non-localized sources of diffusion fields , in particular to straight line and polygonal sources #CITE# , respectively . They furthermore consider other governing equations , such as the wave and Poisson equations #CITE# . $SEP$ We propose a scheme utilizing ideas from infinite dimensional compressed sensing for thermal source localization . Using the soft recovery framework of one of the authors , we provide rigorous theoretical guarantees for the recovery performance . In particular , we extend the framework in order to also include noisy measurements . Further , we conduct numerical experiments , showing that our proposed method has strong performance , in a wide range of settings . These include scenarios with few sensors , off-grid source positioning and high noise levels , both in one and two dimensions . Monitoring temperature over spatial domains is an important task with practical importance for surveillance and automation purposes . Areas of application include agriculture , climate change studies , thermal monitoring of CPUs , and environmental protection . Other applications include monitoring of the thermal field caused by on-chip sensors for many-core systems , and cultivation of sensitive species . For these and similar applications , it is necessary to monitor the temperature with high resolution using a proper sampling device for possibly long term periods . One possible way to do this is to estimate the positions of the initial heat sources . $SEP$ Abstract-We consider diffusion fields induced by a finite number of spatially localized sources and address the problem of estimating these sources using spatiotemporal samples of the field obtained with a sensor network . Within this framework , we consider two different time evolutions : the case where the sources are instantaneous , as well as , the case where the sources decay exponentially in time after activation . We first derive novel exact inversion formulas , for both source distributions , through the use of Green 's second theorem and a family of sensing functions to compute generalized field samples . These generalized samples can then be inverted using variations of existing algebraic methods such as Prony 's method . Next , we develop a novel and robust $SEPB$ In this paper we consider a diffusion field induced by multiple point sources and address the problem of reconstructing the field from its spatio-temporal samples obtained using a sensor network . We begin by formulating the problem as a multi-source estimation problem -so estimating source locations , activation times and intensities given samples of the induced field . Next a two-step algorithm is proposed for the single source field . First , the source location and intensity are estimated by applying the `` reciprocity gap '' principle ; we show that this step can also reveal locations of multiple non-instantaneous sources . In the second step , we use an iterative method , based on CauchySchwarz inequality , to find the activation time given the estimated location and $SEPB$ Sensor networks are important for monitoring several physical phenomena . In this paper , we consider the monitoring of diffusion fields and design simple , yet robust , sensing , data processing and communication strategies for estimating the sources of diffusion fields under communication constraints . Specifically , based on our previous work in the area , we firstly show how sources of the field can be recovered analytically through the use of well-chosen sensing functions . Then , by properly extending this scheme to our sensor network setting , we design and propose an effective diffusion field sensing strategy . Next , we introduce a physics-driven quantized gossip scheme , as a joint information processing and communication strategy for handling the network communication constraints : i .e $SEPB$ Abstract-Partial differential equations are central to describing many physical phenomena . Moreover in many applications these phenomena are observed through a sensor network , with the aim of inferring its underlying properties . Here we present a new framework for analysing fields governed by linear partial differential equations . The framework leverages from certain results in sampling and approximation theory to provide a unifying approach for solving a class of inverse source problems . Specifically , we show that the unknown field sources can be recovered from a sequence of so called generalised measurements using multidimensional frequency estimation techniques . Moreover , we show that this sequence of generalised measurements for our physics-driven fields , can be computed by taking linear weighted-sums of the sensor measurements , whereby
1	Most previous studies rely on a prior training of this model , which can be instrumentspecific #CITE# or generic #CITE# . $SEP$ Audio-to-score alignment aims at matching a symbolic representation to a musical recording . A key problem in this application is the great variability of audio observations which can be explained by a single symbolic element . Whereas most previous works deal with this problem by training or heuristic design of a generic observation model , we propose the adaptation of this model to each musical piece . We exploit a template-based formulation of the observation model and we investigate two strategies for the adaptation of the templates using a Hidden Markov Model for the alignment . Experiments run on a large dataset of popular and classical piano music show that such an approach can lead to a significant improvement of the alignment accuracy compared to the use of a single generic model , even if the latter is trained on real data . $SEP$ This paper describes our attempt to make the Hidden Markov Model score following system developed at Ircam sensible to past experiences in order to obtain better audio to score real-time alignment for musical applications . A new observation modeling based on Gaussian Mixture Models is developed which is trainable using a learning algorithm we would call automatic discriminative training . The novelty of this system lies in the fact that this method , unlike classical methods for HMM training , is not concerned with modeling the music signal but with correctly choosing the sequence of music events that was performed . Besides obtaining better alignment , new system 's parameters are controllable in a physical manner and the training algorithm learns different styles of music performance as discussed $SEPB$ We present a new method for establishing an alignment between a polyphonic musical score and a corresponding sampled audio performance . The method uses a graphical model containing both latent discrete variables , corresponding to score position , as well as a latent continuous tempo process . We use a simple data model based only on the pitch content of the audio signal . The data interpretation is defined to be the most likely configuration of the hidden variables , given the data , and we develop computational methodology to identify or approximate this configuration using a variant of dynamic programming involving parametrically represented continuous variables . Experiments are presented on a 55-minute hand-marked orchestral test set . $FULLTEXT$ We address an audio recognition problem in which a $SEPB$ We present a new method for realtime alignment of audio to score for polyphonic music signals . In this paper , we will be focusing mostly on the multiple-pitch observation algorithm proposed based on realtime Non-negative Matrix Factorization with sparseness constraints and hierarchical hidden Markov models for sequential modeling using particle filtering for decoding . The proposed algorithm has the advantage of having an explicit instrument model for pitch obtained through unsupervised learning as well as access to single note contribution probabilities which construct a complex chord instead of modeling the chord as one event . $FULLTEXT$ Traditionally , score following was introduced for two main reasons : First for musical accompaniment of human performers with a computer and second , for synchronization of live sound processing algorithms
1	Most of existing re-ID models are developed in a supervised manner to learn discriminative features #CITE# , #CITE# , #CITE# , #CITE# , #CITE# or learn distance metrics #CITE# , #CITE# , #CITE# . $SEP$ Abstract-Person re-identification is a task of matching pedestrians under disjoint camera views . To recognise paired snapshots , it has to cope with large cross-view variations caused by the camera view shift . Supervised deep neural networks are effective in producing a set of non-linear projections that can transform cross-view images into a common feature space . However , they typically impose a symmetric architecture , yielding the network ill-conditioned on its optimisation . In this paper , we learn view-invariant subspace for person re-ID , and its corresponding similarity metric using an adversarial view adaptation approach . The main contribution is to learn coupled asymmetric mappings regarding view characteristics which are adversarially trained to address the view discrepancy by optimising the cross-entropy view confusion objective . To determine the similarity value , the network is empowered with a similarity discriminator to promote features that are highly discriminant in distinguishing positive and negative pairs . The other contribution includes an adaptive weighing on the most difficult samples to address the imbalance of within/between-identity pairs . Our approach achieves notable improved performance in comparison to state-of-the-arts on benchmark datasets . $SEP$ Person re-identification aims to match pedestrians observed by disjoint camera views . It attracts increasing attention in computer vision due to its importance to surveillance system . To combat the major challenge of cross-view visual variations , deep embedding approaches are proposed by learning a compact feature space from images such that the Euclidean distances correspond to their cross-view similarity metric . However , the global Euclidean distance can not faithfully characterize the ideal similarity in a complex visual feature space because features of pedestrian images exhibit unknown distributions due to large variations in poses , illumination and occlusion . Moreover , intra-personal training samples within a local range are robust to guide deep embedding against uncontrolled variations , which however , can not be captured by a $SEPB$ In this paper , we address the problem of person reidentification , which $FULLTEXT$ Person re-identification is a problem of associating the persons captured from different cameras located at different physical sites . If the camera views are overlapped , the solution is trivial : the temporal information is reliable to solve the problem . In some real cases , the camera views are significantly disjoint and the temporal transition time between cameras varies greatly , making the temporal information not enough to solve the problem , and thus this problem becomes more challenging . Therefore , a lot of solutions exploiting various cues , such as appearance , which is also the interest in this paper , have been developed .Recently , deep neural networks have been $SEPB$ Existing person re-identification methods rely mostly on either localised or global feature representation alone . This ignores their joint benefit and mutual complementary effects . In this work , we show the advantages of jointly learning local and global features in a Convolutional Neural Network by aiming to discover correlated local and global features in different context . Specifically , we formulate a method for joint learning of local and global feature selection losses designed to optimise person re-id when using only generic matching metrics such as the L2 distance . We design a novel CNN architecture for Jointly Learning Multi-Loss of local and global discriminative feature optimisation subject concurrently to the same re-id labelled information . Extensive comparative evaluations demonstrate the advantages of this new JLML model $SEPB$ Most existing person re-identification methods focus on learning the optimal distance metrics across camera views . Typically a person 's appearance is represented using features of thousands of dimensions , whilst only hundreds of training samples are available due to the difficulties in collecting matched training images . With the number of training samples much smaller than the feature dimension , the existing methods thus face the classic small sample size problem and have to resort to dimensionality reduction techniques and/or matrix regularisation , which lead to loss of discriminative power . In this work , we propose to overcome the SSS problem in re-id distance metric learning by matching people in a discriminative null space of the training data . In this null space , images of
1	Three recently proposed GANs , IcGAN #CITE# , conditional Cycle-GAN #CITE# and StarGAN #CITE# , are able to translate a given image into an image with multiple attributes through conditional input labels . $SEP$ Generative adversarial networks have demonstrated great success in generating various visual content . However , images generated by existing GANs are often of attributes learned from one image domain . As a result , generating images of multiple attributes requires many real samples possessing multiple attributes which are very resource expensive to be collected . In this paper , we propose a novel GAN , namely Intersect-GAN , to learn multiple attributes from different image domains through an intersecting architecture . For example , given two image domains X 1 and X 2 with certain attributes , the intersection X 1 ∩ X 2 denotes a new domain where images possess the attributes from both X 1 and X 2 domains . The proposed IntersectGAN consists of two discriminators D 1 and D 2 to distinguish between generated and real samples of different domains , and three generators where the intersection generator is trained against both discriminators . And an overall adversarial loss function is defined over three generators . As a result , our proposed IntersectGAN can be trained on multiple domains of which each presents one specific attribute , and eventually eliminates the need of real sample images $SEP$ Generative Adversarial Networks have recently demonstrated to successfully approximate complex data distributions . A relevant extension of this model is conditional GANs , where the introduction of external information allows to determine specific representations of the generated images . In this work , we evaluate encoders to inverse the mapping of a cGAN , ie , mapping a real image into a latent space and a conditional representation . This allows , for example , to reconstruct and modify real images of faces conditioning on arbitrary attributes . Additionally , we evaluate the design of cGANs . The combination of an encoder with a cGAN , which we call Invertible cGAN , enables to re-generate real images with deterministic complex modifications . $FULLTEXT$ Image editing can be performed $SEPB$ Abstract . We are interested in attribute-guided face generation : given a low-res face input image , an attribute vector that can be extracted from a high-res image , our new method generates a highres face image for the low-res input that satisfies the given attributes . To address this problem , we condition the CycleGAN and propose conditional CycleGAN , which is designed to 1 ) handle unpaired training data because the training low/high-res and high-res attribute images may not necessarily align with each other , and to 2 ) allow easy control of the appearance of the generated face via the input attributes . We demonstrate high-quality results on the attribute-guided conditional CycleGAN , which can synthesize realistic face images with appearance easily controlled by user-supplied $SEPB$ . Multi-domain image-to-image translation results on the CelebA dataset via transferring knowledge learned from the RaFD dataset . The first and sixth columns show input images while the remaining columns are images generated by StarGAN . Note that the images are generated by a single generator network , and facial expression labels such as angry , happy , and fearful are from RaFD , not CelebA .Recent studies have shown remarkable success in imageto-image translation for two domains . However , existing approaches have limited scalability and robustness in handling more than two domains , since different models should be built independently for every pair of image domains . To address this limitation , we propose StarGAN , a novel and scalable approach that can perform image-to-image translations
2	Conventional approaches formulate optical flow estimation as an energy minimization problem based on brightness constancy and spatial smoothness since #CITE# with many follow-up improvements #CITE# . Estimating optical flow in a coarse-to-fine manner achieves better performance since it better solves large displacements #CITE# . Later works propose to use CNN extractors for feature matching #CITE# . $SEP$ Feature warping is a core technique in optical flow estimation ; however , the ambiguity caused by occluded areas during warping is a major problem that remains unsolved . In this paper , we propose an asymmetric occlusionaware feature matching module , which can learn a rough occlusion mask that filters useless areas immediately after feature warping without any explicit supervision . The proposed module can be easily integrated into end-to-end network architectures and enjoys performance gains while introducing negligible computational cost . The learned occlusion mask can be further fed into a subsequent network cascade with dual feature pyramids with which we achieve state-of-the-art performance . At the time of submission , our method , called MaskFlownet , surpasses all published optical flow methods on the MPI Sintel , KITTI 2012 and 2015 benchmarks . Code is available at https : //github .com/microsoft/MaskFlownet . $SEP$ ABSTRACT $FULLTEXT$ Optical flow is the distribution of apparent velocities of movement of brightness patterns in an image . Optical flow can arise from relative motion of objects and the viewer . Discontinuities in the optical flow can help in i segmenting images into regions that correspond to different objects . $SEPB$ Abstract-In this paper , we address the issue of recovering and segmenting the apparent velocity field in sequences of images . As for motion estimation , we minimize an objective function involving two robust terms . The first one cautiously captures the optical flow constraint , while the second term incorporates a discontinuity-preserving smoothness constraint . To cope with the nonconvex minimization problem thus defined , we design an efficient deterministic multigrid procedure . It converges fast toward estimates of good quality , while revealing the large discontinuity structures of flow fields . We then propose an extension of the model by attaching to it a flexible object-based segmentation device based on deformable closed curves . Experimental results on synthetic and natural sequences are presented , including an $SEPB$ Optical flow computation is a key component in many computer vision systems designed for tasks such as action detection or activity recognition . However , despite several major advances over the last decade , handling large displacement in optical flow remains an open problem .Inspired by the large displacement optical flow of Brox & Malik , our approach , termed DeepFlow , blends a matching algorithm with a variational approach for optical flow . We propose a descriptor matching algorithm , tailored to the optical flow problem , that allows to boost performance on fast motions . The matching algorithm builds upon a multi-stage architecture with 6 layers , interleaving convolutions and max-pooling , a construction akin to deep convolutional nets . Using dense sampling , it allows $SEPB$ Learning based approaches have not yet achieved their full potential in optical flow estimation , where their performance still trails heuristic approaches . In this paper , we present a CNN based patch matching approach for optical flow estimation . An important contribution of our approach is a novel thresholded loss for Siamese networks . We demonstrate that our loss performs clearly better than existing losses . It also allows to speed up training by a factor of 2 in our tests . Furthermore , we present a novel way for calculating CNN based features for different image scales , which performs better than existing methods . We also discuss new ways of evaluating the robustness of trained features for the application of patch matching for optical flow $SEPB$ We present an optical flow estimation approach that operates on the full four-dimensional cost volume . This direct approach shares the structural benefits of leading stereo matching pipelines , which are known to yield high accuracy . To this day , such approaches have been considered impractical due to the size of the cost volume . We show that the full four-dimensional cost volume can be constructed in a fraction of a second due to its regularity . We then exploit this regularity further by adapting semi-global matching to the four-dimensional setting . This yields a pipeline that achieves significantly higher accuracy than state-of-the-art optical flow methods while being faster than most . Our approach outperforms all published general-purpose optical flow methods on both Sintel and KITTI 2015
0	At present , there are numerous studies related to failure detectors in distributed systems #CITE# - #CITE# . $SEP$ The failure detector is one of the fundamental components for maintaining high availability of Vehicular Ad-hoc Networks . However , the dynamic nature of VANETs caused by the high mobility of vehicles and communication link failures has a serious impact on the performance of failure detection . Therefore , it is very meaningful to design a suitable failure detector that can deal with the dynamic nature of VANETs well . In this paper , we propose a hierarchical failure detector based on the architecture of VANETs . This failure detector can adapt to the dynamic network conditions and meet the different Quality of Service requirements of multiple applications in VANETs . Different from existing failure detectors , we propose a failure detector that employs a detection-result sharing mechanism and groups the nodes according to the architecture of VANETs . We evaluate our proposed failure detector by using NS2 and GT-ITM to simulate the work environment of VANETs . The experimental result shows that our proposed failure detector can improve the detection time by at most 45 % and the detection accuracy by at most 25 % under similar detection overhead . INDEX TERMS VANETs , hierarchical failure detection , architecture $SEP$ Abstract-Failure detection plays a central role in the engineering of distributed systems . Furthermore , many applications have timing constraints and require failure detectors that provide quality of service with some quantitative timeliness guarantees . Therefore , they need failure detectors that are fast and accurate .We introduce the Two Windows Failure Detector , an algorithm that provides QoS and is able to react to sudden changes in network conditions , a property that currently existing algorithms do not satisfy .We ran tests on real traces and compared the 2W-FD to state-of-the-art algorithms . Our results show that our algorithm presents the best performance in terms of speed and accuracy in unstable scenarios . $FULLTEXT$ Distributed systems should provide reliable and continuous services despite the failures of some $SEPB$ Unreliable failure detectors are a basic building block of reliable distributed systems . Failure detectors are used to monitor processes of any application and provide process state information . This work presents an Internet Failure Detector Service for processes running in the Internet on multiple autonomous systems . The failure detection service is adaptive , and can be easily integrated into applications that require configurable QoS guarantees . The service is based on monitors which are capable of providing global process state information through a SNMP MIB . Monitors at different networks communicate across the Internet using Web Services . The system was implemented and evaluated for monitored processes running both on single LAN and on PlanetLab . Experimental results are presented , showing the performance of the
2	Conventional methods attempts to propose mathematical algorithms of optical flow estimation such as DeepFlow #CITE# and EpicFlow #CITE# by matching features of two frames . $SEP$ Optical flow estimation is an important yet challenging problem in the field of video analytics . The features of different semantics levels/layers of a convolutional neural network can provide information of different granularity . To exploit such flexible and comprehensive information , we propose a semi-supervised Feature Pyramidal Correlation and Residual Reconstruction Network for optical flow estimation from frame pairs . It consists of two main modules : pyramid correlation mapping and residual reconstruction . The pyramid correlation mapping module takes advantage of the multi-scale correlations of global/local patches by aggregating features of different scales to form a multi-level cost volume . The residual reconstruction module aims to reconstruct the sub-band highfrequency residuals of finer optical flow in each stage . Based on the pyramid correlation mapping , we further propose a correlation-warping-normalization module to efficiently exploit the correlation dependency . Experiment results show that the proposed scheme achieves the state-of-the-art performance , with improvement by 0 .80 , 1 .15 and 0 .10 in terms of average end-point error against competing baseline methods -FlowNet2 , LiteFlowNet and PWC-Net on the Final pass of Sintel dataset , respectively . $SEP$ Optical flow computation is a key component in many computer vision systems designed for tasks such as action detection or activity recognition . However , despite several major advances over the last decade , handling large displacement in optical flow remains an open problem .Inspired by the large displacement optical flow of Brox & Malik , our approach , termed DeepFlow , blends a matching algorithm with a variational approach for optical flow . We propose a descriptor matching algorithm , tailored to the optical flow problem , that allows to boost performance on fast motions . The matching algorithm builds upon a multi-stage architecture with 6 layers , interleaving convolutions and max-pooling , a construction akin to deep convolutional nets . Using dense sampling , it allows $SEPB$ We propose a novel approach for optical flow estima tion , targeted at large displacements with significant oc clusions . It consists of two steps : i ) dense matching by edge-preserving interpolation from a sparse set of matches ; ii ) variational energy minimization initialized with the dense matches . The sparse-to-dense interpolation relies on an appropriate choice of the distance , namely an edge aware geodesic distance . This distance is tailored to han dle occlusions and motion boundaries -two common and difficult issues for optical flow computation . We also pro pose an approximation scheme for the geodesic distance to allow fast computation without loss of performance . Sub sequent to the dense interpolation step , standard one-level variational energy minimization is carried out on
0	Its main advantage is to estimate link expiration time #CITE# , #CITE# in order to improve routing performances . Authors of #CITE# and #CITE# proposed two different methods for mobility prediction . $SEP$ Abstract-Mobility prediction allows estimating the stability of paths in a mobile wireless Ad Hoc networks . Identifying stable paths helps to improve routing by reducing the overhead and the number of connection interruptions . In this paper , we introduce a neural network based method for mobility prediction in Ad Hoc networks . This method consists of a multi-layer and recurrent neural network using back propagation through time algorithm for training . $SEP$ Abstract-A predictive model-based mobility tracking method , called dead reckoning , is proposed for mobile ad hoc networks . It disseminates both location and movement models of mobile nodes in the network so that every node is able to predict or track the movement of every other node with a very low overhead . This technique is applied to solve the unicast routing problem by modeling link costs using both link lifetime and geographic distance from the destination to the link egress point . This method presents a much superior routing performance compared to either DSR or AODV , two other popular routing protocols , particularly in terms of delivery fraction and routing load . $FULLTEXT$ Routing protocols in mobile ad hoc networks must adapt to frequently changing $SEPB$ Abstract-A predictive model-based mobility tracking method , called dead reckoning , is proposed for mobile ad hoc networks . It disseminates both location and movement models of mobile nodes in the network so that every node is able to predict or track the movement of every other node with a very low overhead . This technique is applied to solve the unicast routing problem by modeling link costs using both link lifetime and geographic distance from the destination to the link egress point . This method presents a much superior routing performance compared to either DSR or AODV , two other popular routing protocols , particularly in terms of delivery fraction and routing load . $FULLTEXT$ Routing protocols in mobile ad hoc networks must adapt to frequently changing
0	All the aforementioned works #CITE# assume perfect and instantaneous channel state information at the transmitter side and they additionally involve some optimization of the parameters of the transmitted improper signal . $SEP$ This paper studies the performance of improper Gaussian signaling over a 2-user Rayleigh single-input single-output interference channel , treating interference as noise . We assume that the receivers have perfect channel state information , while the transmitters have access to only statistical CSI . Under these assumptions , we consider a signaling scheme , which we refer to as proper/improper Gaussian signaling or PGS/IGS , where at most one user may employ IGS . For the Rayleigh fading channel model , we characterize the statistical distribution of the signal-to-interference-plus-noise ratio at each receiver and derive closed-form expressions for the ergodic rates . By adapting the powers , we characterize the Pareto boundary of the ergodic rate region for the 2-user fading IC . The ergodic transmission rates can be attained using fixed-rate codebooks and no optimization is involved . Our results show that , in the moderate and strong interference regimes , the proposed PGS/IGS scheme improves the performance with respect to the PGS scheme . Additionally , we numerically compute the ergodic rate region of the full IGS scheme when both users can employ IGS and their transmission parameters are optimized by an exhaustive search . Our results suggest $SEP$ It has been conjectured by Høst-Madsen and Nosratinia that complex Gaussian interference channels with constant channel coefficients have only one degree-of-freedom regardless of the number of users . While several examples are known of constant channels that achieve more than 1 degree of freedom , these special cases only span a subset of measure zero . In other words , for almost all channel coefficient values , it is not known if more than 1 degree-of-freedom is achievable . In this paper , we settle the Høst-Madsen-Nosratinia conjecture in the negative . We show that at least 1 .2 degrees-of-freedom are achievable for all values of complex channel coefficients except for a subset of measure zero . For the class of linear beamforming and interference alignment schemes considered $SEPB$ In this letter we study the potential benefits of improper signaling for a secondary user in underlay cognitive radio networks . We consider a basic yet illustrative scenario in which the primary user always transmit proper Gaussian signals and has a minimum rate constraint . After parameterizing the SU transmit signal in terms of its power and circularity coefficient , we prove that the SU improves its rate by transmitting improper signals only when the ratio of the squared modulus between the SU-PU interference link and the SU direct link exceeds a given threshold . As a by-product of this analysis , we obtain the optimal circularity coefficient that must be used by the SU depending on its power budget . Some simulation results show that the SU $SEPB$ Abstract-Recent results have elucidated the benefits of using improper Gaussian signaling as compared with conventional proper Gaussian signaling in terms of achievable rate for interference-limited conditions . This paper exploits majorization theory tools to formally quantify the gains of IGS along with widely linear transceivers for multiple-input multipleoutput systems in interference-limited scenarios . The MIMO point-to-point channel with interference is analyzed , assuming that received interference can be either proper or improper , and we demonstrate that the use of the optimal IGS when received interference is improper strictly outperforms the use of the optimal PGS when interference is proper . Then , these results are extended to two practical situations . First , the MIMO Z-interference channel is investigated , where a trade-off arises : with IGS $SEPB$ Abstract-This paper studies the achievable rates of Gaussian interference channels with additive white Gaussian noise , when improper or circularly asymmetric complex Gaussian signaling is applied . For the Gaussian multiple-input multiple-output interference channel with the interference treated as Gaussian noise , we show that the user 's achievable rate can be expressed as a summation of the rate achievable by the conventional proper or circularly symmetric complex Gaussian signaling in terms of the users ' transmit covariance matrices , and an additional term , which is a function of both the users ' transmit covariance and pseudo-covariance matrices . The additional degrees of freedom in the pseudocovariance matrix , which is conventionally set to be zero for the case of proper Gaussian signaling , provide an opportunity $SEPB$ Abstract-Wireless nodes in future communication systems need to overcome three barriers when compared to their transitional counterparts , namely , to support significantly higher data rates , have long-lasting energy supplies , and remain fully operational in interference-limited heterogeneous networks . This could be partially achieved by providing three promising features , which are radio frequency energy harvesting , improper Gaussian signaling , and operating in full-duplex communication mode , ie , transmit and receive at the same time within the same frequency band . In this paper , we consider these aspects jointly in a multi-antenna heterogeneous two-tier network . In this network , the users in the femtocell share the scarce resources with the cellular users in the macro-cell and have to cope with the interference $SEPB$ Improper Gaussian signaling has been used as an effective interference management tool in interference limited systems . Improper Gaussian signals are correlated with their complex conjugates . In this paper , we investigate the optimality of IGS from an energy efficiency perspective . First , we obtain closed form optimality conditions for IGS . We then leverage these conditions to devise a bisection method that finds the optimal transmission parameters . Our results show that IGS can improve the EE of an underlay cognitive radio system . $FULLTEXT$ Energy consumption is always a critical parameter of modern wireless communication systems , where the power has to be used efficiently . Moreover , ever-increasing demand for data rate makes it inevitable to employ resources efficiently . A way to $SEPB$ This paper investigates the energy efficiency of improper Gaussian signaling in a K-user interference channel . IGS allows unequal variances and/or correlation between the real and imaginary parts , and it has recently been shown to be advantageous in various interference-limited scenarios . In this paper , we propose an energy-efficient IGS design for the K-user IC , which is based on a separate optimization of the powers and complementary variances of the users . We compare the EE region achieved by the proposed scheme with that achieved by conventional proper signaling and show that IGS can significantly improve the EE region . $FULLTEXT$ Energy-aware techniques have become more and more important in the design of modern wireless communication systems . For instance , energy efficiency is among
0	The upcoming 5G wireless architectures pose stringent requirements in terms of latency #CITE# and motivate the placement of content near the user #CITE# . Introducing caches at the network edge is an appealing solution since the cost of network equipment substantially exceeds the cost of installing a cache #CITE# . There has recently been a large body of work on cache optimization for wireless systems , cf . #CITE# - #CITE# . $SEP$ Abstract-This paper addresses a fundamental limitation for the adoption of caching for wireless access networks due to small population sizes . This shortcoming is due to two main challenges : making timely estimates of varying content popularity and inferring popular content from small samples . We propose a framework which alleviates such limitations . To timely estimate varying popularity in a context of a single cache we propose an Age-Based Threshold policy which caches all contents requested more times than a threshold N , where τ is the content age . We show that ABT is asymptotically hit rate optimal in the many contents regime , which allows us to obtain the first characterization of the optimal performance of a caching system in a dynamic context . We then address small sample sizes focusing on L local caches and one global cache . On the one hand we show that the global cache learns L times faster by aggregating all requests from local caches , which improves hit rates . On the other hand , aggregation washes out local characteristics of correlated traffic which penalizes hit rate . This motivates coordination mechanisms which combine global learning of popularity scores in $SEP$ Abstract-What will 5G be ? What it will not be is an incremental advance on 4G . The previous four generations of cellular technology have each been a major paradigm shift that has broken backwards compatibility . And indeed , 5G will need to be a paradigm shift that includes very high carrier frequencies with massive bandwidths , extreme base station and device densities and unprecedented numbers of antennas . But unlike the previous four generations , it will also be highly integrative : tying any new 5G air interface and spectrum together with LTE and WiFi to provide universal high-rate coverage and a seamless user experience . To support this , the core network will also have to reach unprecedented levels of flexibility and intelligence , spectrum $SEPB$ Abstract-An information-centric network should realize significant economies by exploiting a favourable memory-bandwidth tradeoff : it is cheaper to store copies of popular content close to users than to fetch them repeatedly over the Internet . We evaluate this tradeoff for some simple cache network structures under realistic assumptions concerning the size of the content catalogue and its popularity distribution . Derived cost formulas reveal the relative impact of various cost , traffic and capacity parameters , allowing an appraisal of possible future network architectures . Our results suggest it probably makes more sense to envisage the future Internet as a loosely interconnected set of local data centers than a network like today 's with routers augmented by limited capacity content stores . $FULLTEXT$ It has become a commonplace $SEPB$ Abstract-We suggest a novel approach to handle the ongoing explosive increase in the demand for video content in wireless/mobile devices . We envision femtocell-like base stations , which we call helpers , with weak backhaul links but large storage capacity . These helpers form a wireless distributed caching network that assists the macro base station by handling requests of popular files that have been cached . Due to the short distances between helpers and requesting devices , the transmission of cached files can be done very efficiently .A key question for such a system is the wireless distributed caching problem , ie , which files should be cached by which helpers . If every mobile device has only access to a exactly one helper , then clearly each
2	Such 2 .5D data can be represented as multiple channel images , and processed by 2D CNNs #CITE# . Wu et al #CITE# in a pioneering paper proposed to extend 2D CNNs to process 3D data directly . $SEP$ Building discriminative representations for 3D data has been an important task in computer graphics and computer vision research . Convolutional Neural Networks have shown to operate on 2D images with great success for a variety of tasks . Lifting convolution operators to 3D seems like a plausible and promising next step . Unfortunately , the computational complexity of 3D CNNs grows cubically with respect to voxel resolution . Moreover , since most 3D geometry representations are boundary based , occupied regions do not increase proportionately with the size of the discretization , resulting in wasted computation . In this work , we represent 3D spaces as volumetric fields , and propose a novel design that employs field probing filters to efficiently extract features from them . Each field probing filter is a set of probing points -sensors that perceive the space . Our learning algorithm optimizes not only the weights associated with the probing points , but also their locations , which deforms the shape of the probing filters and adaptively distributes them in 3D space . The optimized probing points sense the 3D space `` intelligently '' , rather than operating blindly over the entire domain . We show $SEP$ Abstract . In this paper we study the problem of object detection for RGB-D images using semantically rich image and depth features . We propose a new geocentric embedding for depth images that encodes height above ground and angle with gravity for each pixel in addition to the horizontal disparity . We demonstrate that this geocentric embedding works better than using raw depth images for learning feature representations with convolutional neural networks . Our final object detection system achieves an average precision of 37 .3 % , which is a 56 % relative improvement over existing methods . We then focus on the task of instance segmentation where we label pixels belonging to object instances found by our detector . For this task , we propose a decision $SEPB$ Robust object recognition is a crucial ingredient of many , if not all , real-world robotics applications . This paper leverages recent progress on Convolutional Neural Networks and proposes a novel RGB-D architecture for object recognition . Our architecture is composed of two separate CNN processing streams -one for each modality -which are consecutively combined with a late fusion network . We focus on learning with imperfect sensor data , a typical problem in real-world robotics tasks . For accurate learning , we introduce a multi-stage training methodology and two crucial ingredients for handling depth data with CNNs . The first , an effective encoding of depth information for CNNs that enables learning without the need for large depth datasets . The second , a data augmentation scheme $SEPB$ 3D shape is a crucial but heavily underutilized cue in today 's computer vision systems , mostly due to the lack of a good generic shape representation . With the recent availability of inexpensive 2 .5D depth sensors , it is becoming increasingly important to have a powerful 3D shape representation in the loop . Apart from category recognition , recovering full 3D shapes from viewbased 2 .5D depth maps is also a critical part of visual understanding . To this end , we propose to represent a geometric 3D shape as a probability distribution of binary variables on a 3D voxel grid , using a Convolutional Deep Belief Network . Our model , 3D ShapeNets , learns the distribution of complex 3D shapes across different object categories
2	The full search algorithm #CITE# is the simplest block-matching algorithm that can deliver the optimal estimation solution regarding the minimal matching error as it checks all candidates one at a time . $SEP$ Motion estimation is one of the major problems in developing video coding applications . Among all motion estimation approaches , Block matching algorithms are the most popular methods due to their effectiveness and simplicity for both software and hardware implementations . A BM approach assumes that the movement of pixels within a defined region of the current frame can be modeled as a translation of pixels contained in the previous frame . In this procedure , the motion vector is obtained by minimizing the sum of absolute differences produced by the MB of the current frame over a determined search window from the previous frame . The SAD evaluation is computationally expensive and represents the most consuming operation in the BM process . The most straightforward BM method is the full search algorithm which finds the most accurate motion vector , calculating exhaustively the SAD values for all elements of the search window . Over this decade , several fast BM algorithms have been proposed to reduce the number of SAD operations by calculating only a fixed subset of search locations at the price of a poor accuracy . In this paper , a new algorithm based on Differential Evolution $SEP$ of small blocks with minimum mean square error is presented . An efficient algorithm for searching the direction of displacement has been described . The results of applying the technique to two sets of images are presented which show 8-10 dB improvement in interframe variance reduction due to motion compensation . The motion compensation is applied for analysis and design of a hybrid coding scheme and the results show a factor of two gain at low bit rates . $FULLTEXT$ LARGE number of image transmission and storage applications , eg , teleconferencing , videotelephone , television and satellite image transmission , medical imaging for computer aided tomography and angiocardiography , etc . , contain images of moving objects . The motion captured in such a multiframe sequence of
0	IA can achieve the maximum degrees of freedom in a K-user interference channel #CITE# . $SEP$ Abstract-Interference Alignment is a precoding technique that achieves the maximum multiplexing gain over an interference channel when perfect Channel State Information is available at transmitters . Most of IA researches assume channels remain static for a period but vary independently from block to block , which neglects the temporal correlation of timevariant channels . In this paper , we propose a novel scheme that transmitters utilize a number of samples to predict CSI instead of obtaining CSI through feedback all the time . By making full use of the correlation of time-variant channels , our proposed scheme is able to reduce overhead and compensate for the feedback error due to low feedback Signal-Noise Ratio . Furthermore , we find an optimized prediction horizon achieving the maximum sum rate of our system , which is the best tradeoff between prediction error and overhead length . Simulation results verify that our scheme outperforms the traditional nonpredictive feedback scheme . $SEP$ Abstract-For the fully connected K user wireless interference channel where the channel coefficients are time-varying and are drawn from a continuous distribution , the sum capacity is characterized as C = K 2 log + o ) . Thus , the K user time-varying interference channel almost surely has K=2 degrees of freedom . Achievability is based on the idea of interference alignment . Examples are also provided of fully connected K user interference channels with constant coefficients where the capacity is exactly achieved by interference alignment at all SNR values .Index Terms-Capacity , degrees of freedom , interference alignment , interference channel , multiple-input-multiple-output , multiplexing . $FULLTEXT$
0	When network resources were still scarce in early years , workflow modules were often mapped to homogeneous systems such as multiprocessors #CITE# . $SEP$ Abstract . Next-generation computational sciences feature large-scale workflows of many computing modules that must be deployed and executed in distributed network environments . With limited computing resources , it is often unavoidable to map multiple workflow modules to the same computer node with possible concurrent module execution , whose scheduling may significantly affect the workflow 's end-to-end performance in the network . We formulate this on-node workflow scheduling problem as an optimization problem and prove it to be NPcomplete . We then conduct a deep investigation into workflow execution dynamics and propose a Critical Path-based Priority Scheduling algorithm to achieve Minimum End-to-end Delay under a given workflow mapping scheme . The performance superiority of the proposed CPPS algorithm is illustrated by extensive simulation results in comparison with a traditional fair-share scheduling policy and is further verified by proof-of-concept experiments based on a real-life scientific workflow for climate modeling deployed and executed in a testbed network . $SEP$ Abstract-We have developed a genetic algorithm approach to the problem of task scheduling for multiprocessor systems . Our approach requires minimal problem specific information and no problem specific operators or repair mechanisms . Key features of our system include a flexible , adaptive problem representation and an incremental fitness function . Comparison with traditional scheduling methods indicates that the GA is competitive in terms of solution quality if it has sufficient resources to perform its search . Studies in a nonstationary environment show the GA is able to automatically adapt to changing targets . $FULLTEXT$ T HE problem of scheduling a set of dependent or independent tasks to be processed in a parallel fashion is a well-studied area . Examples of such problems include the scheduling of jobs $SEPB$ In this paper , we propose a static scheduling algorithm for allocating task graphs to fullyconnected multiprocessors . We discuss six recently reported scheduling algorithms and show that they possess one drawback or the other which can lead to poor performance . The proposed algorithm , which is called the Dynamic Critical-Path scheduling algorithm , is different from the previously proposed algorithms in a number of ways . First , it determines the critical path of the task graph and selects the next node to be scheduled in a dynamic fashion . Second , it rearranges the schedule on each processor dynamically in the sense that the positions of the nodes in the partial schedules are not fixed until all nodes have been considered . Third , it
1	Since the discriminative parts , such as head and body , are crucial for fine-grained image classification , previous works #CITE# , #CITE# , #CITE# select discriminative parts from the candidate image patches produced by the bottom-up process like selective search #CITE# . $SEP$ Abstract-Fine-grained image classification is to recognize hundreds of subcategories belonging to the same basic-level category , such as 200 subcategories belonging to bird , and highly challenging due to large variance in same subcategory and small variance among different subcategories . Existing methods generally find where the object or its parts are and then discriminate which subcategory the image belongs to . However , they mainly have two limitations : Relying on object or parts annotations which are heavily labor consuming . Ignoring the spatial relationship between the object and its parts as well as among these parts , both of which are significantly helpful for finding discriminative parts . Therefore , this paper proposes the object-part attention driven discriminative localization approach for weakly supervised fine-grained image classification , and the main novelties are : Object-part attention model integrates two level attentions : object-level attention localizes objects of images , and part-level attention selects discriminative parts of object . Both are jointly employed to learn multi-view and multi-scale features to enhance their mutual promotion . Object-part spatial model combines two spatial constraints : object spatial constraint ensures selected parts highly representative , and part spatial constraint eliminates redundancy and enhances $SEP$ We propose an architecture for fine-grained visual categorization that approaches expert human performance in the classification of bird species . Our architecture first computes an estimate of the object 's pose ; this is used to compute local image features which are , in turn , used for classification . The features are computed by applying deep convolutional nets to image patches that are located and normalized by the pose . We perform an empirical study of a number of pose normalization schemes , including an investigation of higher order geometric warping functions . We propose a novel graph-based clustering algorithm for learning a compact pose normalization space . We perform a detailed investigation of stateof-the-art deep convolutional feature implementations and finetuning feature learning for fine-grained classification . $SEPB$ Recognizing objects in fine-grained domains can be extremely challenging due to the subtle differences between subcategories . Discriminative markings are often highly localized , leading traditional object recognition approaches to struggle with the large pose variation often present in these domains . Pose-normalization seeks to align training exemplars , either piecewise by part or globally for the whole object , effectively factoring out differences in pose and in viewing angle . Prior approaches relied on computationally-expensive filter ensembles for part localization and required extensive supervision . This paper proposes two pose-normalized descriptors based on computationally-efficient deformable part models . The first leverages the semantics inherent in strongly-supervised DPM parts . The second exploits weak semantic annotations to learn cross-component correspondences , computing pose-normalized descriptors from the latent parts
2	EEP learning using convolutional and fully connected neural networks has achieved unprecedented accuracy on many modern artificial intelligence applications , such as image , voice , and DNA pattern detection and recognition #CITE# . $SEP$ > This work has been submitted to the IEEE TVLSI for possible publication . 1  Abstract-A memristive neural network computing engine based on CMOS-compatible charge-trap transistor is proposed in this paper . CTT devices are used as analog multipliers . Compared to digital multipliers , CTT-based analog multipliers show dramatic area and power reduction . The proposed memristive computing engine is composed of a scalable CTT multiplier array and energy efficient analog-digital interfaces . Through implementing the sequential analog fabric , the engine 's mixed-signal interfaces are simplified and hardware overhead remains constant regardless of the size of the array . A proof-of-concept 784 by 784 CTT computing engine is implemented using TSMC 28nm CMOS technology and occupied 0 .68mm 2 . It achieves 69 .9 TOPS with 500 MHz clock frequency and consumes 14 .8 mW . As an example , we utilize this computing engine to address a classic pattern recognition problem − classifying handwritten digits on MNIST database − and obtained a performance comparable to state-of-the-art fully connected neural networks using 8-bit fixed-point resolution . $SEP$ We trained a large , deep convolutional neural network to classify the 1 .2 million high-resolution images in the ImageNet LSVRC-2010 contest into the 1000 different classes . On the test data , we achieved top-1 and top-5 error rates of 37 .5 % and 17 .0 % , respectively , which is considerably better than the previous state-of-the-art . The neural network , which has 60 million parameters and 650 ,000 neurons , consists of five convolutional layers , some of which are followed by max-pooling layers , and three fully connected layers with a final 1000-way softmax . To make training faster , we used nonsaturating neurons and a very efficient GPU implementation of the convolution operation . To reduce overfitting in the fully connected layers $SEPB$ In this work we investigate the effect of the convolutional network depth on its accuracy in the large-scale image recognition setting . Our main contribution is a thorough evaluation of networks of increasing depth , which shows that a significant improvement on the prior-art configurations can be achieved by pushing the depth to 16-19 weight layers . These findings were the basis of our ImageNet Challenge 2014 submission , where our team secured the first and the second places in the localisation and classification tracks respectively . We also show that our representations generalise well to other datasets , where they achieve the stateof-the-art results . Importantly , we have made our two best-performing ConvNet models publicly available to facilitate further research on the use of deep visual $SEPB$ We propose a deep convolutional neural network architecture codenamed Inception that achieves the new state of the art for classification and detection in the Im-ageNet Large-Scale Visual Recognition Challenge 2014 . The main hallmark of this architecture is the improved utilization of the computing resources inside the network . By a carefully crafted design , we increased the depth and width of the network while keeping the computational budget constant . To optimize quality , the architectural decisions were based on the Hebbian principle and the intuition of multi-scale processing . One particular incarnation used in our submission for ILSVRC14 is called GoogLeNet , a 22 layers deep network , the quality of which is assessed in the context of classification and detection .1 978-1-4673-6964-0/15/ $ 31 .00 $SEPB$ Deeper neural networks are more difficult to train . We present a residual learning framework to ease the training of networks that are substantially deeper than those used previously . We explicitly reformulate the layers as learning residual functions with reference to the layer inputs , instead of learning unreferenced functions . We provide comprehensive empirical evidence showing that these residual networks are easier to optimize , and can gain accuracy from considerably increased depth . On the ImageNet dataset we evaluate residual nets with a depth of up to 152 layers-8× deeper than VGG nets but still having lower complexity . An ensemble of these residual nets achieves 3 .57 % error on the ImageNet test set . This result won the 1st place on the ILSVRC $SEPB$ Abstract : Deep convolutional neural networks are widely used in modern artificial intelligence and smart vision systems but also limited by computation latency , throughput , and energy efficiency on a resource-limited scenario , such as mobile devices , internet of things , unmanned aerial vehicles , and so on . A hardware streaming architecture is proposed to accelerate convolution and pooling computations for state-of-the-art deep CNNs . It is optimized for energy efficiency by maximizing local data reuse to reduce off-chip DRAM data access . In addition , image and feature decomposition techniques are introduced to optimize memory access pattern for an arbitrary size of image and number of features within limited on-chip SRAM capacity . A prototype accelerator was implemented in TSMC 65 nm CMOS technology $SEPB$ Abstract-State-of-the-art deep neural networks have hundreds of millions of connections and are both computationally and memory intensive , making them difficult to deploy on embedded systems with limited hardware resources and power budgets . While custom hardware helps the computation , fetching weights from DRAM is two orders of magnitude more expensive than ALU operations , and dominates the required power .Previously proposed 'Deep Compression ' makes it possible to fit large DNNs fully in on-chip SRAM . This compression is achieved by pruning the redundant connections and having multiple connections share the same weight . We propose an energy efficient inference engine that performs inference on this compressed network model and accelerates the resulting sparse matrix-vector multiplication with weight sharing . Going from DRAM to SRAM gives
2	To address the overfitting problem , Chawla et al #CITE# introduced a method , called SMOTE , to generate new instances by linear interpolation between closely lying minority class samples . Safe-level SMOTE #CITE# carefully generates synthetic samples in the so-called safe regions , where the majority and minority class regions are not overlapping . The combination of undersampling and oversampling procedures #CITE# , #CITE# , #CITE# to balance the training data have also shown to perform well . $SEP$ Class imbalance is a common problem in the case of real-world object detection and classification tasks . Data of some classes are abundant , making them an overrepresented majority , and data of other classes are scarce , making them an underrepresented minority . This imbalance makes it challenging for a classifier to appropriately learn the discriminating boundaries of the majority and minority classes . In this paper , we propose a cost-sensitive deep neural network , which can automatically learn robust feature representations for both the majority and minority classes . During training , our learning procedure jointly optimizes the class-dependent costs and the neural network parameters . The proposed approach is applicable to both binary and multiclass problems without any modification . Moreover , as opposed to data-level approaches , we do not alter the original data distribution , which results in a lower computational cost during the training process . We report the results of our experiments on six major image classification data sets and show that the proposed approach significantly outperforms the baseline algorithms . Comparisons with popular data sampling techniques and CoSen classifiers demonstrate the superior performance of our proposed method . Index Terms-Convolutional neural $SEP$ An approach to the construction of classifiers from imbalanced datasets is described . A dataset is imbalanced if the classification categories are not approximately equally represented . Often real-world data sets are predominately composed of `` normal '' examples with only a small percentage of `` abnormal '' or `` interesting '' examples . It is also the case that the cost of misclassifying an abnormal example as a normal example is often much higher than the cost of the reverse error . Under-sampling of the majority class has been proposed as a good means of increasing the sensitivity of a classifier to the minority class . This paper shows that a combination of our method of over-sampling the minority class and under-sampling the majority class can achieve $SEPB$ Abstract . The class imbalanced problem occurs in various disciplines when one of target classes has a tiny number of instances comparing to other classes . A typical classifier normally ignores or neglects to detect a minority class due to the small number of class instances . SMOTE is one of over-sampling techniques that remedies this situation . It generates minority instances within the overlapping regions . However , SMOTE randomly synthesizes the minority instances along a line joining a minority instance and its selected nearest neighbours , ignoring nearby majority instances . Our technique called SafeLevel-SMOTE carefully samples minority instances along the same line with different weight degree , called safe level . The safe level computes by using nearest neighbour minority instances . By synthesizing the $SEPB$ Abstract . In classification , when the distribution of the training data among classes is uneven , the learning algorithm is generally dominated by the feature of the majority classes . The features in the minority classes are normally difficult to be fully recognized . In this paper , a method is proposed to enhance the classification accuracy for the minority classes . The proposed method combines Synthetic Minority Over-sampling Technique and Complementary Neural Network to handle the problem of classifying imbalanced data . In order to demonstrate that the proposed technique can assist classification of imbalanced data , several classification algorithms have been used . They are Artificial Neural Network , kNearest Neighbor and Support Vector Machine . The benchmark data sets with various ratios between the
2	Rapid development of DNNs has promoted various applications such as image classification #CITE# , object detection #CITE# and scene detection Netzer et al , 2011] . $SEP$ Today a canonical approach to reduce the computation cost of Deep Neural Networks is to pre-define an over-parameterized model before training to guarantee the learning capacity , and then prune unimportant learning units during training to improve model compactness . We argue it is unnecessary to introduce redundancy at the beginning of the training but then reduce redundancy for the ultimate inference model . In this paper , we propose a Continuous Growth and Pruning scheme to minimize the redundancy from the beginning . CGaP starts the training from a small network seed , then expands the model continuously by reinforcing important learning units , and finally prunes the network to obtain a compact and accurate model . As the growth phase favors important learning units , CGaP provides a clear learning purpose to the pruning phase . Experimental results on representative datasets and DNN architectures demonstrate that CGaP outperforms previous pruning-only approaches that deal with pre-defined structures . For VGG-19 on CIFAR-100 and SVHN datasets , CGaP reduces the number of parameters by 78 .9 % and 85 .8 % , FLOPs by 53 .2 % and 74 .2 % , respectively ; For ResNet-110 On CIFAR-10 , CGaP $SEP$ We introduce a method to train Quantized Neural Networks -neural networks with extremely low precision weights and activations , at run-time . At traintime the quantized weights and activations are used for computing the parameter gradients . During the forward pass , QNNs drastically reduce memory size and accesses , and replace most arithmetic operations with bit-wise operations . As a result , power consumption is expected to be drastically reduced . We trained QNNs over the MNIST , CIFAR-10 , SVHN and ImageNet datasets . The resulting QNNs achieve prediction accuracy comparable to their 32-bit counterparts . For example , our quantized version of AlexNet with 1-bit weights and 2-bit activations achieves 51 % top-1 accuracy . Moreover , we quantize the parameter gradients to 6-bits as $SEPB$ We propose an efficient and unified framework , namely ThiNet , to $FULLTEXT$ In the past few years , we have witnessed a rapid development of deep neural networks in the field of computer vision , from basic image classification tasks such as the ImageNet recognition challenge , to some more advanced applications , eg , object detection , semantic segmentation , image captioning and many others . Deep neural networks have achieved state-of-the-art performance in these fields compared with traditional methods based on manually designed visual features .In spite of its great success , a typical deep model is hard to be deployed on resource constrained devices , eg , mobile phones or embedded gadgets . A resource constrained scenario means a computing task must be accomplished $SEPB$ We propose an efficient and unified framework , namely ThiNet , to $FULLTEXT$ In the past few years , we have witnessed a rapid development of deep neural networks in the field of computer vision , from basic image classification tasks such as the ImageNet recognition challenge , to some more advanced applications , eg , object detection , semantic segmentation , image captioning and many others . Deep neural networks have achieved state-of-the-art performance in these fields compared with traditional methods based on manually designed visual features .In spite of its great success , a typical deep model is hard to be deployed on resource constrained devices , eg , mobile phones or embedded gadgets . A resource constrained scenario means a computing task must be accomplished
0	Consistently with #CITE# , we have neglected diffusive transport in the micromixer problem . $SEP$ A material-based , ie , Lagrangian , methodology for exact integration of flux by volume-preserving flows through a surface has been developed recently in Karrasch , SIAM J . Appl . Math . , 76 , pp . 1178-1190 . In the present paper , we first generalize this framework to general compressible flows , thereby solving the donating region problem in full generality . Second , we demonstrate the efficacy of this approach on a slightly idealized version of a classic two-dimensional mixing problem : transport in a cross-channel micromixer , as considered recently in $SEP$ Mixing between two different miscible fluids with a mutual interface must be initiated by fluid transporting across this fluid interface , caused for example by applying an unsteady velocity agitation . In general , there is no necessity for this physical flow barrier between the fluids to be associated with extremal or exponential attraction as might be revealed by applying Lagrangian coherent structures , finite-time Lyapunov exponents or other methods on the fluid velocity . It is shown that streaklines are key to understanding the breaking of the interface under velocity agitations , and a theory for locating the relevant streaklines is presented . Simulations of streaklines in a cross-channel mixer and a perturbed Kirchhoff 's elliptic vortex are quantitatively compared to the theoretical results . A methodology
2	Constrained decoding Prior work explored methods to apply lexical constraints to a Neural Machine Translation decoder . $SEP$ Lexically-constrained sequence decoding allows for explicit positive or negative phrasebased constraints to be placed on target output strings in generation tasks such as machine translation or monolingual text rewriting . We describe vectorized dynamic beam allocation , which extends work in lexically-constrained decoding to work with batching , leading to a five-fold improvement in throughput when working with positive constraints . Faster decoding enables faster exploration of constraint strategies : we illustrate this via data augmentation experiments with a monolingual rewriter applied to the tasks of natural language inference , question answering and machine translation , showing improvements in all three . $SEP$ We present Grid Beam Search , an algorithm which extends beam search to allow the inclusion of pre-specified lexical constraints . The algorithm can be used with any model that generates a sequenceŷ = { y 0 . . . y T } , by maximizing p = t p . Lexical constraints take the form of phrases or words that must be present in the output sequence . This is a very general way to incorporate additional knowledge into a model 's output without requiring any modification of the model parameters or training data . We demonstrate the feasibility and flexibility of Lexically Constrained Decoding by conducting experiments on Neural Interactive-Predictive Translation , as well as Domain Adaptation for Neural Machine Translation . Experiments show that GBS $SEPB$ Existing image captioning models do not generalize well to out-of-domain images containing novel scenes or objects . This limitation severely hinders the use of these models in real world applications dealing with images in the wild . We address this problem using a flexible approach that enables existing deep captioning architectures to take advantage of image taggers at test time , without re-training . Our method uses constrained beam search to force the inclusion of selected tag words in the output , and fixed , pretrained word embeddings to facilitate vocabulary expansion to previously unseen tag words . Using this approach we achieve state of the art results for out-of-domain captioning on MSCOCO . Perhaps surprisingly , our results significantly outperform approaches that incorporate the same tag predictions
1	With recent progress in deep learning , large labeled training datasets are becoming increasingly important #CITE# . $SEP$ In this work , we investigate semi-supervised learning for image classification using adversarial training . Previous results have illustrated that generative adversarial networks can be used for multiple purposes . Triple-GAN , which aims to jointly optimize model components by incorporating three players , generates suitable image-label pairs to compensate for the lack of labeled data in SSL with improved benchmark performance . Conversely , Bad GAN , optimizes generation to produce complementary data-label pairs and force a classifier 's decision boundary to lie between data manifolds . Although it generally outperforms Triple-GAN , Bad GAN is highly sensitive to the amount of labeled data used for training . Unifying these two approaches , we present unified-GAN , a novel framework that enables a classifier to simultaneously learn from both good and bad samples through adversarial training . We perform extensive experiments on various datasets and demonstrate that UGAN : 1 ) achieves stateof-the-art performance among other deep generative models , and 2 ) is robust to variations in the amount of labeled data used for training . Recently , generative adversarial networks , have demonstrated their capability in SSL frameworks . GANs are a powerful class of deep generative $SEP$ The explosion of image data on the Internet has the potential to foster more sophisticated and robust models and algorithms to index , retrieve , organize and interact with images and multimedia data . But exactly how such data can be harnessed and organized remains a critical problem . We introduce here a new database called `` ImageNet '' , a largescale ontology of images built upon the backbone of the WordNet structure . ImageNet aims to populate the majority of the 80 ,000 synsets of WordNet with an average of 500-1000 clean and full resolution images . This will result in tens of millions of annotated images organized by the semantic hierarchy of WordNet . This paper offers a detailed analysis of ImageNet in its current state $SEPB$ Abstract-We present a new dataset with the goal of advancing the state-of-the-art in object recognition by placing the question of object recognition in the context of the broader question of scene understanding . This is achieved by gathering images of complex everyday scenes containing common objects in their natural context . Objects are labeled using per-instance segmentations to aid in precise object localization . Our dataset contains photos of 91 objects types that would be easily recognizable by a 4 year old . With a total of 2 .5 million labeled instances in 328k images , the creation of our dataset drew upon extensive crowd worker involvement via novel user interfaces for category detection , instance spotting and instance segmentation . We present a detailed statistical analysis of $SEPB$ Many recent advancements in Computer Vision are attributed to large datasets . Open-source software packages for Machine Learning and inexpensive commodity hardware have reduced the barrier of entry for exploring novel approaches at scale . It is possible to train models over millions of examples within a few days . Although large-scale datasets exist for image understanding , such as ImageNet , there are no comparable size video classification datasets .In this paper , we introduce YouTube-8M , the largest multi-label video classification dataset , composed of ∼8 million videos-500K hours of video-annotated with a vocabulary of 4800 visual entities . To get the videos and their labels , we used a YouTube video annotation system , which labels videos with the main topics in them . While
0	BRDF estimation methods #CITE# solve for an analytical BRDF f by separating out the global lighting E . $SEP$ Figure 1 : Synthetic renderings of highly reflective objects reconstructed with a hand-held commodity RGBD sensor . Note the faithful texture , specular highlights , and global effects such as interreflections and shadows . We present an approach for interactively scanning highly reflective objects with a commodity RGBD sensor . In addition to shape , our approach models the surface light field , encoding scene appearance from all directions . By factoring the surface light field into view-independent and wavelength-independent components , we arrive at a representation that can be robustly estimated with IR-equipped commodity depth sensors , and achieves high quality results . $SEP$ : From 10 photographs of an object taken under varying illumination , we can reconstruct its normals and materials , represented as a material weight map controlling a mixture of fundamental materials . Using this representation we can rerender the object under novel lighting .We describe a suite of techniques for extracting shape and materials from multiple photographs of an object captured from the same viewpoint but with differing illumination . Our method extracts perpixel BRDFs along with 3D shape , under an assumption that the materials can be described as a convex combination of a small number of fundamental materials . We also show examples of interactive lighting and editing operations made possible by our methods , including direct manipulation of material coefficients and material transfer between $SEPB$ Real-world objects are usually composed of a number of different materials that often show subtle changes even within a single material . Photorealistic rendering of such objects requires accurate measurements of the reflection properties of each material , as well as the spatially varying effects . We present an image-based measuring method that robustly detects the different materials of real objects and fits an average bidirectional reflectance distribution function to each of them . In order to model local changes as well , we project the measured data for each surface point into a basis formed by the recovered BRDFs leading to a truly spatially varying BRDF representation . Real-world objects often also have fine geometric detail that is not represented in an acquired mesh . To increase
2	Over the last few years , deep learning has achieved impressive results on various visual understanding tasks , such as image classification #CITE# , object detection #CITE# , or semantic segmentation #CITE# . $SEP$ Abstract Given an initial recognition model already trained on a set of base classes , the goal of this work is to develop $SEP$ We trained a large , deep convolutional neural network to classify the 1 .2 million high-resolution images in the ImageNet LSVRC-2010 contest into the 1000 different classes . On the test data , we achieved top-1 and top-5 error rates of 37 .5 % and 17 .0 % , respectively , which is considerably better than the previous state-of-the-art . The neural network , which has 60 million parameters and 650 ,000 neurons , consists of five convolutional layers , some of which are followed by max-pooling layers , and three fully connected layers with a final 1000-way softmax . To make training faster , we used nonsaturating neurons and a very efficient GPU implementation of the convolution operation . To reduce overfitting in the fully connected layers $SEPB$ In this work we investigate the effect of the convolutional network depth on its accuracy in the large-scale image recognition setting . Our main contribution is a thorough evaluation of networks of increasing depth , which shows that a significant improvement on the prior-art configurations can be achieved by pushing the depth to 16-19 weight layers . These findings were the basis of our ImageNet Challenge 2014 submission , where our team secured the first and the second places in the localisation and classification tracks respectively . We also show that our representations generalise well to other datasets , where they achieve the stateof-the-art results . Importantly , we have made our two best-performing ConvNet models publicly available to facilitate further research on the use of deep visual $SEPB$ We propose a deep convolutional neural network architecture codenamed Inception that achieves the new state of the art for classification and detection in the Im-ageNet Large-Scale Visual Recognition Challenge 2014 . The main hallmark of this architecture is the improved utilization of the computing resources inside the network . By a carefully crafted design , we increased the depth and width of the network while keeping the computational budget constant . To optimize quality , the architectural decisions were based on the Hebbian principle and the intuition of multi-scale processing . One particular incarnation used in our submission for ILSVRC14 is called GoogLeNet , a 22 layers deep network , the quality of which is assessed in the context of classification and detection .1 978-1-4673-6964-0/15/ $ 31 .00 $SEPB$ Deeper neural networks are more difficult to train . We present a residual learning framework to ease the training of networks that are substantially deeper than those used previously . We explicitly reformulate the layers as learning residual functions with reference to the layer inputs , instead of learning unreferenced functions . We provide comprehensive empirical evidence showing that these residual networks are easier to optimize , and can gain accuracy from considerably increased depth . On the ImageNet dataset we evaluate residual nets with a depth of up to 152 layers-8× deeper than VGG nets but still having lower complexity . An ensemble of these residual nets achieves 3 .57 % error on the ImageNet test set . This result won the 1st place on the ILSVRC $SEPB$ In this work we address the task of semantic image segmentation with Deep Learning and make three main contributions that are experimentally shown to have substantial practical merit . First , we highlight convolution with upsampled filters , or 'atrous convolution ' , as a powerful tool in dense prediction tasks . Atrous convolution allows us to explicitly control the resolution at which feature responses are computed within Deep Convolutional Neural Networks . It also allows us to effectively enlarge the field of view of filters to incorporate larger context without increasing the number of parameters or the amount of computation . Second , we propose atrous spatial pyramid pooling to robustly segment objects at multiple scales . ASPP probes an incoming convolutional feature layer with filters at
1	Recent sequence labeling models achieve state-of-the-art performance by combining both character-level and word-level information . $SEP$ Previous work on cross-lingual sequence labeling tasks either requires parallel data or bridges the two languages through word-byword matching . Such requirements and assumptions are infeasible for most languages , especially for languages with large linguistic distances , eg , English and Chinese . In this work , we propose a Multilingual Language Model with deep semantic Alignment to generate language-independent representations for cross-lingual sequence labeling . Our methods require only monolingual corpora with no bilingual resources at all and take advantage of deep contextualized representations . Experimental results show that our approach achieves new state-of-the-art NER and POS performance across European languages , and is also effective on distant language pairs such as English and Chinese . $SEP$ Named entity recognition is a challenging task that has traditionally required large amounts of knowledge in the form of feature engineering and lexicons to achieve high performance .In this paper , we present a novel neural network architecture that automatically detects word-and character-level features using a hybrid bidirectional LSTM and CNN architecture , eliminating the need for most feature engineering . We also propose a novel method of encoding partial lexicon matches in neural networks and compare it to existing approaches . Extensive evaluation shows that , given only tokenized text and publicly available word embeddings , our system is competitive on the CoNLL-2003 dataset and surpasses the previously reported state of the art performance on the OntoNotes 5 .0 dataset by 2 .13 F1 points . By $SEPB$ State-of-the-art sequence labeling systems traditionally require large amounts of taskspecific knowledge in the form of handcrafted features and data pre-processing . In this paper , we introduce a novel neutral network architecture that benefits from both word-and character-level representations automatically , by using combination of bidirectional LSTM , CNN and CRF . Our system is truly end-to-end , requiring no feature engineering or data preprocessing , thus making it applicable to a wide range of sequence labeling tasks . We evaluate our system on two data sets for two sequence labeling tasks -Penn Treebank WSJ corpus for part-of-speech tagging and CoNLL 2003 corpus for named entity recognition . We obtain state-of-the-art performance on both datasets -97 .55 % accuracy for POS tagging and 91 .21 % F1 for $SEPB$ State-of-the-art named entity recognition systems rely heavily on hand-crafted features and domain-specific knowledge in order to learn effectively from the small , supervised training corpora that are available . In this paper , we introduce two new neural architectures-one based on bidirectional LSTMs and conditional random fields , and the other that constructs and labels segments using a transition-based approach inspired by shift-reduce parsers . Our models rely on two sources of information about words : character-based word representations learned from the supervised corpus and unsupervised word representations learned from unannotated corpora . Our models obtain state-of-the-art performance in NER in four languages without resorting to any language-specific knowledge or resources such as gazetteers . $FULLTEXT$ Named entity recognition is a challenging learning problem . One the one
2	Sampling-based approximations to the denominator of the softmax have also been proposed to reduce calculation at training . $SEP$ In this paper , we propose a new method for calculating the output layer in neural machine translation systems . The method is based on predicting a binary code for each word and can reduce computation time/memory requirements of the output layer to be logarithmic in vocabulary size in the best case . In addition , we also introduce two advanced approaches to improve the robustness of the proposed model : using error-correcting codes and combining softmax and binary codes . Experiments on two English ↔ Japanese bidirectional translation tasks show proposed models achieve BLEU scores that approach the softmax , while reducing memory usage to the order of less than 1/10 and improving decoding speed on CPUs by x5 to x10 . $SEP$ In spite of their superior performance , neural probabilistic language models remain far less widely used than n-gram models due to their notoriously long training times , which are measured in weeks even for moderately-sized datasets . Training NPLMs is computationally expensive because they are explicitly normalized , which leads to having to consider all words in the vocabulary when computing the log-likelihood gradients .We propose a fast and simple algorithm for training NPLMs based on noise-contrastive estimation , a newly introduced procedure for estimating unnormalized continuous distributions . We investigate the behaviour of the algorithm on the Penn Treebank corpus and show that it reduces the training times by more than an order of magnitude without affecting the quality of the resulting models . The algorithm is $SEPB$ The recently introduced continuous Skip-gram model is an efficient method for learning high-quality distributed vector representations that capture a large number of precise syntactic and semantic word relationships . In this paper we present several extensions that improve both the quality of the vectors and the training speed . By subsampling of the frequent words we obtain significant speedup and also learn more regular word representations . We also describe a simple alternative to the hierarchical softmax called negative sampling . An inherent limitation of word representations is their indifference to word order and their inability to represent idiomatic phrases . For example , the meanings of `` Canada '' and `` Air '' can not be easily combined to obtain `` Air Canada '' . Motivated by
1	Another approach is static analysis , in particular , type systems , that can statically ensure race-freedom and atomicity #CITE# . $SEP$ Concurrent programs are notorious for containing errors that are difficult to reproduce and diagnose . Two common kinds of concurrency errors are data races and atomicity violations . Several static and dynamic analysis techniques exist to detect potential races and atomicity violations . Run-time checking may miss errors in unexecuted code and incurs significant run-time overhead . On the other hand , run-time checking generally produces fewer false alarms than static analysis ; this is a significant practical advantage , since diagnosing all of the warnings from static analysis of large codebases may be prohibitively expensive . This paper explores the use of static analysis to significantly decrease the overhead of run-time checking . Our approach is based on a type system for analyzing data races and atomicity . A type discovery algorithm is used to obtain types for as much of the program as possible . Warnings from the typechecker are used to identify parts of the program from which run-time checking can safely be omitted . The approach is completely automatic , scalable to very large programs , and significantly reduces the overhead of run-time checking for data races and atomicity violations . $SEP$ This paper presents a static race detection analysis for multithreaded Java programs . Our analysis is based on a formal type system that is capable of capturing many common synchronization patterns . These patterns include classes with internal synchronization , classes that require client-side synchronization , and thread-local classes . Experience checking over 40 ,000 lines of Java code with the type system demonstrates that it is an effective approach for eliminating races conditions . On large examples , fewer than 20 additional type annotations per 1000 lines of code were required by the type checker , and we found a number of races in the standard Java libraries and other test programs . $FULLTEXT$ Race conditions are common , insidious errors in multithreaded programs . A race $SEPB$ Ensuring the correctness of multithreaded programs is difficult , due to the potential for unexpected and nondeterministic interactions between threads . Previous work addressed this problem by devising tools for detecting race conditions , a situation where two threads simultaneously access the same data variable , and at least one of the accesses is a write . However , verifying the absence of such simultaneous-access race conditions is neither necessary nor sufficient to ensure the absence of errors due to unexpected thread interactions .We propose that a stronger non-interference property is required , namely atomicity . Atomic methods can be assumed to execute serially , without interleaved steps of other threads . Thus , atomic methods are amenable to sequential reasoning techniques , which significantly simplifies both formal
2	The above problem is a mixed integer nonlinear programming , and some standard algorithms have been developed to solve it , eg , the branch-and-bound algorithm #CITE# . $SEP$ Abstract-In this paper , we study the stochastic optimization of cloud radio access networks by joint remote radio head activation and beamforming in the downlink . Unlike most previous works that only consider a static optimization framework with full traffic buffers , we formulate a dynamic optimization problem by explicitly considering the effects of random traffic arrivals and time-varying channel fading . The stochastic formulation can quantify the tradeoff between power consumption and queuing delay . Leveraging on the Lyapunov optimization technique , the stochastic optimization problem can be transformed into a per-slot penalized weighted sum rate maximization problem , which is shown to be non-deterministic polynomial-time hard . Based on the equivalence between the penalized weighted sum rate maximization problem and the penalized weighted minimum mean square error problem , the group sparse beamforming optimization based WMMSE algorithm and the relaxed integer programming based WMMSE algorithm are proposed to efficiently obtain the joint RRH activation and beamforming policy . Both algorithms can converge to a stationary solution with low-complexity and can be implemented in a parallel manner , thus they are highly scalable to large-scale C-RANs . In addition , these two proposed algorithms provide a flexible and efficient $SEP$ Abstract-This paper presents an exact algorithm for sparse filter design under a quadratic constraint on filter performance . The algorithm is based on branch-and-bound , a combinatorial optimization procedure that can either guarantee an optimal solution or produce a sparse solution with a bound on its deviation from optimality . To reduce the complexity of branch-and-bound , several methods are developed for bounding the optimal filter cost . Bounds based on infeasibility yield incrementally accumulating improvements with minimal computation , while two convex relaxations , referred to as linear and diagonal relaxations , are derived to provide stronger bounds . The approximation properties of the two relaxations are characterized analytically as well as numerically . Design examples involving wireless channel equalization and minimum-variance distortionless-response beamforming show that the
2	There are some previous methods #CITE# which are able to take indirect illumination into account . $SEP$ In this paper we present a novel plausible rendering method for mixed reality systems , which is useful for many real-life application scenarios , like architecture , product visualization or edutainment . To allow virtual objects to seamlessly blend into the real environment , the real lighting conditions and the mutual illumination effects between real and virtual objects must be considered , while maintaining interactive frame rates . The most important such effects are indirect illumination and shadows cast between real and virtual objects . Our approach combines Instant Radiosity and Differential Rendering . In contrast to some previous solutions , we only need to render the scene once in order to find the mutual effects of virtual and real scenes . In addition , we avoid artifacts like double shadows or inconsistent color bleeding which appear in previous work . The dynamic real illumination is derived from the image stream of a fish-eye lens camera . The scene gets illuminated by virtual point lights , which use imperfect shadow maps to calculate visibility . A sufficiently fast scene reconstruction is done at run-time with Microsoft 's Kinect sensor . Thus a time-consuming manual pre-modeling step of the real scene $SEP$ Inserting virtual objects in real camera images with correct lighting is an active area of research . Current methods use a high dynamic range camera with a fish-eye lens to capture the incoming illumination . The main problem with this approach is the limitation to distant illumination . Therefore , the focus of our work is a real-time description of both near -and far-field illumination for interactive movement of virtual objects in the camera image of a real room . The daylight , which is coming in through the windows , produces a spatially varying distribution of indirect light in the room ; therefore a near-field description of incoming light is necessary . Our approach is to measure the daylight from outside and to simulate the resulting indirect
1	From the perspective of methodology , Liu et al #CITE# propose a learning-to-rank framework via leveraging unlabeled data . Sam et al #CITE# present almost unsupervised autoencoder for dense crowd counting , whose 99 .9% parameters are trained without any labeled data . $SEP$ With the development of deep neural networks , the performance of crowd counting and pixel-wise density estimation are continually being refreshed . Despite this , there are still two challenging problems in this field : 1 ) current supervised learning needs a large amount of training data , but collecting and annotating them is difficult ; 2 ) existing methods can not generalize well to the unseen domain . A recently released synthetic crowd dataset alleviates these two problems . However , the domain gap between the real-world data and synthetic images decreases the models ' performance . To reduce the gap , in this paper , we propose a domain-adaptation-style crowd counting method , which can effectively adapt the model from synthetic data to the specific real-world scenes . It consists of Multi-level Feature-aware Adaptation and Structured Density map Alignment . To be specific , MFA boosts the model to extract domain-invariant features from multiple layers . SDA guarantees the network outputs fine density maps with a reasonable distribution on the real domain . Finally , we evaluate the proposed method on four mainstream surveillance crowd datasets , Shanghai Tech Part B , WorldExpo'10 , Mall and UCSD . $SEP$ We propose a novel crowd counting approach that leverages abundantly available unlabeled crowd imagery in a learning-to-rank framework . To induce a ranking of cropped images , we use the observation that any sub-image of a crowded scene image is guaranteed to contain the same number or fewer persons than the super-image . This allows us to address the problem of limited size of existing datasets for crowd counting . We collect two crowd scene datasets from Google using keyword searches and queryby-example image retrieval , respectively . We demonstrate how to efficiently learn from these unlabeled datasets by incorporating learning-to-rank in a multi-task network which simultaneously ranks images and estimates crowd density maps . Experiments on two of the most challenging crowd counting datasets show that our $SEPB$ We present an unsupervised learning method for dense crowd count estimation . Marred by large variability in appearance of people and extreme overlap in crowds , enumerating people proves to be a difficult task even for humans . This implies creating large-scale annotated crowd data is expensive and directly takes a toll on the performance of existing CNN based counting models on account of small datasets . Motivated by these challenges , we develop Grid Winner-Take-All autoencoder to learn several layers of useful filters from unlabeled crowd images . Our GWTA approach divides a convolution layer spatially into a grid of cells . Within each cell , only the maximally activated neuron is allowed to update the filter . Almost 99 .9 % of the parameters of the
2	The viscous free surface condition has not been studied closely in conforming Lagrangian tetrahedral mesh methods , although these methods should incorporate it implicitly . $SEP$ . By carefully treating coupling between viscosity and pressure forces , our unified Stokes-based fluid solver can reproduce the classic liquid rope coiling instability of viscous liquids like honey , while prior grid-based methods can not . We propose a novel unsteady Stokes solver for coupled viscous and pressure forces in grid-based liquid animation which yields greater accuracy and visual realism than previously achieved . Modern fluid simulators treat viscosity and pressure in separate solver stages , which reduces accuracy and yields incorrect free surface behavior . Our proposed implicit variational formulation of the Stokes problem leads to a symmetric positive definite linear system that gives properly coupled forces , provides unconditional stability , and treats difficult boundary conditions naturally through simple volume weights . Surface tension and moving solid boundaries are also easily incorporated . Qualitatively , we show that our method recovers the characteristic rope coiling instability of viscous liquids and preserves fine surface details , while previous grid-based schemes do not . Quantitatively , we demonstrate that our method is convergent through grid refinement studies on analytical problems in two dimensions . We conclude by offering practical guidelines for choosing an appropriate viscous solver , based on $SEP$ This article describes a Lagrangian finite element method that simulates the behavior of liquids and solids in a unified framework . Local mesh improvement operations maintain a high-quality tetrahedral discretization even as the mesh is advected by fluid flow . We conserve volume and momentum , locally and globally , by assigning to each element an independent rest volume and adjusting it to correct for deviations during remeshing and collisions . Incompressibility is enforced with per-node pressure values , and extra degrees of freedom are selectively inserted to prevent pressure locking . Topological changes in the domain are explicitly treated with local mesh splitting and merging . Our method models surface tension with an implicit formulation based on surface energies computed on the boundary of the volume mesh $SEPB$ Abstract-In this paper , we present a method for animating multiphase flow of immiscible fluids using unstructured moving meshes . Our underlying discretization is an unstructured tetrahedral mesh , the deformable simplicial complex , that moves with the flow in a Lagrangian manner . Mesh optimization operations improve element quality and avoid element inversion . In the context of multiphase flow , we guarantee that every element is occupied by a single fluid and , consequently , the interface between fluids is represented by a set of faces in the simplicial complex . This approach ensures that the underlying discretization matches the physics and avoids the additional book-keeping required in grid-based methods where multiple fluids may occupy the same cell . Our Lagrangian approach naturally leads us to
0	Recent work on extending GPs to big-data applications has focused on deriving variational representations of GPs #CITE# , constructing sparse approximations of GPs #CITE# and training local GPs using informative subsets of the data #CITE# . $SEP$ Numerous engineering problems of interest to the industry are often characterized by expensive black-box objective function evaluations . These objective functions could be physical experiments or computer simulations . Obtaining a comprehensive idea of the problem and/or performing subsequent optimizations generally requires hundreds of thousands of evaluations of the objective function which is most often a practically unachievable task . Gaussian Process surrogate modeling replaces the expensive function with a cheap-to-evaluate data-driven probabilistic model . While the GP does not assume a functional form of the problem , it is defined by a set of parameters , called hyperparameters , that need to be learned from the data . The hyperparameters define the characteristics of the objective function , such as smoothness , magnitude , periodicity , etc . Accurately estimating these hyperparameters is a key ingredient in developing a reliable and generalizable surrogate model . Markov chain Monte Carlo is a ubiquitously used Bayesian method to estimate these hyperparameters . At GE 's Global Research Center , a customized industry-strength Bayesian hybrid modeling framework utilizing the GP , called GEBHM , has been employed and validated over many years . GEBHM is very effective on problems of small and $SEP$ Gaussian processes are powerful non-parametric function estimators . However , their applications are largely limited by the expensive computational cost of the inference procedures . Existing stochastic or distributed synchronous variational inferences , although have alleviated this issue by scaling up GPs to millions of samples , are still far from satisfactory for real-world large applications , where the data sizes are often orders of magnitudes larger , say , billions . To solve this problem , we propose ADVGP , the first Asynchronous Distributed Variational Gaussian Process inference for regression , on the recent large-scale machine learning platform , PARAMETERSERVER . ADVGP uses a novel , flexible variational framework based on a weight space augmentation , and implements the highly efficient , asynchronous proximal gradient optimization . $SEPB$ We introduce stochastic variational inference for Gaussian process models . This enables the application of Gaussian process models to data sets containing millions of data points . We show how GPs can be variationally decomposed to depend on a set of globally relevant inducing variables which factorize the model in the necessary manner to perform variational inference . Our approach is readily extended to models with non-Gaussian likelihoods and latent variable models based around Gaussian processes . We demonstrate the approach on a simple toy problem and two real world data sets . $FULLTEXT$ Gaussian processes are perhaps the dominant approach for inference on functions . They underpin a range of algorithms for regression , classification and unsupervised learning . Unfortunately , when applying a Gaussian process to
2	Besides the achievable rate region characterization , significant research effort on Gaussian ICs has been devoted to solving the WSRMax problems #CITE# , #CITE# . Many suboptimal algorithms have thus been proposed , eg , the gradient descent algorithm #CITE# , the interferencepricing based algorithm #CITE# , the game-theory based algorithm #CITE# , and the iterative weighted minimum mean-square-error based algorithm #CITE# . More recently , for Gaussian SISO-IC , SIMO-IC and MISO-IC , the globally optimal solutions to WSRMax problems have been obtained under the monotonic optimization framework #CITE# , #CITE# . $SEP$ This paper studies the achievable rate region of the K-user Gaussian multiple-input single-output interference channel with the interference treated as noise , when improper or circularly asymmetric complex Gaussian signaling is applied . The transmit optimization with improper Gaussian signaling involves not only the signal covariance matrix as in the conventional proper or circularly symmetric Gaussian signaling , but also the signal pseudo-covariance matrix , which is conventionally set to zero in proper Gaussian signaling . By exploiting the separable rate expression with improper Gaussian signaling , we propose a separate transmit covariance and pseudo-covariance optimization algorithm , which is guaranteed to improve the users ' achievable rates over the conventional proper Gaussian signaling . In particular , for the pseudo-covariance optimization , we establish the optimality of rank-1 pseudo-covariance matrices , given the optimal rank-1 transmit covariance matrices for achieving the Pareto boundary of the rate region . Based on this result , we are able to greatly reduce the number of variables in the pseudo-covariance optimization problem and thereby develop an efficient solution by applying the celebrated semidefinite relaxation technique . Finally , we extend the result to the Gaussian MISO broadcast channel with improper Gaussian signaling or $SEP$ Abstract-This paper considers the non-cooperative maximization of mutual information in the vector Gaussian interference channel in a fully distributed fashion via game theory . This problem has been widely studied in a number of works during the past decade for frequency-selective channels , and recently for the more general MIMO case , for which the state-of-the art results are valid only for nonsingular square channel matrices . Surprisingly , these results do not hold true when the channel matrices are rectangular and/or rank deficient matrices .The goal of this paper is to provide a complete characterization of the MIMO game for arbitrary channel matrices , in terms of conditions guaranteeing both the uniqueness of the Nash equilibrium and the convergence of asynchronous distributed iterative waterfilling algorithms . Our $SEPB$ Achieving weighted throughput maximization through power control has been a long standing open problem in interference-limited wireless networks . The complicated coupling between the mutual interferences of links gives rise to a non-convex optimization problem . Previous work has considered the WTM problem in the high signal to interference-and-noise ratio regime , where the problem can be approximated and transformed into a convex optimization problem through proper change of variables . In the general SINR regime , however , the approximation and transformation approach does not work . This paper proposes an algorithm , MAPEL , which globally converges to a global optimal solution of the WTM problem in the general SINR regime . The MAPEL algorithm is designed based on three key observations of the WTM problem $SEPB$ Abstract-Resource allocation and transmit optimization for the multiple-antenna Gaussian interference channel are important but difficult problems . The spatial degrees of freedom can be exploited to avoid , align , or utilize the interference . In recent literature , the upper boundary of the achievable rate region has been characterized . However , the resulting programming problems for finding the sum-rate , proportional fair , and minimax operating points are non-linear and non-convex .In this paper , we develop a non-convex optimization framework based on monotonic optimization by outer polyblock approximation . First , the objective functions are represented in terms of differences of monotonic increasing functions . Next , the problems are reformulated as maximization of increasing functions over normal constraint sets . Finally , the idea $SEPB$ Abstract-The performance of multiuser systems is both difficult to measure fairly and to optimize . Most resource allocation problems are non-convex and NP-hard , even under simplifying assumptions such as perfect channel knowledge , homogeneous channel properties among users , and simple power constraints . We establish a general optimization framework that systematically solves these problems to global optimality . The proposed branch-reduce-and-bound algorithm handles general multicell downlink systems with single-antenna users , multiantenna transmitters , arbitrary quadratic power constraints , and robustness to channel uncertainty . A robust fairness-profile optimization problem is solved at each iteration , which is a quasi-convex problem and a novel generalization of maxmin fairness . The BRB algorithm is computationally costly , but it shows better convergence than the previously proposed outer $SEPB$ Abstract-This paper considers the non-cooperative maximization of mutual information in the vector Gaussian interference channel in a fully distributed fashion via game theory . This problem has been widely studied in a number of works during the past decade for frequency-selective channels , and recently for the more general MIMO case , for which the state-of-the art results are valid only for nonsingular square channel matrices . Surprisingly , these results do not hold true when the channel matrices are rectangular and/or rank deficient matrices .The goal of this paper is to provide a complete characterization of the MIMO game for arbitrary channel matrices , in terms of conditions guaranteeing both the uniqueness of the Nash equilibrium and the convergence of asynchronous distributed iterative waterfilling algorithms . Our $SEPB$ Achieving weighted throughput maximization through power control has been a long standing open problem in interference-limited wireless networks . The complicated coupling between the mutual interferences of links gives rise to a non-convex optimization problem . Previous work has considered the WTM problem in the high signal to interference-and-noise ratio regime , where the problem can be approximated and transformed into a convex optimization problem through proper change of variables . In the general SINR regime , however , the approximation and transformation approach does not work . This paper proposes an algorithm , MAPEL , which globally converges to a global optimal solution of the WTM problem in the general SINR regime . The MAPEL algorithm is designed based on three key observations of the WTM problem $SEPB$ Abstract-Resource allocation and transmit optimization for the multiple-antenna Gaussian interference channel are important but difficult problems . The spatial degrees of freedom can be exploited to avoid , align , or utilize the interference . In recent literature , the upper boundary of the achievable rate region has been characterized . However , the resulting programming problems for finding the sum-rate , proportional fair , and minimax operating points are non-linear and non-convex .In this paper , we develop a non-convex optimization framework based on monotonic optimization by outer polyblock approximation . First , the objective functions are represented in terms of differences of monotonic increasing functions . Next , the problems are reformulated as maximization of increasing functions over normal constraint sets . Finally , the idea $SEPB$ Abstract-The performance of multiuser systems is both difficult to measure fairly and to optimize . Most resource allocation problems are non-convex and NP-hard , even under simplifying assumptions such as perfect channel knowledge , homogeneous channel properties among users , and simple power constraints . We establish a general optimization framework that systematically solves these problems to global optimality . The proposed branch-reduce-and-bound algorithm handles general multicell downlink systems with single-antenna users , multiantenna transmitters , arbitrary quadratic power constraints , and robustness to channel uncertainty . A robust fairness-profile optimization problem is solved at each iteration , which is a quasi-convex problem and a novel generalization of maxmin fairness . The BRB algorithm is computationally costly , but it shows better convergence than the previously proposed outer
0	Several methods have been proposed to transfer various knowledge across tasks . $SEP$ Despite achieving great success on performance in various sequential decision task , deep reinforcement learning is extremely data inefficient . Many approaches have been proposed to improve the data efficiency , e .g . transfer learning which utilizes knowledge learned from related tasks to accelerate training . Previous researches on transfer learning mostly attempt to learn a common feature space of states across related tasks to exploit knowledge as much as possible . However , semantic information of actions may be shared as well , even between tasks with different action space size . In this work , we first propose a method to learn action embedding for discrete actions in RL from generated trajectories without any prior knowledge , and then leverage it to transfer policy across tasks with different state space and/or discrete action space . We validate our method on a set of gridworld navigation tasks , discretized continuous control tasks and fighting tasks in a commercial video game . Our experimental results show that our method can effectively learn informative action embeddings and accelerate learning by policy transfer across tasks . $SEP$ Most deep reinforcement learning algorithms are data inefficient in complex and rich environments , limiting their applicability to many scenarios . One direction for improving data efficiency is multitask learning with shared neural network parameters , where efficiency may be improved through transfer across related tasks . In practice , however , this is not usually observed , because gradients from different tasks can interfere negatively , making learning unstable and sometimes even less data efficient . Another issue is the different reward schemes between tasks , which can easily lead to one task dominating the learning of a shared model . We propose a new approach for joint training of multiple tasks , which we refer to as Distral . Instead of sharing parameters between the different $SEPB$ We propose an algorithm for meta-learning that is model-agnostic , in the sense that it is compatible with any model trained with gradient descent and applicable to a variety of different learning problems , including classification , regression , and reinforcement learning . The goal of meta-learning is to train a model on a variety of learning tasks , such that it can solve new learning tasks using only a small number of training samples . In our approach , the parameters of the model are explicitly trained such that a small number of gradient steps with a small amount of training data from a new task will produce good generalization performance on that task . In effect , our method trains the model to be easy to
2	Stochastic network calculus has been extended to capture the randomly varying channel capacity of wireless links , following different methods #CITE# . Most of the existing work builds on an abstracted finite-state Markov channel model of the underlying fading channel , eg , #CITE# or uses moment generating function based network calculus #CITE# . $SEP$ Motivated by emerging vision-based intelligent services , we consider the problem of rate adaptation for high quality and low delay visual information delivery over wireless networks using scalable video coding . Rate adaptation in this setting is inherently challenging due to the interplay between the variability of the wireless channels , the queuing at the network nodes and the frame-based decoding and playback of the video content at the receiver at very short time scales . To address the problem , we propose a low-complexity , model-based rate adaptation algorithm for scalable video streaming systems , building on a novel performance model based on stochastic network calculus . We validate the model using extensive simulations . We show that it allows fast , near optimal rate adaptation for fixed transmission paths , as well as cross-layer optimized routing and video rate adaptation in mesh networks , with less than 10 % quality degradation compared to the best achievable performance . $SEP$ Abstract-The MIMO wireless channel offers a rich ground for quality of service analysis . In this work , we present a stochastic network calculus analysis of a MIMO system , operating in spatial multiplexing mode , using moment generating functions . We quantify the spatial multiplexing gain , achieved through multiple antennas , for flow level quality of service performance . Specifically we use Gilbert-Elliot model to describe individual spatial paths between the antenna pairs and model the whole channel by an N -State Markov chain , where N depends upon the degrees of freedom available of the MIMO system . We derive probabilistic delay bounds for bursty channels and show the impact of increasing the number of antennas on the delay bounds under various conditions , such $SEPB$ Abstract-Network calculus is a min-plus system theory for performance evaluation of queuing networks . Its elegance stems from intuitive convolution formulas for concatenation of deterministic servers . Recent research dispenses with the worstcase assumptions of network calculus to develop a probabilistic equivalent that benefits from statistical multiplexing . Significant achievements have been made , owing for example to the theory of effective bandwidths , however , the outstanding scalability set up by concatenation of deterministic servers has not been shown . This paper establishes a concise , probabilistic network calculus with moment generating functions . The presented work features closed-form , end-to-end , probabilistic performance bounds that achieve the objective of scaling linearly in the number of servers in series . The consistent application of moment generating functions $SEPB$ Abstract-The MIMO wireless channel offers a rich ground for quality of service analysis . In this work , we present a stochastic network calculus analysis of a MIMO system , operating in spatial multiplexing mode , using moment generating functions . We quantify the spatial multiplexing gain , achieved through multiple antennas , for flow level quality of service performance . Specifically we use Gilbert-Elliot model to describe individual spatial paths between the antenna pairs and model the whole channel by an N -State Markov chain , where N depends upon the degrees of freedom available of the MIMO system . We derive probabilistic delay bounds for bursty channels and show the impact of increasing the number of antennas on the delay bounds under various conditions , such $SEPB$ Abstract-Network calculus is a min-plus system theory for performance evaluation of queuing networks . Its elegance stems from intuitive convolution formulas for concatenation of deterministic servers . Recent research dispenses with the worstcase assumptions of network calculus to develop a probabilistic equivalent that benefits from statistical multiplexing . Significant achievements have been made , owing for example to the theory of effective bandwidths , however , the outstanding scalability set up by concatenation of deterministic servers has not been shown . This paper establishes a concise , probabilistic network calculus with moment generating functions . The presented work features closed-form , end-to-end , probabilistic performance bounds that achieve the objective of scaling linearly in the number of servers in series . The consistent application of moment generating functions
2	An alternative approach is to fold sequences separately , then find a consensus secondary structure , eg using a tree edit algorithm as in Hofacker et al and Höchsmann et al . Sankoff ; Gorodkin et al ; Havgaard et al ; Mathews and Turner solve this problem by inferring the alignment and folding simultaneously using dynamic programing . $SEP$ ABSTRACT Motivation : The recent discoveries of large numbers of non-coding RNAs and computational advances in genome-scale RNA search create a need for tools for automatic , high quality identification and characterization of conserved RNA motifs that can be readily used for database search . Previous tools fall short of this goal . Results : CMfinder is a new tool to predict RNA motifs in unaligned sequences . It is an expectation maximization algorithm using covariance models for motif description , featuring novel integration of multiple techniques for effective search of motif space , and a Bayesian framework that blends mutual information-based and folding energy-based approaches to predict structure in a principled way . Extensive tests show that our method works well on datasets with either low or high sequence similarity , is robust to inclusion of lengthy extraneous flanking sequence and/or completely unrelated sequences , and is reasonably fast and scalable . In testing on 19 known ncRNA families , including some difficult cases with poor sequence conservation and large indels , our method demonstrates excellent average per-basepair accuracy-79 % compared with at most 60 % for alternative methods . More importantly , the resulting probabilistic model can be $SEP$ We present a systematic treatment of alignment distance and local similarity algorithms on trees and forests . We build upon the tree alignment algorithm for ordered trees given by Jiang et . al and extend it to calculate local forest alignments , which is essential for finding local similar regions in RNA secondary structures . The time complexity of our algorithm isMotivationRNA is a chain molecule , mathematically a string over a four letter alphabet . It is built from nucleotides containing the bases A , C , G , and U . By folding back onto itself , an RNA molecule forms structure , stabilized by the forces of hydrogen bonds between certain pairs of bases , and dense stacking of neighbouring base pairs .The investigation of $SEPB$ Motivation : Searching for non-coding RNA genes and structural RNA elements are major challenges in gene finding today as these often are conserved in structure rather than in sequence . Even though the number of available methods is growing , it is still of interest to pairwise detect two genes with low sequence similarity , where the genes are part of a larger genomic region .Here we present such an approach for pairwise local alignment which is based on foldalign and the Sankoff algorithm for simultaneous structural alignment of multiple sequences . We include the ability to conduct mutual scans of two sequences of arbitrary length while searching for common local structural motifs of some maximum length . This drastically reduces the complexity of the algorithm . The
0	If there are no errors in the data , ie , the data are strictly drawn from multiple subspaces , several existing methods can be used to solve subspace clustering exactly #CITE# . $SEP$ We propose a symmetric low-rank representation method for subspace clustering , which assumes that a data set is approximately drawn from the union of multiple subspaces . The proposed technique can reveal the membership of multiple subspaces through the self-expressiveness property of the data . In particular , the SLRR method considers a collaborative representation combined with low-rank matrix recovery techniques as a low-rank representation to learn a symmetric low-rank representation , which preserves the subspace structures of high-dimensional data . In contrast to performing iterative singular value decomposition in some existing low-rank representation based algorithms , the symmetric low-rank representation in the SLRR method can be calculated as a closed form solution by solving the symmetric low-rank optimization problem . By making use of the angular information of the principal directions of the symmetric low-rank representation , an affinity graph matrix is constructed for spectral clustering . Extensive experimental results show that it outperforms state-of-the-art subspace clustering algorithms . $SEP$ Abstract-In this work we address the subspace clustering problem . Given a set of data samples approximately drawn from a union of multiple subspaces , our goal is to cluster the samples into their respective subspaces and remove possible outliers as well . To this end , we propose a novel objective function named Low-Rank Representation , which seeks the lowestrank representation among all the candidates that can represent the data samples as linear combinations of the bases in a given dictionary . It is shown that the convex program associated with LRR solves the subspace clustering problem in the following sense : when the data is clean , we prove that LRR exactly recovers the true subspace structures ; when the data are contaminated by outliers , $SEPB$ We analyze and improve low rank representation , the state-of-the-art algorithm for subspace segmentation of data . We prove that for the noiseless case , the optimization model of LRR has a unique solution , which is the shape interaction matrix of the data matrix . So in essence LRR is equivalent to factorization methods . We also prove that the minimum value of the optimization model of LRR is equal to the rank of the data matrix . For the noisy case , we show that LRR can be approximated as a factorization method that combines noise removal by column sparse robust PCA . We further propose an improved version of LRR , called Robust Shape Interaction , which uses the corrected data as the dictionary instead
2	For instance , Wang et al #CITE# propose two deep neural networks to integrate local estimation and global search for saliency detection . Li et al #CITE# train fully connected layers of mutiple CNNs to predict the saliency degree of each superpixel . $SEP$ Deep convolutional neural networks have delivered superior performance in many computer vision tasks . In this paper , we propose a novel deep fully convolutional network model for accurate salient object detection . The key contribution of this work is to learn deep uncertain convolutional features , which encourage the robustness and accuracy of saliency detection . We achieve this via introducing a reformulated dropout after specific convolutional layers to construct an uncertain ensemble of internal feature units . In addition , we propose an effective hybrid upsampling method to reduce the checkerboard artifacts of deconvolution operators in our decoder network . The proposed methods can also be applied to other deep convolutional networks . Compared with existing saliency detection methods , the proposed UCF model is able to incorporate uncertainties for more accurate object boundary inference . Extensive experiments demonstrate that our proposed saliency model performs favorably against state-ofthe-art approaches . The uncertain feature learning mechanism as well as the upsampling method can significantly improve performance on other pixel-wise vision tasks . $SEP$ This paper presents a saliency detection algorithm by integrating both local estimation and global search . In the local estimation stage , we detect local saliency by using a deep neural network which learns local patch features to determine the saliency value of each pixel . The estimated local saliency maps are further refined by exploring the high level object concepts . In the global search stage , the local saliency map together with global contrast and geometric information are used as global features to describe a set of object candidate regions . Another deep neural network is trained to predict the saliency score of each object region based on the global features . The final saliency map is generated by a weighted sum of salient object regions $SEPB$ Visual saliency is a fundamental problem in both cogni tive and computational sciences , including computer vision . In this paper , we discover that a high-quality visual saliency model can be learned from multiscale features extracted using deep convolutional neural networks , which have had many successes in visual recognition tasks . For learning such saliency models , we introduce a neural net work architecture , which has fully connected layers on top ofCNNs responsible for feature extraction at three dif f erent scales . We then propose a refinement method to enhance the spatial coherence of our saliency results . Finally , aggre gating multiple saliency maps computed for dif f erent levels of image segmentation can further boost the performance , yielding saliency maps better
2	Additionally , multiple kernel learning #CITE# , #CITE# , #CITE# , the column generation boosting #CITE# and the linear programming boosting #CITE# have also been proposed for object recognition . $SEP$ Abstract-Image/video data is usually represented with multiple visual features . Fusion of multi-source information for establishing the attributes has been widely recognized . Multi-feature visual recognition has recently received much attention in multimedia applications . This paper studies visual understanding via a newly proposed -norm based multi-feature shared learning framework , which can simultaneously learn a global label matrix and multiple sub-classifiers with the labeled multi-feature data . Additionally , a group graph manifold regularizer composed of the Laplacian and Hessian graph is proposed for better preserving the manifold structure of each feature , such that the label prediction power is much improved through the semi-supervised learning with global label consistency . For convenience , we call the proposed approach Global-Label-Consistent Classifier . The merits of the proposed method include : 1 ) the manifold structure information of each feature is exploited in learning , resulting in a more faithful classification owing to the global label consistency ; 2 ) a group graph manifold regularizer based on the Laplacian and Hessian regularization is constructed ; 3 ) an efficient alternative optimization method is introduced as a fast solver owing to the convex sub-problems . Experiments on several benchmark visual datasets $SEP$ An efficient and general multiple kernel learning algorithm has been recently proposed by Sonnenburg et al . . This approach has opened new perspectives since it makes the MKL approach tractable for largescale problems , by iteratively using existing support vector machine code . However , it turns out that this iterative algorithm needs several iterations before converging towards a reasonable solution . In this paper , we address the MKL problem through an adaptive 2-norm regularization formulation . Weights on each kernel matrix are included in the standard SVM empirical risk minimization problem with a 1 constraint to encourage sparsity . We propose an algorithm for solving this problem and provide an new insight on MKL algorithms based on block 1-norm regularization by showing that the two $SEPB$ We examine linear program approaches to boosting and demonstrate their efficient solution using LPBoost , a column generation based simplex method . We formulate the problem as if all possible weak hypotheses had already been generated . The labels produced by the weak hypotheses become the new feature space of the problem . The boosting task becomes to construct a learning function in the label space that minimizes misclassification error and maximizes the soft margin . We prove that for classification , minimizing the 1-norm soft margin error function directly optimizes a generalization error bound . The equivalent linear program can be efficiently solved using column generation techniques developed for large-scale optimization problems . The resulting LPBoost algorithm can be used to solve any LP boosting formulation by
0	Prior work Trajanovski et al , 2015) on epidemic games has relied on the N-Intertwined Mean Field Approximation Van Mieghem and Omic , 2013) . ) studied a game-theoretic setting where nodes choose their curing rates , and showed the existence of a pure Nash equilibrium assuming that the steady-state infection probability of a node is a convex function of her own curing rate under the NIMFA . $SEP$ Abstract : We study networks of human decision-makers who independently decide how to protect themselves against Susceptible-Infected-Susceptible epidemics . Motivated by studies in behavioral economics showing that humans perceive probabilities in a nonlinear fashion , we examine the impacts of such misperceptions on the equilibrium protection strategies . In our setting , nodes choose their curing rates to minimize the infection probability under the degree-based mean-field approximation of the SIS epidemic plus the cost of their selected curing rate . We establish the existence of a degree based equilibrium under both true and nonlinear perceptions of infection probabilities . When the per-unit cost of curing rate is sufficiently high , we show that true expectation minimizers choose the curing rate to be zero at the equilibrium , while curing rate is nonzero under nonlinear probability weighting . $SEP$ Abstract-Defining an optimal protection strategy against viruses , spam propagation or any other kind of contamination process is an important feature for designing new networks and architectures . In this work , we consider decentralized optimal protection strategies when a virus is propagating over a network through a SIS epidemic process . We assume that each node in the network can fully protect itself from infection at a constant cost , or the node can use recovery software , once it is infected . We model our system using a game theoretic framework and find pure , mixed equilibria , and the Price of Anarchy in several network topologies . Further , we propose both a decentralized algorithm and an iterative procedure to compute a pure equilibrium in $SEPB$ Abstract-Our N -intertwined model for virus spread in any network with N nodes is extended to a full heterogeneous setting . The metastable steady-state nodal infection probabilities are specified in terms of a generalized Laplacian , that possesses analogous properties as the classical Laplacian in graph theory . The critical threshold that separates global network infection from global network health is characterized via an N dimensional vector that makes the largest eigenvalue of a modified adjacency matrix equal to unity . Finally , the steady-state infection probability of node i is convex in the own curing rate δi , but concave in the curing rates δj of the other nodes 1 ≤ j = i ≤ N in the network . $FULLTEXT$ This paper generalizes our N -intertwined
0	Several works proposed theoretical frameworks to examine how vulnerable or de-anonymizable any graph dataset is , given its structure #CITE# . $SEP$ Real social network datasets provide significant benefits for understanding phenomena such as information diffusion or network evolution . Yet the privacy risks raised from sharing real graph datasets , even when stripped of user identity information , are significant . Previous research shows that many graph anonymization techniques fail against existing graph de-anonymization attacks . However , the specific reason for the success of such de-anonymization attacks is yet to be understood . This paper systematically studies the structural properties of real graphs that make them more vulnerable to machine learning-based techniques for de-anonymization . More precisely , we study the boundaries of anonymity based on the structural properties of real graph datasets in terms of how their dKbased anonymized versions resist to various types of attacks . Our experimental results lead to three contributions . First , we identify the strength of an attacker based on the graph characteristics of the subset of nodes from which it starts the de-anonymization attack . Second , we quantify the relative effectiveness of dK-series for graph anonymization . And third , we identify the properties of the original graph that make it more vulnerable to de-anonymization . $SEP$ In this paper , we conduct the first comprehensive quantification on the perfect de-anonymizability and partial deanonymizability of real world social networks with seed information in general scenarios , where a social network can follow an arbitrary distribution model . This quantification provides the theoretical foundation for existing structure based de-anonymization attacks and closes the gap between de-anonymization practice and theory . Besides that , our quantification can serve as a testing-stone for the effectiveness of anonymization techniques , ie , researchers can employ our quantified structural conditions to evaluate the potential deanonymizability of the anonymized social networks . Based on our quantification , we conduct a large scale evaluation on the de-anonymizability of 24 various real world social networks by quantitatively showing : 1 ) the conditions $SEPB$ The proliferation of online social networks , and the concomitant accumulation of user data , give rise to hotly debated issues of privacy , security , and control . One specific challenge is the sharing or public release of anonymized data without accidentally leaking personally identifiable information . Unfortunately , it is often difficult to ascertain that sophisticated statistical techniques , potentially employing additional external data sources , are unable to break anonymity .In this paper , we consider an instance of this problem , where the object of interest is the structure of a social network , ie , a graph describing users and their links . Recent work demonstrates that anonymizing node identities may not be sufficient to keep the network private : the availability of
1	With the availability of large-scale training data , the field of visual object recognition has made significant progress in the last several years #CITE# . $SEP$ Most existing Zero-Shot Learning methods have the strong bias problem , in which instances of unseen classes tend to be categorized as one of the seen classes . So they yield poor performance after being deployed in the generalized ZSL settings . In this paper , we propose a straightforward yet effective method named Quasi-Fully Supervised Learning to alleviate the bias problem . Our method follows the way of transductive learning , which assumes that both the labeled source images and unlabeled target images are available for training . In the semantic embedding space , the labeled source images are mapped to several fixed points specified by the source categories , and the unlabeled target images are forced to be mapped to other points specified by the target categories . Experiments conducted on AwA2 , CUB and SUN datasets demonstrate that our method outperforms existing state-ofthe-art approaches by a huge margin of 9 .3 ∼ 24 .5 % following generalized ZSL settings , and by a large margin of 0 .2 ∼ 16 .2 % following conventional ZSL settings . $SEP$ We trained a large , deep convolutional neural network to classify the 1 .2 million high-resolution images in the ImageNet LSVRC-2010 contest into the 1000 different classes . On the test data , we achieved top-1 and top-5 error rates of 37 .5 % and 17 .0 % , respectively , which is considerably better than the previous state-of-the-art . The neural network , which has 60 million parameters and 650 ,000 neurons , consists of five convolutional layers , some of which are followed by max-pooling layers , and three fully connected layers with a final 1000-way softmax . To make training faster , we used nonsaturating neurons and a very efficient GPU implementation of the convolution operation . To reduce overfitting in the fully connected layers $SEPB$ We propose a deep convolutional neural network architecture codenamed Inception that achieves the new state of the art for classification and detection in the Im-ageNet Large-Scale Visual Recognition Challenge 2014 . The main hallmark of this architecture is the improved utilization of the computing resources inside the network . By a carefully crafted design , we increased the depth and width of the network while keeping the computational budget constant . To optimize quality , the architectural decisions were based on the Hebbian principle and the intuition of multi-scale processing . One particular incarnation used in our submission for ILSVRC14 is called GoogLeNet , a 22 layers deep network , the quality of which is assessed in the context of classification and detection .1 978-1-4673-6964-0/15/ $ 31 .00 $SEPB$ Deeper neural networks are more difficult to train . We present a residual learning framework to ease the training of networks that are substantially deeper than those used previously . We explicitly reformulate the layers as learning residual functions with reference to the layer inputs , instead of learning unreferenced functions . We provide comprehensive empirical evidence showing that these residual networks are easier to optimize , and can gain accuracy from considerably increased depth . On the ImageNet dataset we evaluate residual nets with a depth of up to 152 layers-8× deeper than VGG nets but still having lower complexity . An ensemble of these residual nets achieves 3 .57 % error on the ImageNet test set . This result won the 1st place on the ILSVRC $SEPB$ Recent work has shown that convolutional networks can be substantially deeper , more accurate , and efficient to train if they contain shorter connections between layers close to the input and those close to the output . In this paper , we embrace this observation and introduce the Dense Convolutional Network , which connects each layer to every other layer in a feed-forward fashion . Whereas traditional convolutional networks with L layers have L connections-one between each layer and its subsequent layer-our network has L 2 direct connections . For each layer , the feature-maps of all preceding layers are used as inputs , and its own feature-maps are used as inputs into all subsequent layers . DenseNets have several compelling advantages : they alleviate the vanishing-gradient problem
1	Additional work on summarization #CITE# attempt on incorporating user query interests . $SEP$ Abstract . A large part of Web resources consists of unstructured textual content . Processing and retrieving relevant content for a particular information need is challenging for both machines and humans . While information retrieval techniques provide methods for detecting suitable resources for a particular query , information extraction techniques enable the extraction of structured data and text summarization allows the detection of important sentences . However , these techniques usually do not consider particular user interests and information needs . In this paper , we present a novel method to automatically generate structured summaries from user queries that uses POS patterns to identify relevant statements and entities in a certain context . Finally , we evaluate our work using the publicly available New York Times corpus , which shows the applicability of our method and the advantages over previous works . $SEP$ This paper presents an investigation into the utility of document summarisation in the context of information retrieval , more specifically in the application of so called query biased summaries : summaries customised to reflect the information need expressed in a query . Employed in the retrieved document list displayed after a retrieval took place , the summaries ' utility was evaluated in a task-based environment by measuring users ' speed and accuracy in identifying relevant documents . This was compared to the performance achieved when users were presented with the more typical output of an IR system : a static predefined summary composed of the title and first few sentences of retrieved documents . The results from the evaluation indicate that the use of query biased summaries significantly $SEPB$ We present and evaluate the initial version of RIPTIDES , a system that combines information extraction , extraction-based summarization , and natural language generation to support userdirected multidocument summarization . $FULLTEXT$ Although recent years has seen increased and successful research efforts in the areas of single-document summarization , multidocument summarization , and information extraction , very few investigations have explored the potential of merging summarization and information extraction techniques . This paper presents and evaluates the initial version of RIPTIDES , a system that combines information extraction , extraction-based summarization , and natural language generation to support userdirected multidocument summarization . Following , we hypothesize that IE-supported summarization will enable the generation of more accurate and targeted summaries in specific domains than is possible with current domain-independent techniques
1	Some researchers trained object part detectors with annotated bounding-box/part annotations #CITE# , #CITE# , #CITE# , #CITE# , #CITE# , and improved classification performance by utilizing the selective part features . $SEP$ ABSTRACT Extracting discriminative fine-grained features is essential for fine-grained image recognition tasks . Many researchers utilize expensive human annotations to learn discriminative part models , which may be impossible for real-world applications . Recently , bilinear pooling has been frequently adopted and has shown its effectiveness owing to its learning discriminative regions automatically . However , most bilinear pooling models still utilize the all convolutional part/region features for recognition , including those noisy or even harmful feature elements . In this paper , we devise a novel fine-grained image classification approach by the Hierarchical Bilinear Pooling with Aggregated Slack Mask model . The proposed model generates a RoI-aware image feature representation for better performance . We conduct experiments on three frequently used fine-grained image classification datasets . The experimental results demonstrate that HBPASM achieves competitive performance or even match the state-of-the-art methods on CUB-200-2011 , Stanford Cars , and FGVC-Aircraft , respectively . INDEX TERMS Fine-grained classification , image mask , multi-scale , RoI feature , deep learning . $SEP$ We propose an architecture for fine-grained visual categorization that approaches expert human performance in the classification of bird species . Our architecture first computes an estimate of the object 's pose ; this is used to compute local image features which are , in turn , used for classification . The features are computed by applying deep convolutional nets to image patches that are located and normalized by the pose . We perform an empirical study of a number of pose normalization schemes , including an investigation of higher order geometric warping functions . We propose a novel graph-based clustering algorithm for learning a compact pose normalization space . We perform a detailed investigation of stateof-the-art deep convolutional feature implementations and finetuning feature learning for fine-grained classification . $SEPB$ Abstract . Semantic part localization can facilitate fine-grained categorization by explicitly isolating subtle appearance differences associated with specific object parts . Methods for pose-normalized representations have been proposed , but generally presume bounding box annotations at test time due to the difficulty of object detection . We propose a model for fine-grained categorization that overcomes these limitations by leveraging deep convolutional features computed on bottom-up region proposals . Our method learns whole-object and part detectors , enforces learned geometric constraints between them , and predicts a fine-grained category from a pose-normalized representation . Experiments on the Caltech-UCSD bird dataset confirm that our method outperforms state-of-the-art fine-grained categorization methods in an end-to-end evaluation without requiring a bounding box at test time . $FULLTEXT$ The problem of visual fine-grained categorization $SEPB$ In the context of fine-grained visual categorization , the ability to interpret models as human-understandable visual manuals is sometimes as important as achieving high classification accuracy . In this paper , we propose a novel Part-Stacked CNN architecture that explicitly explains the finegrained recognition process by modeling subtle differences from object parts . Based on manually-labeled strong part annotations , the proposed architecture consists of a fully convolutional network to locate multiple object parts and a two-stream classification network that encodes object-level and part-level cues simultaneously . By adopting a set of sharing strategies between the computation of multiple object parts , the proposed architecture is very efficient running at 20 frames/sec during inference . Experimental results on the CUB-200-2011 dataset reveal the effectiveness of the proposed architecture
0	Earlier works #CITE# evaluate the forwarding capability of a node by the historic contact information , while more recent studies #CITE# employ the social property of nodes or transient contact patterns #CITE# for relay selection . $SEP$ Existing routing algorithms for Delay Tolerant Networks assume that nodes are willing to forward packets for others . In the real world , however , most people are socially selfish ; ie , they are willing to forward packets for nodes with whom they have social ties but not others , and such willingness varies with the strength of the social tie . Following the philosophy of design for user , we propose a Social Selfishness Aware Routing algorithm to cope with user selfishness and provide good routing performance in an efficient way . To select an effective forwarding node , SSAR considers both users ' willingness to forward and their contact opportunity , and derives a metric with mathematical modeling and machine learning techniques to measure the forwarding capability of the mobile nodes . Moreover , SSAR formulates the data forwarding process as a Multiple Knapsack Problem with Assignment Restrictions to satisfy user demands for selfishness and performance . Trace-driven simulations show that SSAR allows users to maintain selfishness and achieves good routing performance with low transmission cost . $SEP$ We consider the problem of routing in intermittently connected networks . In such networks there is no guarantee that a fully connected path between source and destination exist at any time , rendering traditional routing protocols unable to deliver messages between hosts . We propose a probabilistic routing protocol for such networks . $FULLTEXT$ Normally , one of the most basic requirements for enabling two nodes to communicate through a network is that there exist a fully connected path between them . However , there are scenarios where this is not the case , but where it still would be desirable to allow communication between nodes . Such scenarios include communication between villages of the Saami population of reindeer herders in the north of Sweden , and other $SEPB$ Message delivery in sparse Mobile Ad hoc Networks is difficult due to the fact that the network graph is rarely connected . A key challenge is to find a route that can provide good delivery performance and low end-to-end delay in a disconnected network graph where nodes may move freely . This paper presents a multidisciplinary solution based on the consideration of the socalled small world dynamics which have been proposed for economy and social studies and have recently revealed to be a successful approach to be exploited for characterising information propagation in wireless networks . To this purpose , some bridge nodes are identified based on their centrality characteristics , ie , on their capability to broker information exchange among otherwise disconnected nodes . Due to the $SEPB$ This paper deals with data dissemination in resource−constrained opportunistic networks , ie , multi-hop ad hoc networks in which simultaneous paths between endpoints are not available , in general , for end-to-end communication . One of the main challenges is to make content available in those regions of the network where interested users are present , without overusing available resources . These regions should be identified dynamically , only by exploiting local information exchanged by nodes upon encountering other peers . To this end , exploiting information about social users ' behaviour turns out to be very efficient . In this paper we propose and evaluate ContentPlace , a system that exploits dynamically learnt information about users ' social relationships to decide where to place data objects in
0	Remark 3: Recently some concerns about network capacity collapsing in UDNs have emerged , eg , the capacity crash due to a non-zero BS-to-UE antenna height difference #CITE# , or a bounded path loss in the near-field region #CITE# , thus showing a pessimistic future for 5G . $SEP$ Abstract-We discover a new capacity scaling law in ultradense networks under practical system assumptions , such as a general multi-piece path loss model , a non-zero base station to user equipment antenna height difference , and a finite UE density . The intuition and implication of this new capacity scaling law are completely different from that found in year 2011 . That law indicated that the increase of the interference power caused by a denser network would be exactly compensated by the increase of the signal power due to the reduced distance between transmitters and receivers , and thus network capacity should grow linearly with network densification . However , we find that both the signal and interference powers become bounded in practical UDNs , which leads to a constant capacity scaling law . As a result , network densification should be stopped at a certain level for a given UE density , because the network capacity will reach its limit due to the bounded signal and interference powers , and a finite frequency reuse factor because of a finite UE density . Our new discovery on the constant capacity scaling law also resolves the recent concerns about network capacity $SEP$ Abstract-In this paper , we present a new and significant theoretical discovery . If the absolute height difference between base station antenna and user equipment antenna is larger than zero , then the network capacity performance in terms of the area spectral efficiency will continuously decrease as the BS density increases for ultra-dense small cell networks . This performance behavior has a tremendous impact on the deployment of UD SCNs in the 5th-generation era . Network operators may invest large amounts of money in deploying more network infrastructure to only obtain an even worse network performance . Our study results reveal that it is a must to lower the SCN BS antenna height to the UE antenna height to fully achieve the capacity gains of UD SCNs in $SEPB$ Besides advanced telecommunications techniques , the most prominent evolution of wireless networks is the densification of network deployment . In particular , the increasing access points/users density and reduced cell size significantly enhance spatial reuse , thereby improving network capacity . Nevertheless , does network ultra-densification and over-deployment always boost the performance of wireless networks ? Since the distance from transmitters to receivers is greatly reduced in dense networks , signal is more likely to be propagated from far-to near-field region . Without considering near-field propagation features , conventional understandings of the impact of network densification become doubtful . With this regard , it is imperative to reconsider the pros and cons brought by network densification . In this article , we first discuss the near-field propagation features
2	Knowledge Graph Reasoning Many works #CITE# have proposed approaches that explicitly model multi-step paths for KG reasoning . Chain-of-Reasoning #CITE# and Compositional Reasoning #CITE# take multi-hop paths found by PRA as input and aim to infer its relation . Two recent works , DeepPath #CITE# and MINERVA #CITE# , use RL-based approaches to explore KG and find better reasoning paths . Later works extend MINERVA with reward reshaping #CITE# or Monte Carlo Tree Search #CITE# respectively . Chen et al #CITE# propose to unify path-finding and path-reasoning with variational inference . Another line of work is IRN #CITE# and NeuralLP #CITE# , which learn first-order logical rules for KG reasoning with neural controller systems with external memory . $SEP$ Inferring new facts from existing knowledge graphs with explainable reasoning processes is a significant problem and has received much attention recently . However , few studies have focused on relation types unseen in the original KG , given only one or a few instances for training . To bridge this gap , we propose CogKR for one-shot KG reasoning . The one-shot relational learning problem is tackled through two modules : the summary module summarizes the underlying relationship of the given instances , based on which the reasoning module infers the correct answers . Motivated by the dual process theory in cognitive science , in the reasoning module , a cognitive graph is built by iteratively coordinating retrieval and reasoning . The structural information offered by the cognitive graph enables our model to aggregate pieces of evidence from multiple reasoning paths and explain the reasoning process graphically . Experiments show that CogKR substantially outperforms previous state-ofthe-art models on one-shot KG reasoning benchmarks , with relative improvements of 24 .3 % -29 .7 % on MRR 1 . $SEP$ We study the problem of learning to reason in large scale knowledge graphs . More specifically , we describe a novel reinforcement learning framework for learning multi-hop relational paths : we use a policy-based agent with continuous states based on knowledge graph embeddings , which reasons in a KG vector space by sampling the most promising relation to extend its path . In contrast to prior work , our approach includes a reward function that takes the accuracy , diversity , and efficiency into consideration . Experimentally , we show that our proposed method outperforms a path-ranking based algorithm and knowledge graph embedding methods on Freebase and Never-Ending Language Learning datasets . 1 $FULLTEXT$ In recent years , deep learning techniques have obtained many state-of-the-art results in various $SEPB$ Knowledge bases , both automatically and manually constructed , are often incomplete -many valid facts can be inferred from the KB by synthesizing existing information . A popular approach to KB completion is to infer new relations by combinatory reasoning over the information found along other paths connecting a pair of entities . Given the enormous size of KBs and the exponential number of paths , previous path-based models have considered only the problem of predicting a missing relation given two entities , or evaluating the truth of a proposed triple . Additionally , these methods have traditionally used random paths between fixed entity pairs or more recently learned to pick paths between them . We propose a new algorithm , MINERVA 1 , which addresses the much $SEPB$ Learning to walk over a graph towards a target node for a given query and a source node is an important problem in applications such as knowledge base completion . It can be formulated as a reinforcement learning problem with a known state transition model . To overcome the challenge of sparse rewards , we develop a graph-walking agent called M-Walk , which consists of a deep recurrent neural network and Monte Carlo Tree Search . The RNN encodes the state and maps it separately to a policy and Q-values . In order to effectively train the agent from sparse rewards , we combine MCTS with the neural policy to generate trajectories yielding more positive rewards . From these trajectories , the network is improved in an off-policy $SEPB$ Inferring missing links in knowledge graphs has attracted a lot of attention from the research community . In this paper , we tackle a practical query answering task involving predicting the relation of a given entity pair . We frame this prediction problem as an inference problem in a probabilistic graphical model and aim at resolving it from a variational inference perspective . In order to model the relation between the query entity pair , we assume that there exists an underlying latent variable in the KG , which carries the equivalent semantics of their relations . However , due to the intractability of connections in large KGs , we propose to use variation inference to maximize the evidence lower bound . More specifically , our framework is $SEPB$ Our goal is to combine the rich multi-step inference of symbolic logical reasoning together with the generalization capabilities of vector embeddings and neural networks . We are particularly interested in complex reasoning about the entities and relations in knowledge bases . Recently Neelakantan et al . presented a compelling methodology using recurrent neural networks to compose the meaning of relations in a Horn clause consisting of a connected chain . However , this work has multiple weaknesses : it accounts for relations but not entities ; it limits generalization by training many separate models ; it does not combine evidence over multiple paths . In this paper we address all these weaknesses , making key strides towards our goal of rich logical reasoning with neural networks : our $SEPB$ We study the problem of learning to reason in large scale knowledge graphs . More specifically , we describe a novel reinforcement learning framework for learning multi-hop relational paths : we use a policy-based agent with continuous states based on knowledge graph embeddings , which reasons in a KG vector space by sampling the most promising relation to extend its path . In contrast to prior work , our approach includes a reward function that takes the accuracy , diversity , and efficiency into consideration . Experimentally , we show that our proposed method outperforms a path-ranking based algorithm and knowledge graph embedding methods on Freebase and Never-Ending Language Learning datasets . 1 $FULLTEXT$ In recent years , deep learning techniques have obtained many state-of-the-art results in various $SEPB$ Knowledge bases , both automatically and manually constructed , are often incomplete -many valid facts can be inferred from the KB by synthesizing existing information . A popular approach to KB completion is to infer new relations by combinatory reasoning over the information found along other paths connecting a pair of entities . Given the enormous size of KBs and the exponential number of paths , previous path-based models have considered only the problem of predicting a missing relation given two entities , or evaluating the truth of a proposed triple . Additionally , these methods have traditionally used random paths between fixed entity pairs or more recently learned to pick paths between them . We propose a new algorithm , MINERVA 1 , which addresses the much $SEPB$ Multi-hop reasoning is an effective approach for query answering over incomplete knowledge graphs . The problem can be formulated in a reinforcement learning setup , where a policy-based agent sequentially extends its inference path until it reaches a target . However , in an incomplete KG environment , the agent receives low-quality rewards corrupted by false negatives in the training data , which harms generalization at test time . Furthermore , since no golden action sequence is used for training , the agent can be misled by spurious search trajectories that incidentally lead to the correct answer . We propose two modeling advances to address both issues : we reduce the impact of false negative supervision by adopting a pretrained onehop embedding model to estimate the reward of $SEPB$ Learning to walk over a graph towards a target node for a given query and a source node is an important problem in applications such as knowledge base completion . It can be formulated as a reinforcement learning problem with a known state transition model . To overcome the challenge of sparse rewards , we develop a graph-walking agent called M-Walk , which consists of a deep recurrent neural network and Monte Carlo Tree Search . The RNN encodes the state and maps it separately to a policy and Q-values . In order to effectively train the agent from sparse rewards , we combine MCTS with the neural policy to generate trajectories yielding more positive rewards . From these trajectories , the network is improved in an off-policy $SEPB$ Inferring missing links in knowledge graphs has attracted a lot of attention from the research community . In this paper , we tackle a practical query answering task involving predicting the relation of a given entity pair . We frame this prediction problem as an inference problem in a probabilistic graphical model and aim at resolving it from a variational inference perspective . In order to model the relation between the query entity pair , we assume that there exists an underlying latent variable in the KG , which carries the equivalent semantics of their relations . However , due to the intractability of connections in large KGs , we propose to use variation inference to maximize the evidence lower bound . More specifically , our framework is $SEPB$ Recent studies on knowledge base completion , the task of recovering missing relationships based on recorded relations , demonstrate the importance of learning embeddings from multi-step relations . However , due to the size of knowledge bases , learning multi-step relations directly on top of observed triplets could be costly . Hence , a manually designed procedure is often used when training the models . In this paper , we propose Implicit ReasoNets , which is designed to perform multi-step inference implicitly through a controller and shared memory . Without a human-designed inference procedure , IRNs use training data to learn to perform multi-step inference in an embedding neural space through the shared memory and controller . While the inference procedure does not explicitly operate on top of
2	It mitigates the cost of running back propagation over the full training data and comes with various theoretical guarantees as well Hardt et al ; Raginsky et al . The reader will notice that part of the reason that constraints have not been intensively explored in a broader range of problems may have to do with the interplay between constraints and the SGD algorithm Márquez-Neila et al . While some regularizers and "local" constraints are easily handled within SGD , some others require a great deal of care and can adversely affect convergence and practical runtime Bengio . These include adaptive sub-gradient methods such as Adagrad Duchi et al , the RMSprop algorithm Dauphin et al which addresses the issue of illconditioning in Deep Networks with a normalized form of SGD , and various adaptive schemes for learning rate adjustments Zeiler and utilizing the momentum method Kingma and Ba . $SEP$ A number of results have recently demonstrated the benefits of incorporating various constraints when training deep architectures in vision and machine learning . The advantages range from guarantees for statistical generalization to better accuracy to compression . But support for general constraints within widely used libraries remains scarce and their broader deployment within many applications that can benefit from them remains under-explored . Part of the reason is that Stochastic gradient descent , the workhorse for training deep neural networks , does not natively deal with constraints with global scope very well . In this paper , we revisit a classical first order scheme from numerical optimization , Conditional Gradients , that has , thus far had limited applicability in training deep models . We show via rigorous analysis how various constraints can be naturally handled by modifications of this algorithm . We provide convergence guarantees and show a suite of immediate benefits that are possible -from training ResNets with fewer layers but better accuracy simply by substituting in our version of CG to faster training of GANs with 50 % fewer epochs in image inpainting applications to provably better generalization guarantees using efficiently implementable forms of recently proposed regularizers $SEP$ We show that parametric models trained by a stochastic gradient method with few iterations have vanishing generalization error . We prove our results by arguing that SGM is algorithmically stable in the sense of Bousquet and Elisseeff . Our analysis only employs elementary tools from convex and continuous optimization . We derive stability bounds for both convex and non-convex optimization under standard Lipschitz and smoothness assumptions .Applying our results to the convex case , we provide new insights for why multiple epochs of stochastic gradient methods generalize well in practice . In the non-convex case , we give a new interpretation of common practices in neural networks , and formally show that popular techniques for training large deep models are indeed stability-promoting . Our findings conceptually underscore the $SEPB$ Stochastic Gradient Langevin Dynamics is a popular variant of Stochastic Gradient Descent , where properly scaled isotropic Gaussian noise is added to an unbiased estimate of the gradient at each iteration . This modest change allows SGLD to escape local minima and suffices to guarantee asymptotic convergence to global minimizers for sufficiently regular nonconvex objectives .The present work provides a nonasymptotic analysis in the context of non-convex learning problems : SGLD requiresÕ iterations to sampleÕ -approximate minimizers of both empirical and population risk , whereÕ hides polynomial dependence on a temperature parameter , the model dimension , and a certain spectral gap parameter .As in the asymptotic setting , our analysis relates the discrete-time SGLD Markov chain to a continuous-time diffusion process . A new tool that drives $SEPB$ Imposing constraints on the output of a Deep Neural Net is one way to improve the quality of its predictions while loosening the requirements for labeled training data . Such constraints are usually imposed as soft constraints by adding new terms to the loss function that is minimized during training . An alternative is to impose them as hard constraints , which has a number of theoretical benefits but has not been explored so far due to the perceived intractability of the problem .In this paper , we show that imposing hard constraints can in fact be done in a computationally feasible way and delivers reasonable results . However , the theoretical benefits do not materialize and the resulting technique is no better than existing ones relying on $SEPB$ Learning algorithms related to artificial neural networks and in particular for Deep Learning may seem to involve many bells and whistles , called hyperparameters . This chapter is meant as a practical guide with recommendations for some of the most commonly used hyper-parameters , in particular in the context of learning algorithms based on backpropagated gradient and gradient-based optimization . It also discusses how to deal with the fact that more interesting results can be obtained when allowing one to adjust many hyper-parameters . Overall , it describes elements of the practice used to successfully and efficiently train and debug large-scale and often deep multi-layer neural networks . It closes with open questions about the training difficulties observed with deeper architectures . $FULLTEXT$ Following a decade of lower $SEPB$ We present a novel per-dimension learning rate method for gradient descent called ADADELTA . The method dynamically adapts over time using only first order information and has minimal computational overhead beyond vanilla stochastic gradient descent . The method requires no manual tuning of a learning rate and appears robust to noisy gradient information , different model architecture choices , various data modalities and selection of hyperparameters . We show promising results compared to other methods on the MNIST digit classification task using a single machine and on a large scale voice dataset in a distributed cluster environment . $FULLTEXT$ The aim of many machine learning methods is to update a set of parameters x in order to optimize an objective function f . This often involves some iterative $SEPB$ We introduce Adam , an algorithm for first-order gradient-based optimization of stochastic objective functions . The method is straightforward to implement and is based on adaptive estimates of lower-order moments of the gradients . The method is computationally efficient , has little memory requirements and is well suited for problems that are large in terms of data and/or parameters . The method is also appropriate for non-stationary objectives and problems with very noisy and/or sparse gradients . The method exhibits invariance to diagonal rescaling of the gradients by adapting to the geometry of the objective function . The hyper-parameters have intuitive interpretations and typically require little tuning . Some connections to related algorithms , on which Adam was inspired , are discussed . We also analyze the theoretical
0	The GAN our pipeline uses is based on the architecture by Isola et al #CITE# , augmented with foreground-similarity and task-specific losses similar to those introduced by Bousmalis et al #CITE# . $SEP$ With the increasing availability of large databases of 3D CAD models , methods for depth-based recognition of localized objects can be trained on an uncountable number of synthetically rendered images . However , discrepancies with the real data acquired from various depth sensors still noticeably impede progress . Previous works adopted unsupervised approaches to generate more realistic depth data , but they all require real scans for training , even if unlabeled . This still represents a strong requirement , especially when considering real-life/industrial settings where real training images are hard or impossible to acquire , but texture-less 3D models are available . We thus propose a novel approach leveraging only CAD models to bridge the realism gap . Purely trained on synthetic data , playing against an extensive augmentation pipeline in an unsupervised manner , our generative adversarial network learns to effectively segment depth images and recover the clean synthetic-looking depth information even from partial occlusions . As our solution is not only fully decoupled from the real domains but also from the task-specific analytics , the pre-processed scans can be handed to any kind and number of recognition methods also trained on synthetic data . Through various experiments $SEP$ The cost of large scale data collection and annotation often makes the application of machine learning algorithms to new tasks or datasets prohibitively expensive . One approach circumventing this cost is training models on synthetic data where annotations are provided automatically . Despite their appeal , such models often fail to generalize from synthetic to real images , necessitating domain adaptation algorithms to manipulate these models before they can be successfully applied . Existing approaches focus either on mapping representations from one domain to the other , or on learning to extract features that are invariant to the domain from which they were extracted . However , by focusing only on creating a mapping or shared representation between the two domains , they ignore the individual characteristics of $SEPB$ Collecting well-annotated image datasets to train modern machine learning algorithms is prohibitively expensive for many tasks . One appealing alternative is rendering synthetic data where ground-truth annotations are generated automatically . Unfortunately , models trained purely on rendered images often fail to generalize to real images . To address this shortcoming , prior work introduced unsupervised domain adaptation algorithms that attempt to map representations between the two domains or learn to extract features that are domain-invariant . In this work , we present a new approach that learns , in an unsupervised manner , a transformation in the pixel space from one domain to the other . Our generative adversarial network -based model adapts source-domain images to appear as if drawn from the target domain . Our approach
0	Pervez et al #CITE# and Pahic et al #CITE# learn DMPs from images using neural networks . $SEP$ Most current methods for learning from demonstrations assume that those demonstrations alone are sufficient to learn the underlying task . This is often untrue , especially if extra safety specifications exist which were not present in the original demonstrations . In this paper , we allow an expert to elaborate on their original demonstration with additional specification information using linear temporal logic . Our system converts LTL specifications into a differentiable loss . This loss is then used to learn a dynamic movement primitive that satisfies the underlying specification , while remaining close to the original demonstration . Further , by leveraging adversarial training , our system learns to robustly satisfy the given LTL specification on unseen inputs , not just those seen in training . We show that our method is expressive enough to work across a variety of common movement specification patterns such as obstacle avoidance , patrolling , keeping steady , and speed limitation . In addition , we show that our system can modify a base demonstration with complex specifications by incrementally composing multiple simpler specifications . We also implement our system on a PR-2 robot to show how a demonstrator can start with an initial $SEP$ Abstract-Dynamic Movement Primitives are widely used for encoding motion data . Task parameterized DMP can adapt a learned skill to different situations . Mostly a customized vision system is used to extract task specific variables . This limits the use of such systems to real world scenarios . This paper proposes a method for combining the DMP with a Convolutional Neural Network . Our approach preserves the generalization properties associated with a DMP , while the CNN learns the task specific features from the camera images . This eliminates the need to extract the task parameters , by directly utilizing the camera image during the motion reproduction . The performance of the developed approach is demonstrated through a trash cleaning task , executed with a real robot . $SEPB$ Abstract-In this paper we propose a new approach for learning perception-action couplings . We show that by collecting a suitable set of raw images and the associated movement trajectories , a deep encoder-decoder network can be trained that takes raw images as input and outputs the corresponding dynamic movement primitives . We propose suitable cost functions for training the network and describe how to calculate their gradients to enable effective training by back-propagation . We tested the proposed approach both on a synthetic dataset and on a widely used MNIST database to generate handwriting movements from raw images of digits . The calculated movements were also applied for digit writing with a real robot . $FULLTEXT$ Autonomous cognitive robots are expected to be able to perceive their environment
0	Domain adaptation has been studied under many different settings: two domains or multiple domains or unlabeled , paired examples from source and target domain , or domain features attached with each domain . Domain adaptation techniques have been applied to numerous tasks in speech , language processing and computer vision . $SEP$ We present CROSSGRAD , a method to use multi-domain training data to learn a classifier that generalizes to new domains . CROSSGRAD does not need an adaptation phase via labeled or unlabeled data , or domain features in the new domain . Most existing domain adaptation methods attempt to erase domain signals using techniques like domain adversarial training . In contrast , CROSSGRAD is free to use domain signals for predicting labels , if it can prevent overfitting on training domains . We conceptualize the task in a Bayesian setting , in which a sampling step is implemented as data augmentation , based on domain-guided perturbations of input instances . CROSSGRAD parallelly trains a label and a domain classifier on examples perturbed by loss gradients of each other 's objectives . This enables us to directly perturb inputs , without separating and re-mixing domain signals while making various distributional assumptions . Empirical evaluation on three different applications where this setting is natural establishes that domain-guided perturbation provides consistently better generalization to unseen domains , compared to generic instance perturbation methods , and that data augmentation is a more stable and accurate method than domain adversarial training . $SEP$ We introduce a new representation learning approach for domain adaptation , in which data at training and test time come from similar but different distributions . Our approach is directly inspired by the theory on domain adaptation suggesting that , for effective domain transfer to be achieved , predictions must be made based on features that can not discriminate between the training and test domains .The approach implements this idea in the context of neural network architectures that are trained on labeled data from the source domain and unlabeled data from the target domain . As the training progresses , the approach promotes the emergence of features that are discriminative for the main learning task on the source domain and indiscriminate with respect to the shift between the $SEPB$ Adversarial learning methods are a promising approach to training robust deep networks , and can generate complex samples across diverse domains . They can also improve recognition despite the presence of domain shift or dataset bias : recent adversarial approaches to unsupervised domain adaptation reduce the difference between the training and test domain distributions and thus improve generalization performance . However , while generative adversarial networks show compelling visualizations , they are not optimal on discriminative tasks and can be limited to smaller shifts . On the other hand , discriminative approaches can handle larger domain shifts , but impose tied weights on the model and do not exploit a GAN-based loss . In this work , we first outline a novel generalized framework for adversarial adaptation , $SEPB$ We describe an approach to domain adaptation that is appropriate exactly in the case when one has enough `` target '' data to do slightly better than just using only `` source '' data . Our approach is incredibly simple , easy to implement as a preprocessing step and outperforms stateof-the-art approaches on a range of datasets . Moreover , it is trivially extended to a multidomain adaptation problem , where one has data from a variety of different domains . $FULLTEXT$ The task of domain adaptation is to develop learning algorithms that can be easily ported from one domain to another-say , from newswire to biomedical documents . This problem is particularly interesting in NLP because we are often in the situation that we have a large $SEPB$ In real-world applications of visual recognition , many factors-such as pose , illumination , or image quality-can cause a significant mismatch between the source domain on which classifiers are trained and the target domain to which those classifiers are applied . As such , the classifiers often perform poorly on the target domain . Domain adaptation techniques aim to correct the mismatch . Existing approaches have concentrated on learning feature representations that are invariant across domains , and they often do not directly exploit low-dimensional structures that are intrinsic to many vision datasets . In this paper , we propose a new kernel-based method that takes advantage of such structures . Our geodesic flow kernel models domain shift by integrating an infinite number of subspaces that characterize changes $SEPB$ We introduce a new representation learning approach for domain adaptation , in which data at training and test time come from similar but different distributions . Our approach is directly inspired by the theory on domain adaptation suggesting that , for effective domain transfer to be achieved , predictions must be made based on features that can not discriminate between the training and test domains .The approach implements this idea in the context of neural network architectures that are trained on labeled data from the source domain and unlabeled data from the target domain . As the training progresses , the approach promotes the emergence of features that are discriminative for the main learning task on the source domain and indiscriminate with respect to the shift between the $SEPB$ Domain adaptation is an important problem in natural language processing due to the lack of labeled data in novel domains . In this paper , we study the domain adaptation problem from the instance weighting perspective . We formally analyze and characterize the domain adaptation problem from a distributional view , and show that there are two distinct needs for adaptation , corresponding to the different distributions of instances and classification functions in the source and the target domains . We then propose a general instance weighting framework for domain adaptation . Our empirical results on three NLP tasks show that incorporating and exploiting more information from the target domain through instance weighting is effective . $FULLTEXT$ Many natural language processing problems such as part-of-speech tagging , named $SEPB$ We describe an approach to domain adaptation that is appropriate exactly in the case when one has enough `` target '' data to do slightly better than just using only `` source '' data . Our approach is incredibly simple , easy to implement as a preprocessing step and outperforms stateof-the-art approaches on a range of datasets . Moreover , it is trivially extended to a multidomain adaptation problem , where one has data from a variety of different domains . $FULLTEXT$ The task of domain adaptation is to develop learning algorithms that can be easily ported from one domain to another-say , from newswire to biomedical documents . This problem is particularly interesting in NLP because we are often in the situation that we have a large $SEPB$ Gatys et al . recently introduced a neural algorithm that renders a content image in the style of another image , achieving so-called style transfer . However , their framework requires a slow iterative optimization process , which limits its practical application . Fast approximations with feed-forward neural networks have been proposed to speed up neural style transfer . Unfortunately , the speed improvement comes at a cost : the network is usually tied to a fixed set of styles and can not adapt to arbitrary new styles . In this paper , we present a simple yet effective approach that for the first time enables arbitrary style transfer in real-time . At the heart of our method is a novel adaptive instance normalization layer that aligns the $SEPB$ We propose a new neural network architecture for solving single-image analogies-the generation of an entire set of stylistically similar images from just a single input image . Solving this problem requires separating image style from content . Our network is a modified variational autoencoder that supports supervised training of singleimage analogies and in-network evaluation of outputs with a structured similarity objective that captures pixel covariances . On the challenging task of generating a 62-letter font from a single example letter we produce images with 22 .4 % lower dissimilarity to the ground truth than state-of-the-art . $FULLTEXT$ Separating image style from content is an important problem in vision and graphics . One key application is analogies : if we can separate an image into style and content factors
1	In previous work , style controls have been explored with various conditioning attributes providing variational information , eg , discriminant codes #CITE# , unsupervised clustered labels #CITE# , style tokens #CITE# , etc . #CITE# proposed to learn style control information by training separated decision trees for differThis work was done when Xixin Wu was an intern at Tencent AI Lab *Corresponding author ent styles in hidden Markov model -based synthesis system . #CITE# and #CITE# proposed to feed speaker codes to input or hidden layers of deep neural network for performing multi-speaker synthesis . #CITE# incorporated latent variables to model emotional variation in training data with predefined partitions . #CITE# investigated different representations of emotional labels . $SEP$ Synthesizing expressive speech with appropriate prosodic variations , eg , various styles , still has much room for improvement . Previous methods have explored to use manual annotations as conditioning attributes to provide variation information . However , the related training data are expensive to obtain and the annotated style codes can be ambiguous and unreliable . In this paper , we explore utilizing the residual error as conditioning attributes . The residual error is the difference between the prediction of a trained average model and the ground truth . We encode the residual error into a style embedding via a neural networkbased error encoder . The style embedding is then fed to the target synthesis model to provide information for modeling various style distributions more accurately . The average model and the error encoder are jointly optimized with the target synthesis model . Our proposed method has two advantages : 1 ) the embedding is automatically learned with no need of manual style annotations , which helps overcome data sparsity and ambiguity limitations ; 2 ) For any unseen audio utterance , the style embedding can be efficiently generated . This enables rapid adaptation to the desired style to $SEP$ Recent studies have shown that DNN-based speech synthesis can produce more natural synthesized speech than the conventional HMM-based speech synthesis . However , an open problem remains as to whether the synthesized speech quality can be improved by utilizing a multi-speaker speech corpus . To address this problem , this paper proposes DNN-based speech synthesis using speaker codes as a simple method to improve the performance of the conventional speaker dependent DNN-based method . In order to model speaker variation in the DNN , the augmented feature is fed to the hidden layer of the conventional DNN . The proposed method trains connection weights of the whole DNN using a multispeaker speech corpus . When synthesizing a speech parameter sequence , a target speaker is chosen from the $SEPB$ Prosodic modeling is a core problem in speech synthesis . The key challenge is producing desirable prosody from textual input containing only phonetic information . In this preliminary study , we introduce the concept of `` style tokens '' in Tacotron , a recently proposed end-to-end neural speech synthesis model . Using style tokens , we aim to extract independent prosodic styles from training data . We show that without annotation data or an explicit supervision signal , our approach can automatically learn a variety of prosodic variations in a purely data-driven way . Importantly , each style token corresponds to a fixed style factor regardless of the given text sequence . As a result , we can control the prosodic style of synthetic speech in a somewhat $SEPB$ Recent studies have shown that DNN-based speech synthesis can produce more natural synthesized speech than the conventional HMM-based speech synthesis . However , an open problem remains as to whether the synthesized speech quality can be improved by utilizing a multi-speaker speech corpus . To address this problem , this paper proposes DNN-based speech synthesis using speaker codes as a simple method to improve the performance of the conventional speaker dependent DNN-based method . In order to model speaker variation in the DNN , the augmented feature is fed to the hidden layer of the conventional DNN . The proposed method trains connection weights of the whole DNN using a multispeaker speech corpus . When synthesizing a speech parameter sequence , a target speaker is chosen from the $SEPB$ For building flexible and appealing high-quality speech synthesisers , it is desirable to be able to accommodate and reproduce fine variations in vocal expression present in natural speech . Synthesisers can enable control over such output properties by adding adjustable control parameters in parallel to their text input . If not annotated in training data , the values of these control inputs can be optimised jointly with the model parameters . We describe how this established method can be seen as approximate maximum likelihood and MAP inference in a latent variable model . This puts previous ideas of synthesiser inputs such as sentence-level control vectors on a more solid theoretical footing . We furthermore extend the method by restricting the latent variables to orthogonal subspaces via a sparse
0	Schneider et al #CITE# propose a method in which each object is grasped several times , learning a vocabulary from the tactile observations . Chitta et 978-1-5386-3157-7/17/$31 .00 ©2017 IEEE Proceedings of the 2017 18th International Conference on Advanced Robotics Hong Kong , China , July 2017 al . #CITE# propose a method that , using features extracted while grasping and compressing the object , can infer if they are empty or full and open or close . $SEP$ Abstract-In this paper we propose a novel method for in-hand object recognition . The method is composed of a grasp stabilization controller and two exploratory behaviours to capture the shape and the softness of an object . Grasp stabilization plays an important role in recognizing objects . First , it prevents the object from slipping and facilitates the exploration of the object . Second , reaching a stable and repeatable position adds robustness to the learning algorithm and increases invariance with respect to the way in which the robot grasps the object . The stable poses are estimated using a Gaussian mixture model . We present experimental results showing that using our method the classifier can successfully distinguish 30 objects . We also compare our method with a benchmark experiment , in which the grasp stabilization is disabled . We show , with statistical significance , that our method outperforms the benchmark method . $SEP$ Abstract-In this paper , we present a novel approach for identifying objects using touch sensors installed in the finger tips of a manipulation robot . Our approach operates on low-resolution intensity images that are obtained when the robot grasps an object . We apply a bag-of-words approach for object identification . By means of unsupervised clustering on training data , our approach learns a vocabulary from tactile observations which is used to generate a histogram codebook . The histogram codebook models distributions over the vocabulary and is the core identification mechanism . As the objects are larger than the sensor , the robot typically needs multiple grasp actions at different positions to uniquely identify an object . To reduce the number of required grasp actions , we apply $SEPB$ Abstract-Tactile information is valuable in determining properties of objects that are inaccessible from visual perception . In this work , we present a tactile perception strategy that allows any mobile robot with tactile sensors in its gripper to measure a set of generic tactile features while grasping an object . We propose a hybrid velocity-force controller , that grasps an object safely and reveals at the same time its deformation properties . As an application , we show that a robot can use these features to distinguish the open/closed and fill state of bottles and cans -purely from tactile sensing -from a small training set . To prove that this is a hard recognition problem , we also conducted a comperative study with 17 human test subjects .
2	While a significant number of regression modelling techniques have been proposed for emotion predictions , the most widely adopted models are Support Vector Regression #CITE# owing to its robustness , and Long-short term memory recurrent neural network #CITE# which captures the temporal dynamics of emotion . $SEP$ Speech based continuous emotion prediction systems have predominantly been based on complex non-linear back-ends , with an increasing attention on long-short term memory recurrent neural networks . While this has led to accurate predictions , complex models may suffer from issues with interpretability , model selection and overfitting . In this paper , we demonstrate that a linear model can capture most of the relationship between speech features and emotion labels in the continuous arousal-valence space . Specifically , an autoregressive exogenous model is shown to be an effective backend . This approach is validated on three commonly used databases , namely RECOLA , SEWA and USC CreativeIT , and shown to be comparable in terms of performance to state-of-the-art LSTM systems . More importantly , this approach allows for the use of well-established linear system theory to aid with model interpretability . $SEP$ In this paper , a prediction-based learning framework is proposed for a continuous prediction task of emotion recognition from speech , which is one of the key components of affective computing in multimedia . The main goal of this framework is to utmost exploit the individual advantages of different regression models cooperatively . To this end , we take two widely used regression models for example , i . e . , support vector regression and bidirectional long short-term memory recurrent neural network . We concatenate the two models in a tandem structure by different ways , forming a united cascaded framework . The outputs predicted by the former model are combined together with the original features as the input of the following model for final predictions . $SEPB$ Estimating continuous emotional states from speech as a function of time has traditionally been framed as a regression problem . In this paper , we present a novel approach that moves the problem into the classification domain by discretizing the training labels at different resolutions . We employ a multi-task deep bidirectional long-short term memory recurrent neural network trained with cost-sensitive Cross Entropy loss to model these labels jointly . We introduce an emotion decoding algorithm that incorporates long-and short-term temporal properties of the signal to produce more robust time series estimates . We show that our proposed approach achieves competitive audio-only performance on the RECOLA dataset , relative to previously published works as well as other strong regression baselines . This work provides a link between regression $SEPB$ To advance the performance of continuous emotion recognition from speech , we introduce a reconstruction-error-based learning framework with memory-enhanced Recurrent Neural Networks . In the framework , two successive RNN models are adopted , where the first model is used as an autoencoder for reconstructing the original features , and the second is employed to perform emotion prediction . The RE of the original features is used as a complementary descriptor , which is merged with the original features and fed to the second model . The assumption of this framework is that the system has the ability to learn its 'drawback ' which is expressed by the RE . Experimental results on the RECOLA database show that the proposed framework significantly outperforms the baseline systems without any
1	Another category of the unsupervised method makes use of additional information . Recently , crossdomain transfer learning is used in the unsupervised re-ID task , where information from an external source dataset is utilized . Wang et al propose to learn an attributesemantic and identity discriminative representation from the source dataset , which is transferable to the target domain . There are also some recent works focusing on the unsupervised video-based re-ID . $SEP$ Most person re-identification approaches are based on supervised learning , which requires intensive manual annotation for training data . However , it is not only resourceintensive to acquire identity annotation but also impractical to label the large-scale real-world data . To relieve this problem , we propose a bottom-up clustering approach to jointly optimize a convolutional neural network and the relationship among the individual samples . Our algorithm considers two fundamental facts in the re-ID task , ie , diversity across different identities and similarity within the same identity . Specifically , our algorithm starts with regarding individual sample as a different identity , which maximizes the diversity over each identity . Then it gradually groups similar samples into one identity , which increases the similarity within each identity . We utilizes a diversity regularization term in the bottom-up clustering procedure to balance the data volume of each cluster . Finally , the model achieves an effective trade-off between the diversity and similarity . We conduct extensive experiments on the large-scale image and video re-ID datasets , including Market-1501 , DukeMTMC-reID , MARS and DukeMTMC-VideoReID . The experimental results demonstrate that our algorithm is not only superior to state-of-the-art unsupervised $SEP$ In this paper , we present supervision-by-registration , an unsupervised approach to improve the precision of facial landmark detectors on both images and video . Our key observation is that the detections of the same landmark in adjacent frames should be coherent with registration , ie , optical flow . Interestingly , coherency of optical flow is a source of supervision that does not require manual labeling , and can be leveraged during detector training . For example , we can enforce in the training loss function that a detected landmark at frame t−1 followed by optical flow tracking from frame t−1 to frame t should coincide with the location of the detection at frame t . Essentially , supervisionby-registration augments the training loss function with a registration $SEPB$ Most existing person re-identification $FULLTEXT$ Person re-identification is the problem of matching people across non-overlapping camera views . It has become one of the most studied problems in video surveillance due to its great potentials for security and safety management applications . Despite the best efforts from the computer vision researchers , it remains an unsolved problem . This is because a person 's appearance often changes dramatically across camera views due to changes in body pose , view angle , occlusion and illumination conditions .To address these challenges , most existing research efforts on Re-ID are based on supervised learning . Specifically , they require a large number of labelled matching pairs across each two camera views to learn a representation or matching function that is invariant $SEPB$ Person re-identification models trained on one domain often fail to generalize well to another . In our attempt , we present a `` learning via translation '' framework . In the baseline , we translate the labeled images from source to target domain in an unsupervised manner . We then train re-ID models with the translated images by supervised methods . Yet , being an essential part of this framework , unsupervised image-image translation suffers from the information loss of source-domain labels during translation .Our motivation is two-fold . First , for each image , the discriminative cues contained in its ID label should be maintained after translation . Second , given the fact that two domains have entirely different persons , a translated image should be dissimilar $SEPB$ Most existing person re-identification methods require supervised model learning from a separate large set of pairwise labelled training data for every single camera pair . This significantly limits their scalability and usability in real-world large scale deployments with the need for performing re-id across many camera views . To address this scalability problem , we develop a novel deep learning method for transferring the labelled information of an existing dataset to a new unseen target domain for person re-id without any supervised learning in the target domain . Specifically , we introduce an Transferable Joint Attribute-Identity Deep Learning for simultaneously learning an attribute-semantic and identitydiscriminative feature representation space transferrable to any new target domain for re-id tasks without the need for collecting new labelled training data from the $SEPB$ Most existing person re-identification methods require supervised model learning from a separate large set of pairwise labelled training data for every single camera pair . This significantly limits their scalability and usability in real-world large scale deployments with the need for performing re-id across many camera views . To address this scalability problem , we develop a novel deep learning method for transferring the labelled information of an existing dataset to a new unseen target domain for person re-id without any supervised learning in the target domain . Specifically , we introduce an Transferable Joint Attribute-Identity Deep Learning for simultaneously learning an attribute-semantic and identitydiscriminative feature representation space transferrable to any new target domain for re-id tasks without the need for collecting new labelled training data from the $SEPB$ Label estimation is an important component in an unsupervised person re-identification system . This paper focuses on cross-camera label estimation , which can be subsequently used in feature learning to learn robust re-ID models . Specifically , we propose to construct a graph for samples in each camera , and then graph matching scheme is introduced for cross-camera labeling association . While labels directly output from existing graph matching methods may be noisy and inaccurate due to significant crosscamera variations , this paper propose a dynamic graph matching method . DGM iteratively updates the image graph and the label estimation process by learning a better feature space with intermediate estimated labels . DGM is advantageous in two aspects : 1 ) the accuracy of estimated labels is improved
1	Some approaches to certifying confidentiality use programming languages that can express information-flow policies #CITE# . $SEP$ Hardware support for isolated execution enables development of applications that keep their code and data confidential even while running on a hostile or compromised host . However , automatically verifying that such applications satisfy confidentiality remains challenging . We present a methodology for designing such applications in a way that enables certifying their confidentiality . Our methodology consists of forcing the application to communicate with the external world through a narrow interface , compiling it with runtime checks that aid verification , and linking it with a small runtime library that implements the interface . The runtime library includes core services such as secure communication channels and memory management . We formalize this restriction on the application as Information Release Confinement , and we show that it allows us to decompose the task of proving confidentiality into one-time , human-assisted functional verification of the runtime to ensure that it does not leak secrets , automatic verification of the application 's machine code to ensure that it satisfies IRC and does not directly read or corrupt the runtime 's internal state . We present /CONFIDENTIAL : a verifier for IRC that is modular , automatic , and keeps our compiler out $SEP$ This paper presents a certification mechanism for verifying the secure flow of information through a program . Because it exploits the properties of a lattice structure among security classes , the procedure is sufficiently simple that it can easily be included in the analysis phase of most existing compilers . Appropriate semantics are presented and proved correct . An important application is the confinement problem : The mechanism can prove that a program can not cause supposedly nonconfidential results to depend on confidential input data . $FULLTEXT$ Computer system security relies in part on information flow control , that is , on methods of regulating the dissemination of information among objects throughout the system . An information flow policy specifies a set of security classes for information , $SEPB$ Ensuring secure information ow within programs in the context of multiple sensitivity levels has been widely studied . Especially noteworthy is Denning 's work in secure ow analysis and the lattice model 6 ] 7 ] . Until now , however , the soundness of Denning 's analysis has not been established satisfactorily . We formulate Denning 's approach as a type system and present a notion of soundness for the system that can be viewed as a form of noninterference . Soundness is established by proving , with respect to a standard programming language semantics , that all well-typed programs have this noninterference property . $FULLTEXT$ The problem of ensuring secure information ow within systems having multiple sensitivity levels has been studied extensively , beginning with the
1	Recent supervised single view reconstruction methods #CITE# require associated 3D shapes . $SEP$ Supervised 3D reconstruction has witnessed a significant progress through the use of deep neural networks . However , this increase in performance requires large scale annotations of 2D/3D data . In this paper , we explore inexpensive 2D supervision as an alternative for expensive 3D CAD annotation . Specifically , we use foreground masks as weak supervision through a raytrace pooling layer that enables perspective projection and backpropagation . Additionally , since the 3D reconstruction from masks is an ill posed problem , we propose to constrain the 3D reconstruction to the manifold of unlabeled realistic 3D shapes that match mask observations . We demonstrate that learning a log-barrier solution to this constrained optimization problem resembles the GAN objective , enabling the use of existing tools for training GANs . We evaluate and analyze the manifold constrained reconstruction on various datasets for single and multi-view reconstruction of both synthetic and real images . $SEP$ What is a good vector representation of an object ? We believe that it should be generative in 3D , in the sense that it can produce new 3D objects ; as well as be predictable from 2D , in the sense that it can be perceived from 2D images . We propose a novel architecture , called the TL-embedding network , to learn an embedding space with these properties . The network consists of two components : an autoencoder that ensures the representation is generative ; and a convolutional network that ensures the representation is predictable . This enables tackling a number of tasks including voxel prediction from 2D images and 3D model retrieval . Extensive experimental analysis demonstrates the usefulness and versatility of this embedding . $SEPB$ Understanding 3D object structure from a single image is an important but difficult task in computer vision , mostly due to the lack of 3D object annotations in real images . Previous work tackles this problem by either solving an optimization task given 2D keypoint positions , or training on synthetic data with ground truth 3D information .In this work , we propose 3D INterpreter Network , an endto-end framework which sequentially estimates 2D keypoint heatmaps and 3D object structure , trained on both real 2D-annotated images and synthetic 3D data . This is made possible mainly by two technical innovations . First , we propose a Projection Layer , which projects estimated 3D structure to 2D space , so that 3D-INN can be trained to predict 3D $SEPB$ We study the problem of 3D object generation . We propose a novel framework , namely 3D Generative Adversarial Network , which generates 3D objects from a probabilistic space by leveraging recent advances in volumetric convolutional networks and generative adversarial nets . The benefits of our model are three-fold : first , the use of an adversarial criterion , instead of traditional heuristic criteria , enables the generator to capture object structure implicitly and to synthesize high-quality 3D objects ; second , the generator establishes a mapping from a low-dimensional probabilistic space to the space of 3D objects , so that we can sample objects without a reference image or CAD models , and explore the 3D object manifold ; third , the adversarial discriminator provides a powerful
0	UCB1 , concerns with learning the single optimal action among a set of candidate actions with unknown rewards #CITE# . Combinatorial bandits extends the basic MAB by allowing multiple-play each time #CITE# and contextual bandits extends the basic MAB by considering the context-dependent reward functions #CITE# , #CITE# . $SEP$ Abstract-Shared edge computing platforms , which enable Application Service Providers to deploy applications in close proximity to mobile users are providing ultra-low latency and location-awareness to a rich portfolio of services . Though ubiquitous edge service provisioning , ie , deploying the application at all possible edge sites , is always preferable , it is impractical due to often limited operational budget of ASPs . In this case , an ASP has to cautiously decide where to deploy the edge service and how much budget it is willing to use . A central issue here is that the service demand received by each edge site , which is the key factor of deploying benefit , is unknown to ASPs a priori . What 's more complicated is that this demand pattern varies temporally and spatially across geographically distributed edge sites . In this paper , we investigate an edge resource rental problem where the ASP learns service demand patterns for individual edge sites while renting computation resource at these sites to host its applications for edge service provisioning . An online algorithm , called Context-aware Online Edge Resource Rental , is proposed based on the framework of Contextual Combinatorial Multi-armed $SEP$ Abstract . Reinforcement learning policies face the exploration versus exploitation dilemma , i .e . the search for a balance between exploring the environment to find profitable actions while taking the empirically best action as often as possible . A popular measure of a policy 's success in addressing this dilemma is the regret , that is the loss due to the fact that the globally optimal policy is not followed all the times . One of the simplest examples of the exploration/exploitation dilemma is the multi-armed bandit problem . Lai and Robbins were the first ones to show that the regret for this problem has to grow at least logarithmically in the number of plays . Since then , policies which asymptotically achieve this regret have been $SEPB$ We formulate the following combinatorial multiarmed bandit problem : There are random variables with unknown mean that are each instantiated in an i .i .d . fashion over time . At each time multiple random variables can be selected , subject to an arbitrary constraint on weights associated with the selected variables . All of the selected individual random variables are observed at that time , and a linearly weighted combination of these selected variables is yielded as the reward . The goal is to find a policy that minimizes regret , defined as the difference between the reward obtained by a genie that knows the mean of each random variable , and that obtained by the given policy . This formulation is broadly applicable and useful for $SEPB$ Personalized web services strive to adapt their services to individual users by making use of both content and user information . Despite a few recent advances , this problem remains challenging for at least two reasons . First , web service is featured with dynamically changing pools of content , rendering traditional collaborative filtering methods inapplicable . Second , the scale of most web services of practical interest calls for solutions that are both fast in learning and computation .In this work , we model personalized recommendation of news articles as a contextual bandit problem , a principled approach in which a learning algorithm sequentially selects articles to serve users based on contextual information about the users and articles , while simultaneously adapting its article-selection strategy based on $SEPB$ Abstract-In this paper , we propose a novel framework for decentralized , online learning by many learners . At each moment of time , an instance characterized by a certain context may arrive to each learner ; based on the context , the learner can select one of its own actions or request assistance from another learner . In the latter case , the requester pays a cost and receives the reward but the provider learns the information . In our framework , learners are modeled as cooperative contextual bandits . Each learner seeks to maximize the expected reward from its arrivals , which involves trading off the reward received from its own actions , the information learned from its own actions , the reward received from the
2	Early works of NAS usually adopt the REINFORCE method #CITE# and evolutionary algorithms #CITE# for searching effective architectures . $SEP$ Recently , there has been a growing interest in automating the process of neural architecture design , and the Differentiable Architecture Search method makes the process available within a few GPU days . In particular , a hypernetwork called one-shot model is introduced , over which the architecture can be searched continuously with gradient descent . However , the performance of DARTS is often observed to collapse when the number of search epochs becomes large . Meanwhile , lots of `` skip-connects '' are found in the selected architectures . In this paper , we claim that the cause of the collapse is that there exist cooperation and competition in the bi-level optimization in DARTS , where the architecture parameters and model weights are updated alternatively . Therefore , we propose a simple and effective algorithm , named `` DARTS+ '' , to avoid the collapse and improve the original DARTS , by `` early stopping '' the search procedure when meeting a certain criterion . We demonstrate that the proposed early stopping criterion is effective in avoiding the collapse issue . We also conduct experiments on benchmark datasets and show the effectiveness of our DARTS+ algorithm , where DARTS+ $SEP$ We propose Efficient Neural Architecture Search , a fast and inexpensive approach for automatic model design . In ENAS , a controller discovers neural network architectures by searching for an optimal subgraph within a large computational graph . The controller is trained with policy gradient to select a subgraph that maximizes the expected reward on a validation set . Meanwhile the model corresponding to the selected subgraph is trained to minimize a canonical cross entropy loss . Sharing parameters among child models allows ENAS to deliver strong empirical performances , while using much fewer GPUhours than existing automatic model design approaches , and notably , 1000x less expensive than standard Neural Architecture Search . On the Penn Treebank dataset , ENAS discovers a novel architecture that achieves a $SEPB$ Neural networks are powerful and flexible models that work well for many difficult learning tasks in image , speech and natural language understanding . Despite their success , neural networks are still hard to design . In this paper , we use a recurrent network to generate the model descriptions of neural networks and train this RNN with reinforcement learning to maximize the expected accuracy of the generated architectures on a validation set . On the CIFAR-10 dataset , our method , starting from scratch , can design a novel network architecture that rivals the best human-invented architecture in terms of test set accuracy . Our CIFAR-10 model achieves a test error rate of 3 .65 , which is 0 .09 percent better and 1 .05x faster than $SEPB$ The effort devoted to hand-crafting neural network image classifiers has motivated the use of architecture search to discover them automatically . Although evolutionary algorithms have been repeatedly applied to neural network topologies , the image classifiers thus discovered have remained inferior to human-crafted ones . Here , we evolve an image classifierAmoebaNet-A-that surpasses hand-designs for the first time .To do this , we modify the tournament selection evolutionary algorithm by introducing an age property to favor the younger genotypes . Matching size , AmoebaNet-A has comparable accuracy to current state-of-the-art ImageNet models discovered with more complex architecture-search methods . Scaled to larger size , AmoebaNet-A sets a new state-of-theart 83 .9 % top-1 / 96 .6 % top-5 ImageNet accuracy . In a controlled comparison against a well
0	It is , of course , possible to recover unknown and varying focal length by first recovering pose and structure up to an unknown projective transform and then upgrading to Euclidean space as shown in #CITE# . $SEP$ The photorealistic modeling of large-scale scenes , such as urban structures , requires a fusion of range sensing technology and traditional digital photography . This paper presents a system that integrates multiview geometry and automated 3D registration techniques for texture mapping 2D images onto 3D range data . The 3D range scans and the 2D photographs are respectively used to generate a pair of 3D models of the scene . The first model consists of a dense 3D point cloud , produced by using a 3D-to-3D registration method that matches 3D lines in the range images . The second model consists of a sparse 3D point cloud , produced by applying a multiview geometry algorithm directly on a sequence of 2D photographs . This paper introduces a novel algorithm for automatically recovering the rotation , scale , and translation that best aligns the dense and sparse models . This alignment is necessary to enable the photographs to be optimally texture mapped onto the dense model . The contribution of this work is that it merges the benefits of multiview geometry with automated registration of 3D range scans to produce photorealistic models with minimal human interaction . We present results from $SEP$ Abstract $FULLTEXT$ There exist several different methods to make Euclidean reconstruction , tha .t is to reconstruct the object up to Euclidean transformations . However , in reconstruction without any knowledge about the scene , the scale ambiguity is always present , because it is impossible to distinguish between a large object far away and a small object close to the camera . This means that it is only possible to reconstruct the object up to similarity transformations , that is Euclidean transformation plus a uniform change of scale . In the sequel the term Eucliidean reconstruction will always mean reconstruction up to similarity transformations .It is well kn0w .n that it is possible to reconstruct an object up to similarity transformations , given images from calibrated cameras $SEPB$ This paper describes a family of factorization-based algorithms that recover 3D projective structure and motion from multiple uncalibrated perspective images of 3D points and lines . They can be viewed as generalizations of the Tomasi-Kanade algorithm from affine to fully perspective cameras , and from points to lines . They make no restrictive assumptions about scene or camera geometry , and unlike most existing reconstruction methods they do not rely on 'privileged ' points or images . All of the available image data is used , and each feature in each image is treated uniformly . The key to projective factorizatiion is the recovery of a consistent set ofprojecrive deprhs for the image points : this is done using fundamental matrices and epipoles estimated from the image data
2	volutional Neural Networks to render a content image in different styles , pioneering a new field called Neural Style Transfer . $SEP$ Prior normalization methods rely on affine transformations to produce arbitrary image style transfers , of which the parameters are computed in a pre-defined way . Such manuallydefined nature eventually results in the high-cost and shared encoders for both style and content encoding , making style transfer systems cumbersome to be deployed in resourceconstrained environments like on the mobile-terminal side . In this paper , we propose a new and generalized normalization module , termed as Dynamic Instance Normalization , that allows for flexible and more efficient arbitrary style transfers . Comprising an instance normalization and a dynamic convolution , DIN encodes a style image into learnable convolution parameters , upon which the content image is stylized . Unlike conventional methods that use shared complex encoders to encode content and style , the proposed DIN introduces a sophisticated style encoder , yet comes with a compact and lightweight content encoder for fast inference . Experimental results demonstrate that the proposed approach yields very encouraging results on challenging style patterns and , to our best knowledge , for the first time enables an arbitrary style transfer using MobileNet-based lightweight architecture , leading to a reduction factor of more than twenty in computational $SEP$ Abstract . We consider image transformation problems , where an input image is transformed into an output image . Recent methods for such problems typically train feed-forward convolutional neural networks using a per-pixel loss between the output and ground-truth images . Parallel work has shown that high-quality images can be generated by defining and optimizing perceptual loss functions based on high-level features extracted from pretrained networks . We combine the benefits of both approaches , and propose the use of perceptual loss functions for training feed-forward networks for image transformation tasks . We show results on image style transfer , where a feed-forward network is trained to solve the optimization problem proposed by Gatys et al in real-time . Compared to the optimization-based method , our network gives
0	• BTF : BTF is an alternative heuristic that might be used by an ISP #CITE# . Note that the algorithms proposed in #CITE# cannot be extended to cover the ingress-to-egress route configuration problem . In #CITE# , the ingress edges of the traffic flows are assumed to be known in advance and so traffic flows going to the same prefix can be aggregated into a job as in the generalized assignment problem #CITE# . $SEP$ Abstract -The BGP ingress-to-egress route configuration problem is to find a set of paths in an ISP to carry the transit flows , such that the amount of network resources consumed is minimized without violating the bandwidth constraint on all network links . To solve the problem , we first formulate it using Integer Linear Programming . Due to the high complexity involved in ILP , a heuristic algorithm , called MPPF , is then proposed . MPPF is designed based on the idea that heavilyloaded destination prefixes should be given higher priority to select less expensive edge links and routes . Simulation results show that MPPF requires less network resources and edge link capacity than an alternative heuristic called BTF . $SEP$ Abstract-An Internet Service Provider must provide transit service for traffic between its customers and its providers and , at the same time , attempt to minimize network utilization and balance traffic according to the capacities of its border routers . Central to the selection of border routers for transit traffic flows is the Border Gateway Protocol between Autonomous Systems peers , through which route advertisements for network prefixes determine the selection of border routers for each traffic flow .This paper examines the problem of determining an optimal set of border routers for the advertisement of network prefixes so as to minimize the cost of traffic across a transit service provider 's network while maintaining egress bandwidth constraints at the border routers . Egress bandwidth constraints are considered because $SEPB$ Abstract-An Internet Service Provider must provide transit service for traffic between its customers and its providers and , at the same time , attempt to minimize network utilization and balance traffic according to the capacities of its border routers . Central to the selection of border routers for transit traffic flows is the Border Gateway Protocol between Autonomous Systems peers , through which route advertisements for network prefixes determine the selection of border routers for each traffic flow .This paper examines the problem of determining an optimal set of border routers for the advertisement of network prefixes so as to minimize the cost of traffic across a transit service provider 's network while maintaining egress bandwidth constraints at the border routers . Egress bandwidth constraints are considered because $SEPB$ Abstract-An Internet Service Provider must provide transit service for traffic between its customers and its providers and , at the same time , attempt to minimize network utilization and balance traffic according to the capacities of its border routers . Central to the selection of border routers for transit traffic flows is the Border Gateway Protocol between Autonomous Systems peers , through which route advertisements for network prefixes determine the selection of border routers for each traffic flow .This paper examines the problem of determining an optimal set of border routers for the advertisement of network prefixes so as to minimize the cost of traffic across a transit service provider 's network while maintaining egress bandwidth constraints at the border routers . Egress bandwidth constraints are considered because
2	For filter-based systems , an alternative , six-dimensional parametrization of the feature locations #CITE# can provide a remedy , supporting rotation-only motion to some extent by admitting features with an uninformative depth prior and filtering the features through multiple motion models #CITE# to constrain their uncertainty . $SEP$ We present an approach to real-time tracking and mapping that supports any type of camera motion in 3D environments , that is , general as well as rotation-only motions . Our approach effectively generalizes both a panorama mapping and tracking system and a keyframe-based Simultaneous Localization and Mapping system , behaving like one or the other depending on the camera movement . It seamlessly switches between the two and is thus able to track and map through arbitrary sequences of general and rotation-only camera movements . Key elements of our approach are to design each system component such that it is compatible with both panoramic data and Structure-from-Motion data , and the use of the 'Geometric Robust Information Criterion ' to decide whether the transformation between a given pair of frames can best be modeled with an essential matrix E , or with a homography H . Further key features are that no separate initialization step is needed , that the reconstruction is unbiased , and that the system continues to collect and map data after tracking failure , thus creating separate tracks which are later merged if they overlap . The latter is in contrast to most existing tracking $SEP$ Abstract-We present a new parametrization for point features within monocular simultaneous localization and mapping that permits efficient and accurate representation of uncertainty during undelayed initialization and beyond , all within the standard extended Kalman filter . The key concept is direct parametrization of the inverse depth of features relative to the camera locations from which they were first viewed , which produces measurement equations with a high degree of Manuscript received February 27 , 2007 ; revised September 28 , 2007 This paper has supplementary downloadable multimedia material available at http : //ieeexplore .ieee .org provided by the author . This material includes the following video files . inverseDepth_indoor .avi shows simultaneous localization and mapping , from a hand-held camera observing an indoor scene . All the processing $SEPB$ Abstract-Recent work has demonstrated the benefits of adopting a fully probabilistic SLAM approach in sequential motion and structure estimation from an image sequence . Unlike standard Structure from Motion methods , this 'monocular SLAM ' approach is able to achieve drift-free estimation with high frame-rate real-time operation , particularly benefitting from highly efficient active feature search , map management and mismatch rejection .A consistent thread in this research on real-time monocular SLAM has been to reduce the assumptions required . In this paper we move towards the logical conclusion of this direction by implementing a fully Bayesian Interacting Multiple Models framework which can switch automatically between parameter sets in a dimensionless formulation of monocular SLAM . Remarkably , our approach of full sequential probability propagation means that there
1	While the parametric based methods #CITE# can directly estimate chrominance values by training one or multiple prediction models , such as deep convolutional neural networks #CITE# or GANs #CITE# . $SEP$ Context enhancement is critical for night vision applications , especially for the dark night situation without any artificial lights . In this paper , we present the infraredto-visual algorithm , a novel unsupervised thermalto-visible image translation framework based on generative adversarial networks . IR2VI is able to learn the intrinsic characteristics from VI images and integrate them into IR images . Since the existing unsupervised GAN-based image translation approaches face several challenges , such as incorrect mapping and lack of fine details , we propose a structure connection module and a region-of-interest focal loss method to address the current limitations . Experimental results show the superiority of the IR2VI algorithm over baseline methods . $SEP$ This paper proposes a method for transferring the RGB color spectrum to near-infrared images using deep multi-scale convolutional neural networks . A direct and integrated transfer between NIR and RGB pixels is trained . The trained model does not require any user guidance or a reference image database in the recall phase to produce images with a natural appearance . To preserve the rich details of the NIR image , its high frequency features are transferred to the estimated RGB image . The presented approach is trained and evaluated on a real-world dataset containing a large amount of road scene images in summer . The dataset was captured by a multi-CCD NIR/RGB camera , which ensures a perfect pixel to pixel registration . $FULLTEXT$ In advanced driver assistance $SEPB$ This paper proposes a method for transferring the RGB color spectrum to near-infrared images using deep multi-scale convolutional neural networks . A direct and integrated transfer between NIR and RGB pixels is trained . The trained model does not require any user guidance or a reference image database in the recall phase to produce images with a natural appearance . To preserve the rich details of the NIR image , its high frequency features are transferred to the estimated RGB image . The presented approach is trained and evaluated on a real-world dataset containing a large amount of road scene images in summer . The dataset was captured by a multi-CCD NIR/RGB camera , which ensures a perfect pixel to pixel registration . $FULLTEXT$ In advanced driver assistance
0	Recently , there has been significant progress on this problem , mostly by leveraging deep Convolutional Neural Networks trained on large labeled datasets #CITE# . $SEP$ We propose a method for multi-person detection and 2-D pose estimation that achieves state-of-art results on the challenging COCO keypoints task . It is a simple , yet powerful , top-down approach consisting of two stages . In the first stage , we predict the location and scale of boxes which are likely to contain people ; for this we use the Faster RCNN detector . In the second stage , we estimate the keypoints of the person potentially contained in each proposed bounding box . For each keypoint type we predict dense heatmaps and offsets using a fully convolutional ResNet . To combine these outputs we introduce a novel aggregation procedure to obtain highly localized keypoint predictions . We also use a novel form of keypoint-based Non-Maximum-Suppression , instead of the cruder boxlevel NMS , and a novel form of keypoint-based confidence score estimation , instead of box-level scoring . Trained on COCO data alone , our final system achieves average precision of 0 .649 on the COCO test-dev set and the 0 .643 test-standard sets , outperforming the winner of the 2016 COCO keypoints challenge and other recent stateof-art . Further , by using additional in-house labeled data $SEP$ . Besides extreme variability in articulations , many of the joints are barely visible . We can guess the location of the right arm in the left image only because we see the rest of the pose and anticipate the motion or activity of the person . Similarly , the left body half of the person on the right is not visible at all . These are examples of the need for holistic reasoning . We believe that DNNs can naturally provide such type of reasoning .We propose a method for human pose estimation based on Deep Neural Networks . The pose estimation is formulated as a DNN-based regression problem towards body joints . We present a cascade of such DNN regressors which results in high precision pose $SEPB$ This paper introduces a new architecture for human pose estimation using a multilayer convolutional network architecture and a modified learning technique that learns low-level features and a higher-level weak spatial model . Unconstrained human pose estimation is one of the hardest problems in computer vision , and our new architecture and learning schema shows improvement over the current stateof-the-art . The main contribution of this paper is showing , for the first time , that a specific variation of deep learning is able to meet the performance , and in many cases outperform , existing traditional architectures on this task . The paper also discusses several lessons learned while researching alternatives , most notably , that it is possible to learn strong low-level feature detectors on regions that $SEPB$ This paper proposes a new hybrid architecture that consists of a deep Convolutional Network and a Markov Random Field . We show how this architecture is successfully applied to the challenging problem of articulated human pose estimation in monocular images . The architecture can exploit structural domain constraints such as geometric relationships between body joint locations . We show that joint training of these two model paradigms improves performance and allows us to significantly outperform existing state-of-the-art techniques . $FULLTEXT$ Despite a long history of prior work , human body pose estimation , or specifically the localization of human joints in monocular RGB images , remains a very challenging task in computer vision . Complex joint interdependencies , partial or full joint occlusions , variations in body shape $SEPB$ We present a method for estimating articulated human pose from a single static image based on a graphical model with novel pairwise relations that make adaptive use of local image measurements . More precisely , we specify a graphical model for human pose which exploits the fact the local image measurements can be used both to detect parts and also to predict the spatial relationships between them . These spatial relationships are represented by a mixture model . We use Deep Convolutional Neural Networks to learn conditional probabilities for the presence of parts and their spatial relationships within image patches . Hence our model combines the representational flexibility of graphical models with the efficiency and statistical power of DCNNs . Our method significantly outperforms the state of the $SEPB$ Abstract . This work introduces a novel Convolutional Network architecture for the task of human pose estimation . Features are processed across all scales and consolidated to best capture the various spatial relationships associated with the body . We show how repeated bottom-up , top-down processing used in conjunction with intermediate supervision is critical to improving the performance of the network . We refer to the architecture as a 'stacked hourglass ' network based on the successive steps of pooling and upsampling that are done to produce a final set of estimates . State-of-the-art results are achieved on the FLIC and MPII benchmarks outcompeting all recent methods .Keywords : Human Pose Estimation $FULLTEXT$ A key step toward understanding people in images and video is accurate pose estimation . $SEPB$ Abstract . This paper is on human pose estimation using Convolutional Neural Networks . Our main contribution is a CNN cascaded architecture specifically designed for learning part relationships and spatial context , and robustly inferring pose even for the case of severe part occlusions . To this end , we propose a detection-followed-by-regression CNN cascade . The first part of our cascade outputs part detection heatmaps and the second part performs regression on these heatmaps . The benefits of the proposed architecture are multi-fold : It guides the network where to focus in the image and effectively encodes part constraints and context . More importantly , it can effectively cope with occlusions because part detection heatmaps for occluded parts provide low confidence scores which subsequently guide the regression $SEPB$ Abstract-We propose a ConvNet model for predicting 2D human body poses in an image . The model regresses a heatmap representation for each body keypoint , and is able to learn and represent both the part appearances and the context of the part configuration .We make the following three contributions : an architecture combining a feed forward module with a recurrent module , where the recurrent module can be run iteratively to improve the performance ; the model can be trained end-to-end and from scratch , with auxiliary losses incorporated to improve performance ; we investigate whether keypoint visibility can also be predicted .The model is evaluated on two benchmark datasets . The result is a simple architecture that achieves performance on par with the state of the $SEPB$ Abstract . In this paper , we present an adaptation of the sequence-tosequence model for structured output prediction in vision tasks . In this model the output variables for a given input are predicted sequentially using neural networks . The prediction for each output variable depends not only on the input but also on the previously predicted output variables . The model is applied to spatial localization tasks and uses convolutional neural networks for processing input images and a multi-scale deconvolutional architecture for making spatial predictions at each time step . We explore the impact of weight sharing with a recurrent connection matrix between consecutive predictions , and compare it to a formulation where these weights are not tied . Untied weights are particularly suited for problems with $SEPB$ The goal of this paper is to advance the state-of-the-art of articulated pose estimation in scenes with multiple people . To that end we contribute on three fronts . We propose improved body part detectors that generate effective bottom-up proposals for body parts ; novel image-conditioned pairwise terms that allow to assemble the proposals into a variable number of consistent body part configurations ; and an incremental optimization strategy that explores the search space more efficiently thus leading both to better performance and significant speed-up factors . We evaluate our approach on two single-person and two multi-person pose estimation benchmarks . The proposed approach significantly outperforms best known multi-person pose estimation results while demonstrating competitive performance on the task of single person pose estimation 1 .1 Models and $SEPB$ We present an approach to efficiently detect the 2D $FULLTEXT$ Human 2D pose estimation-the problem of localizing anatomical keypoints or `` parts '' -has largely focused on finding body parts of individuals . Inferring the pose of multiple people in images , especially socially engaged individuals , presents a unique set of challenges . First , each image may contain an unknown number of people that can occur at any position or scale . Second , interactions between people induce complex spatial interference , due to contact , occlusion , and limb articulations , making association of parts difficult . Third , runtime complexity tends to grow with the number of people in the image , making realtime performance a challenge .A common approach is to employ a
1	Loss correction #CITE# methods assume that the noise transition matrix is already known or that some clean data are obtainable to calculate the noise transition matrix . #CITE# modeled the noise transition matrix by adding an additional layer . Several other approaches attempted to correct the label directly #CITE# . $SEP$ Convolutional Neural Networks provide excellent performance when used for image classification . The classical method of training CNNs is by labeling images in a supervised manner as in `` input image belongs to this label '' , which is a fast and accurate method if the labels are assigned correctly to all images . However , if inaccurate labels , or noisy labels , exist , training with PL will provide wrong information , thus severely degrading performance . To address this issue , we start with an indirect learning method called Negative Learning , in which the CNNs are trained using a complementary label as in `` input image does not belong to this complementary label . '' Because the chances of selecting a true label as a complementary label are low , NL decreases the risk of providing incorrect information . Furthermore , to improve convergence , we extend our method by adopting PL selectively , termed as Selective Negative Learning and Positive Learning . PL is used selectively to train upon expected-to-be-clean data , whose choices become possible as NL progresses , thus resulting in superior performance of filtering out noisy data . With simple semi-supervised training $SEP$ Collecting large training datasets , annotated with high quality labels , is a costly process . This paper proposes a novel framework for training deep convolutional neural networks from noisy labeled datasets . The problem is formulated using an undirected graphical model that represents the relationship between noisy and clean labels , trained in a semi-supervised setting . In the proposed structure , the inference over latent clean labels is tractable and is regularized during training using auxiliary sources of information . The proposed model is applied to the image labeling problem and is shown to be effective in labeling unseen images as well as reducing label noise in training on CIFAR-10 and MS COCO datasets . $FULLTEXT$ The availability of large annotated data collections such as ImageNet $SEPB$ The growing importance of massive datasets with the advent of deep learning makes robustness to label noise a critical property for classifiers to have . Sources of label noise include automatic labeling , non-expert labeling , and label corruption by data poisoning adversaries . In the latter case , corruptions may be arbitrarily bad , even so bad that a classifier predicts the wrong labels with high confidence . To protect against such sources of noise , we leverage the fact that a small set of clean labels is often easy to procure . We demonstrate that robustness to label noise up to severe strengths can be achieved by using a set of trusted data with clean labels , and propose a loss correction that utilizes trusted examples $SEPB$ Large datasets often have unreliable labels-such as those obtained from Amazon 's Mechanical Turk or social media platforms-and classifiers trained on mislabeled datasets often exhibit poor performance . We present a simple , effective technique for accounting for label noise when training deep neural networks . We augment a standard deep network with a softmax layer that models the label noise statistics . Then , we train the deep network and noise model jointly via endto-end stochastic gradient descent on the dataset . The augmented model is underdetermined , so in order to encourage the learning of a non-trivial noise model , we apply dropout regularization to the weights of the noise model during training . Numerical experiments on noisy versions of the CIFAR-10 and MNIST datasets show $SEPB$ AbstractWe present an approach to effectively use millions of images with noisy annotations in conjunction with $FULLTEXT$ Deep convolutional neural networks proliferate in current machine vision . One of the biggest bottlenecks in scaling their learning is the need for massive and clean collections of semantic annotations for images . Today , even after five years of success of ImageNet , there is still no publicly available dataset containing an order of magnitude more clean labeled data . To tackle this bottleneck , other training paradigms have been explored aiming to bypass the need of training with expensive manually collected annotations . Examples include unsupervised learn- * Work done during internship at Google Research . Figure 1 . Sample images and annotations from the Open Images validation set $SEPB$ The ability of learning from noisy labels is very useful in many visual recognition tasks , as a vast amount of data with noisy labels are relatively easy to obtain . Traditionally , label noise has been treated as statistical outliers , and techniques such as importance re-weighting and bootstrapping have been proposed to alleviate the problem . According to our observation , the real-world noisy labels exhibit multimode characteristics as the true labels , rather than behaving like independent random outliers . In this work , we propose a unified distillation framework to use `` side '' information , including a small clean dataset and label relations in knowledge graph , to `` hedge the risk '' of learning from noisy labels . Unlike the traditional approaches
1	Skipthought is an unsupervised sequence model that has been shown to generate useful sentence embeddings . $SEP$ Sentence vectors represent an appealing approach to meaning : learn an embedding that encompasses the meaning of a sentence in a single vector , that can be used for a variety of semantic tasks . Existing models for learning sentence embeddings either require extensive computational resources to train on large corpora , or are trained on costly , manually curated datasets of sentence relations . We observe that humans naturally annotate the relations between their sentences with discourse markers like `` but '' and `` because '' . These words are deeply linked to the meanings of the sentences they connect . Using this natural signal , we automatically collect a classification dataset from unannotated text . We evaluate our sentence embeddings on a variety of transfer tasks , including discourse-related tasks using Penn Discourse Treebank . We demonstrate that training a model to predict discourse markers yields high quality sentence embeddings . $SEP$ We describe an approach for unsupervised learning of a generic , distributed sentence encoder . Using the continuity of text from books , we train an encoderdecoder model that tries to reconstruct the surrounding sentences of an encoded passage . Sentences that share semantic and syntactic properties are thus mapped to similar vector representations . We next introduce a simple vocabulary expansion method to encode words that were not seen as part of training , allowing us to expand our vocabulary to a million words . After training our model , we extract and evaluate our vectors with linear models on 8 tasks : semantic relatedness , paraphrase detection , image-sentence ranking , question-type classification and 4 benchmark sentiment and subjectivity datasets . The end result is an
1	During the past few years , many research studies have been carried out on background subtraction or foreground detection #CITE# , #CITE# , #CITE# , #CITE# , #CITE# , #CITE# , #CITE# as well as background initialization #CITE# , #CITE# , #CITE# , #CITE# , #CITE# . Many surveys have also contributed to these topics #CITE# - #CITE# , #CITE# . Recently , deep Convolutional Neural Network based methods have also been proposed for foreground segmentation #CITE# , #CITE# , #CITE# . $SEP$ Abstract-Background estimation and foreground segmentation are important steps in many high-level vision tasks . Many existing methods estimate background as a low-rank component and foreground as a sparse matrix without incorporating the structural information . Therefore , these algorithms exhibit degraded performance in the presence of dynamic backgrounds , photometric variations , jitter , shadows , and large occlusions . We observe that these backgrounds often span multiple manifolds . Therefore , constraints that ensure continuity on those manifolds will result in better background estimation . Hence , we propose to incorporate the spatial and temporal sparse subspace clustering into the robust principal component analysis framework . To that end , we compute a spatial and temporal graph for a given sequence using motion-aware correlation coefficient . The information captured by both graphs is utilized by estimating the proximity matrices using both the normalized Euclidean and geodesic distances . The low-rank component must be able to efficiently partition the spatiotemporal graphs using these Laplacian matrices . Embedded with the RPCA objective function , these Laplacian matrices constrain the background model to be spatially and temporally consistent , both on linear and nonlinear manifolds . The solution of the proposed objective $SEP$ El acceso a la versión del editor puede requerir la suscripción del recurso Access to the published version may require subscriptionBackground estimation in video consists in extracting a foreground-free image from a set of training frames . Moving and stationary objects may affect the background visibility , thus invalidating the assumption of many related literature where background is the temporal dominant data . In this paper ,we present a temporal-spatial block-level approach for background estimation in video to cope with moving and stationary objects . First , a Temporal Analysis module obtains a compact representation of the training data by motion filtering and dimensionality reduction . Then , a threshold-free hierarchical clustering determines a set of candidates to represent the background for each spatial location . Second , $SEPB$ Object detection is a fundamental step for automated video analysis in many vision applications . Object detection in a video is usually performed by object detectors or background subtraction techniques . Often , an object detector requires manually labeled examples to train a binary classifier , while background subtraction needs a training sequence that contains no objects to build a background model . To automate the analysis , object detection without a separate training phase becomes a critical task . People have tried to tackle this task by using motion information . But existing motion-based methods are usually limited when coping with complex scenarios such as nonrigid motion and dynamic background . In this paper , we show that the above challenges can be addressed in a unified $SEPB$ This paper introduces a fast algorithm for randomized computation of a low-rank Dynamic Mode Decomposition of a matrix . Here we consider this matrix to represent the development of a spatial grid through time e .g . data from a static video source .DMD was originally introduced in the fluid mechanics community , but is also suitable for motion detection in video streams and its use for background subtraction has received little previous investigation . In this study we present a comprehensive evaluation of back- $FULLTEXT$ The demand for video processing is rapidly increasing , driven by greater numbers of sensors with greater resolution , new types of sensors , new collection methods and an ever wider range of applications . For example , video surveillance , vehicle $SEPB$ Abstract-Given a set of images of a scene taken at different times , the availability of an initial background model that describes the scene without foreground objects is the prerequisite for a wide range of applications , ranging from video surveillance to computational photography . Even though several methods have been proposed for scene background initialization , the lack of a common groundtruthed dataset and of a common set of metrics makes it difficult to compare their performance . To move first steps towards an easy and fair comparison of these methods , we assembled a dataset of sequences frequently adopted for background initialization , selected or created ground truths for quantitative evaluation through a selected suite of metrics , and compared results obtained by some existing methods $SEPB$ Abstract-Given a set of images of a scene taken at different times , the availability of an initial background model that describes the scene without foreground objects is the prerequisite for a wide range of applications , ranging from video surveillance to computational photography . Even though several methods have been proposed for scene background initialization , the lack of a common groundtruthed dataset and of a common set of metrics makes it difficult to compare their performance . To move first steps towards an easy and fair comparison of these methods , we assembled a dataset of sequences frequently adopted for background initialization , selected or created ground truths for quantitative evaluation through a selected suite of metrics , and compared results obtained by some existing methods $SEPB$ Abstract-Background subtraction is usually based on lowlevel or hand-crafted features such as raw color components , gradients , or local binary patterns . As an improvement , we present a background subtraction algorithm based on spatial features learned with convolutional neural networks . Our algorithm uses a background model reduced to a single background image and a scene-specific training dataset to feed ConvNets that prove able to learn how to subtract the background from an input image patch . Experiments led on 2014 ChangeDetection .net dataset show that our ConvNet based algorithm at least reproduces the performance of state-of-the-art methods , and that it even outperforms them significantly when scene-specific knowledge is considered . $FULLTEXT$ Detecting moving objects in video sequences acquired with static cameras is essential for
0	Among other subspace clustering methods , Park et al and Heckel & Bölcskei are the only two papers that provide provable exact clustering guarantees for problems beyond independent subspaces . $SEP$ Subspace clustering is the problem of clustering data points into a union of low-dimensional linear/affine subspaces . It is the mathematical abstraction of many important problems in computer vision , image processing and has been drawing avid attention in machine learning and statistics recently . In particular , a line of recent work provided strong theoretical guarantee for the seminal algorithm : Sparse Subspace Clustering under various settings , and to some extent , justified its state-of-the-art performance in applications such as motion segmentation and face clustering . The focus of these work has been getting milder conditions under which SSC obeys `` self-expressiveness property '' , which ensures that no two points from different subspaces can be clustered together . Such guarantee however is not sufficient for the clustering to be correct , thanks to the notorious `` graph connectivity problem '' . In this paper , we show that this issue can be resolved by a very simple post-processing procedure under only a mild `` general position '' assumption . In addition , we show that the approach is robust to arbitrary bounded perturbation of the data whenever the `` general position '' assumption holds with a margin $SEP$ We consider the problem of subspace clustering : given points that lie on or near the union of many low-dimensional linear subspaces , recover the subspaces . To this end , one first identifies sets of points close to the same subspace and uses the sets to estimate the subspaces . As the geometric structure of the clusters forbids proper performance of general distance based approaches such as K-means , many model-specific methods have been proposed . In this paper , we provide new simple and efficient algorithms for this problem . Our statistical analysis shows that the algorithms are guaranteed exact clustering performance under certain conditions on the number of points and the affinity between subspaces . These conditions are weaker than those considered in the standard $SEPB$ The problem of clustering noisy and incompletely observed high-dimensional data points into a union of lowdimensional subspaces and a set of outliers is considered . The number of subspaces , their dimensions , and their orientations are assumed unknown . We propose a simple low-complexity subspace clustering algorithm , which applies spectral clustering to an adjacency matrix obtained by thresholding the correlations between data points . In other words , the adjacency matrix is constructed from the nearest neighbors of each data point in spherical distance . A statistical performance analysis shows that the algorithm exhibits robustness to additive noise and succeeds even when the subspaces intersect . Specifically , our results reveal an explicit tradeoff between the affinity of the subspaces and the tolerable noise level .
1	and BBN1 #CITE# . $SEP$ This paper describes a real-time sequential method to simultaneously recover the camera motion and the 3D shape of deformable objects from a calibrated monocular video . For this purpose , we consider the Navier-Cauchy equations used in 3D linear elasticity and solved by finite elements , to model the time-varying shape per frame . These equations are embedded in an extended Kalman filter , resulting in sequential Bayesian estimation approach . We represent the shape , with unknown material properties , as a combination of elastic elements whose nodal points correspond to salient points in the image . The global rigidity of the shape is encoded by a stiffness matrix , computed after assembling each of these elements . With this piecewise model , we can linearly relate the 3D displacements with the 3D acting forces that cause the object deformation , assumed to be normally distributed . While standard finite-element-method techniques require imposing boundary conditions to solve the resulting linear system , in this work we eliminate this requirement by modeling the compliance matrix with a generalized pseudoinverse that enforces a pre-fixed rank . Our framework also ensures surface continuity without the need for a post-processing step to stitch $SEP$ We present an algorithm to simultaneously recover nonrigid $FULLTEXT$ Recovering non-rigid 3D shape from monocular sequences is known to be a highly ambiguous problem because very different shapes may have a similar projection . As shown in Fig . 1 the problem becomes even further ill-conditioned if the camera moves while the shape deforms , and both non-rigid shape and camera motion have to be simultaneously retrieved . In order to turn this problem into a tractable one , it is required to introduce prior knowledge about the object 's behavior or camera properties .Standard approaches to limit the space of possible solutions involve introducing deformation models , either physically inspired ones or learned from training data . Surface deformations are then expressed as weighted sums of modes
0	The work of develops a method for implementing any robust supervised learning algorithm in a distributed manner . provide lower bounds for the communication complexity of PAC learning in a distributed environment , in the presence of malicious errors and outliers . Fault tolerance and resistance to adversarial behavior of individual nodes in a distributed system has been studied from the point of view of Byzantinerobust distributed optimization , eg . $SEP$ Modern machine learning methods often require more data for training than a single expert can provide . Therefore , it has become a standard procedure to collect data from external sources , e .g . via crowdsourcing . Unfortunately , the quality of these sources is not always guaranteed . As additional complications , the data might be stored in a distributed way , or might even have to remain private . In this work , we address the question of how to learn robustly in such scenarios . Studying the problem through the lens of statistical learning theory , we derive a procedure that allows for learning from all available sources , yet automatically suppresses irrelevant or corrupted data . We show by extensive experiments that our method provides significant improvements over alternative approaches from robust statistics and distributed optimization . $SEP$ We consider the problems of robust PAC learning from distributed and streaming data , which may contain malicious errors and outliers , and analyze their fundamental complexity questions . In particular , we establish lower bounds on the communication complexity for distributed robust learning performed on multiple machines , and on the space complexity for robust learning from streaming data on a single machine . These results demonstrate that gaining robustness of learning algorithms is usually at the expense of increased complexities . As far as we know , this work gives the first complexity results for distributed and online robust PAC learning . $FULLTEXT$ The last decade has witnessed a tremendous growth in the amount of data involved in machine learning tasks . In many cases , $SEPB$ This paper studies the problem of distributed stochastic optimization in an adversarial setting where , out of the m machines which allegedly compute stochastic gradients every iteration , an α-fraction are Byzantine , and can behave arbitrarily and adversarially . Our main result is a variant of stochastic gradient descent which finds ε-approximate minimizers of convex functions initerations . In contrast , traditional mini-batch SGD needs T = O 1 ε 2 m iterations , but can not tolerate Byzantine failures . Further , we provide a lower bound showing that , up to logarithmic factors , our algorithm is information-theoretically optimal both in terms of sampling complexity and time complexity . $FULLTEXT$ Data used in machine learning applications is becoming increasingly decentralized . This can be either
2	Methods that involve calculation of optimal fluxes subject to constraints , such as flux coupling #CITE# , have performed better than local topological metrics based on shared neighbours in predicting transcript co-expression . $SEP$ Background : Metabolic reconstructions contain detailed information about metabolic enzymes and their reactants and products . These networks can be used to infer functional associations between metabolic enzymes . Many methods are based on the number of metabolites shared by two enzymes , or the shortest path between two enzymes . Metabolite sharing can miss associations between non-consecutive enzymes in a serial pathway , and shortest-path algorithms are sensitive to high-degree metabolites such as water and ATP that create connections between enzymes with little functional similarity . Results : We present new , fast methods to infer functional associations in metabolic networks . A local method , the degree-corrected Poisson score , is based only on the metabolites shared by two enzymes , but uses the known metabolite degree distribution . A global method , based on graph diffusion kernels , predicts associations between enzymes that do not share metabolites . Both methods are robust to high-degree metabolites . They out-perform previous methods in predicting shared Gene Ontology annotations and in predicting experimentally observed synthetic lethal genetic interactions . Including cellular compartment information improves GO annotation predictions but degrades synthetic lethal interaction prediction . These new methods perform nearly as $SEP$ To what extent can modes of gene regulation be explained by systems-level properties of metabolic networks ? Prior studies on co-regulation of metabolic genes have mainly focused on graph-theoretical features of metabolic networks and demonstrated a decreasing level of co-expression with increasing network distance , a naïve , but widely used , topological index . Others have suggested that static graph representations can poorly capture dynamic functional associations , eg , in the form of dependence of metabolic fluxes across genes in the network . Here , we systematically tested the relative importance of metabolic flux coupling and network position on gene co-regulation , using a genome-scale metabolic model of Escherichia coli . After validating the computational method with empirical data on flux correlations , we confirm that
2	We could take a non-Gaussian approach #CITE# that uses an extension of independent component analysis with more latent independent components than observed variables to formally consider hidden common causes in semi-parametric methods . $SEP$ Abstract . We discuss the problem of estimating the causal direction between two observed variables in the presence of hidden common causes . Managing hidden common causes is essential when studying causal relations based on observational data . We previously proposed a Bayesian estimation method for estimating the causal direction using the nonGaussianity of data . This method does not require us to explicitly model hidden common causes . The experiments on artificial data presented in this paper imply that Bayes factors could be useful for selecting a better causal direction when using a non-Gaussian method . $SEP$ The task of estimating causal effects from non-experimental data is notoriously difficult and unreliable . Nevertheless , precisely such estimates are commonly required in many fields including economics and social science , where controlled experiments are often impossible . Linear causal models , combined with an implicit normality assumption on the data , provide a widely used framework for this task .We have recently described how non-Gaussianity in the data can be exploited for estimating causal effects . In this paper we show that , with non-Gaussian data , causal inference is possible even in the presence of hidden variables , even when the existence of such variables is unknown a priori . Thus , we provide a comprehensive and complete framework for the estimation of causal effects $SEPB$ In an overcomplete basis , the number of basis vectors is greater than the dimensionality of the input , and the representation of an input is not a unique combination of basis vectors . Overcomplete representations have been advocated because they have greater robustness in the presence of noise , can be sparser , and can have greater flexibility in matching structure in the data . Overcomplete codes have also been proposed as a model of some of the response properties of neurons in primary visual cortex . Previous work has focused on finding the best representation of a signal using a fixed overcomplete basis . We present an algorithm for learning an overcomplete basis by viewing it as probabilistic model of the observed data . We show
2	In #CITE# , Gehler et al described several feature combination methods including average kernel support vector machine , product kernel support vector machine , multiple kernel learning #CITE# , #CITE# , #CITE# , column generation boosting #CITE# , and linear programming boosting #CITE# for object recognition . $SEP$ Abstract-Image/video data is usually represented by multiple visual features . Fusion of multi-sources information for establishing the identity has been widely recognized . Multi-feature visual recognition has recently received attention in multimedia applications . This paper studies visual understanding via a newly proposed -norm based multi-feature jointly sharing learning framework , which can simultaneously learn the global label matrix and explicit classifiers from the labeled visual data represented by multiple feature modalities . Additionally , a multi-modal group graph manifold regularizer formed by mixed Laplacian and Hessian graph is proposed for better preserving the manifold structure of different features on the labeled data , while preserving the label consistency and improving the label prediction power via semi-supervised learning . The merits of the proposed multi-feature learning framework lie in jointly sharing the structural information from multiple features in global classifier learning phase based on a mixed graph regularizer on one hand , and an efficient alternating optimization method for fast classifier training on the other hand . Experiments on several benchmark visual datasets , such as 17-category Oxford Flower dataset , the challenging 101-category Caltech dataset , YouTube & Consumer Videos dataset and large-scale NUS-WIDE dataset for multimedia understanding all $SEP$ An efficient and general multiple kernel learning algorithm has been recently proposed by Sonnenburg et al . . This approach has opened new perspectives since it makes the MKL approach tractable for largescale problems , by iteratively using existing support vector machine code . However , it turns out that this iterative algorithm needs several iterations before converging towards a reasonable solution . In this paper , we address the MKL problem through an adaptive 2-norm regularization formulation . Weights on each kernel matrix are included in the standard SVM empirical risk minimization problem with a 1 constraint to encourage sparsity . We propose an algorithm for solving this problem and provide an new insight on MKL algorithms based on block 1-norm regularization by showing that the two $SEPB$ We examine linear program approaches to boosting and demonstrate their efficient solution using LPBoost , a column generation based simplex method . We formulate the problem as if all possible weak hypotheses had already been generated . The labels produced by the weak hypotheses become the new feature space of the problem . The boosting task becomes to construct a learning function in the label space that minimizes misclassification error and maximizes the soft margin . We prove that for classification , minimizing the 1-norm soft margin error function directly optimizes a generalization error bound . The equivalent linear program can be efficiently solved using column generation techniques developed for large-scale optimization problems . The resulting LPBoost algorithm can be used to solve any LP boosting formulation by
0	As there is no explicit rating available , we tried to apply a collaborative filtering based approach to compute personalized ranking using implicit feedback like favoring or retweeting #CITE# . $SEP$ To help their users to discover important items at a particular time , major websites like Twitter , Yelp , TripAdvisor or NYTimes provide Top-K recommendations , which rely on crowdsourced popularity signals to select the items . However , different sections of a crowd may have different preferences , and there is a large silent majority who do not explicitly express their opinion . Also , the crowd often consists of actors like bots , spammers , or people running orchestrated campaigns . Recommendation algorithms today largely do not consider such nuances , hence are vulnerable to strategic manipulation by small but hyper-active user groups . To fairly aggregate the preferences of all users while recommending top-K items , we borrow ideas from prior research on social choice theory , and identify a voting mechanism called Single Transferable Vote as having many of the fairness properties we desire in top-K item elections . We develop an innovative mechanism to attribute preferences of silent majority which also make STV completely operational . We show the generalizability of our approach by implementing it on two different real-world datasets . Through extensive experimentation and comparison with state-ofthe-art techniques , we show that $SEP$ Item recommendation is the task of predicting a personalized ranking on a set of items . In this paper , we investigate the most common scenario with implicit feedback . There are many methods for item recommendation from implicit feedback like matrix factorization or adaptive knearest-neighbor . Even though these methods are designed for the item prediction task of personalized ranking , none of them is directly optimized for ranking . In this paper we present a generic optimization criterion BPR-Opt for personalized ranking that is the maximum posterior estimator derived from a Bayesian analysis of the problem . We also provide a generic learning algorithm for optimizing models with respect to BPR-Opt . The learning method is based on stochastic gradient descent with bootstrap sampling . We
1	Recent advances in deep neural models allow us to build reliable NE recognition systems . $SEP$ Deep neural network models have helped named entity recognition achieve amazing performance without handcrafting features . However , existing systems require large amounts of human annotated training data . Efforts have been made to replace human annotations with external knowledge , while it is another challenge to obtain such effective resources . In this work , we propose a fully unsupervised NE recognition model which only needs to take informative clues from pre-trained word embeddings . We first apply Gaussian Hidden Markov Model and Deep Autoencoding Gaussian Mixture Model on word embeddings for entity span detection and type prediction , and then further design an instance selector based on reinforcement learning to distinguish positive sentences from noisy sentences and refine these coarse-grained annotations through neural networks . Extensive experiments on CoNLL benchmark datasets demonstrate that our proposed light NE recognition model achieves remarkable performance without using any annotated lexicon or corpus . $SEP$ State-of-the-art named entity recognition systems rely heavily on hand-crafted features and domain-specific knowledge in order to learn effectively from the small , supervised training corpora that are available . In this paper , we introduce two new neural architectures-one based on bidirectional LSTMs and conditional random fields , and the other that constructs and labels segments using a transition-based approach inspired by shift-reduce parsers . Our models rely on two sources of information about words : character-based word representations learned from the supervised corpus and unsupervised word representations learned from unannotated corpora . Our models obtain state-of-the-art performance in NER in four languages without resorting to any language-specific knowledge or resources such as gazetteers . $FULLTEXT$ Named entity recognition is a challenging learning problem . One the one $SEPB$ State-of-the-art sequence labeling systems traditionally require large amounts of taskspecific knowledge in the form of handcrafted features and data pre-processing . In this paper , we introduce a novel neutral network architecture that benefits from both word-and character-level representations automatically , by using combination of bidirectional LSTM , CNN and CRF . Our system is truly end-to-end , requiring no feature engineering or data preprocessing , thus making it applicable to a wide range of sequence labeling tasks . We evaluate our system on two data sets for two sequence labeling tasks -Penn Treebank WSJ corpus for part-of-speech tagging and CoNLL 2003 corpus for named entity recognition . We obtain state-of-the-art performance on both datasets -97 .55 % accuracy for POS tagging and 91 .21 % F1 for
1	Fast and efficient discriminative classifiers like Random Forests have shown promising results for video segmentation #CITE# . $SEP$ We propose a novel directed graphical model for label propagation in lengthy and complex video sequences . Given hand-labelled start and end frames of a video sequence , a variational EM based inference strategy propagates either one of several class labels or assigns an unknown class label to each pixel in the video . These labels are used to train a multi-class classifier . The pixel labels estimated by this classifier are injected back into the Bayesian network for another iteration of label inference . The novel aspect of this iterative scheme , as compared to a recent approach , is its ability to handle occlusions . This is attributed to a hybrid of generative propagation and discriminative classification in a pseudo time-symmetric video model . The end result is a conservative labelling of the video ; large parts of the static scene are labelled into known classes , and a void label is assigned to moving objects and remaining parts of the static scene . These labels can be used as ground truth data to learn the static parts of a scene from videos of it or more generally for semantic video segmentation . We demonstrate the efficacy of $SEP$ Abstract . We propose an algorithm for semantic segmentation based on 3D point clouds derived from ego-motion . We motivate five simple cues designed to model specific patterns of motion and 3D world structure that vary with object category . We introduce features that project the 3D cues back to the 2D image plane while modeling spatial layout and context . A randomized decision forest combines many such features to achieve a coherent 2D segmentation and recognize the object categories present . Our main contribution is to show how semantic segmentation is possible based solely on motion-derived 3D world structure . Our method works well on sparse , noisy point clouds , and unlike existing approaches , does not need appearance-based descriptors . Experiments were performed on a $SEPB$ We propose semantic texton forests , efficient and powerful new low-level features . These are ensembles of decision trees that act directly on image pixels , and therefore do not need the expensive computation of filter-bank responses or local descriptors . They are extremely fast to both train and test , especially compared with k-means clustering and nearest-neighbor assignment of feature descriptors . The nodes in the trees provide an implicit hierarchical clustering into semantic textons , and an explicit local classification estimate . Our second contribution , the bag of semantic textons , combines a histogram of semantic textons over an image region with a region prior category distribution . The bag of semantic textons is computed over the whole image for categorization , and over local
2	Existing techniques can be categorized into two groups: spatial cloaking #CITE# and transformation based matching #CITE# techniques . $SEP$ Abstract . Publish/subscribe systems support highly scalable , manyto-many communications among loosely coupled publishers and subscribers . Modern pub/sub systems perform message routing based on the message content and allow subscribers to receive messages related to their subscriptions and the current context . However , both content and context encode sensitive information which should be protected from third-party brokers that make routing decisions . In this work , we address this issue by proposing an approach for constructing a privacy preserving context-based pub/sub system . In particular , our approach assures the confidentiality of the messages being published and subscriptions being issued while allowing the brokers to make routing decisions without decrypting individual messages and subscriptions , and without learning the context . Further , subscribers with a frequently changing context such as location are able to issue and update subscriptions without revealing the subscriptions in plaintext to the broker and without the need to contact a trusted third party for each subscription change resulting from a change in the context . Our approach is based on a modified version of the Paillier additive homomorphic cryptosystem and a recent expressive group key management scheme . The former construct is used $SEP$ This paper describes a personalized k-anonymity model for protecting location privacy against various privacy threats through location information sharing . Our model has two unique features . First , we provide a unified privacy personalization framework to support location k-anonymity for a wide range of users with context-sensitive personalized privacy requirements . This framework enables each mobile node to specify the minimum level of anonymity it desires as well as the maximum temporal and spatial resolutions it is willing to tolerate when requesting for k-anonymity preserving location-based services . Second , we devise an efficient message perturbation engine which runs by the location protection broker on a trusted server and performs location anonymization on mobile users ' LBS request messages , such as identity removal and spatio-temporal cloaking $SEPB$ Abstract . In this paper we propose a fundamental approach to perform the class of Nearest Neighbor queries , the core class of queries used in many of the location-based services , without revealing the origin of the query in order to preserve the privacy of this information . The idea behind our approach is to utilize one-way transformations to map the space of all static and dynamic objects to another space and resolve the query blindly in the transformed space . However , in order to become a viable approach , the transformation used should be able to resolve NN queries in the transformed space accurately and more importantly prevent malicious use of transformed data by untrusted entities . Traditional encryption based techniques incur expensive O computation
1	Recently , such a strategy becomes learnable with the help of graph convolutional networks . Many GCN-based methods have been proposed to embed graphs , eg , the large-scale embedding method in , and the hierarchical embedding method in . $SEP$ We propose a new nonlinear factorization model for graphs that are with topological structures , and optionally , node attributes . This model is based on a pseudometric called Gromov-Wasserstein discrepancy , which compares graphs in a relational way . It estimates observed graphs as GW barycenters constructed by a set of atoms with different weights . By minimizing the GW discrepancy between each observed graph and its GW barycenter-based estimation , we learn the atoms and their weights associated with the observed graphs . The model achieves a novel and flexible factorization mechanism under GW discrepancy , in which both the observed graphs and the learnable atoms can be unaligned and with different sizes . We design an effective approximate algorithm for learning this Gromov-Wasserstein factorization model , unrolling loopy computations as stacked modules and computing gradients with backpropagation . The stacked modules can be with two different architectures , which correspond to the proximal point algorithm and Bregman alternating direction method of multipliers , respectively . Experiments show that our model obtains encouraging results on clustering graphs . In this paper , we borrow the terms `` atoms '' and `` coefficients '' from a kind of factorization $SEP$ We introduce propagation kernels , a general graph-kernel framework for efficiently measuring the similarity of structured data . Propagation kernels are based on monitoring how information spreads through a set of given graphs . They leverage earlystage distributions from propagation schemes such as random walks to capture structural information encoded in node labels , attributes , and edge information . This has two benefits . First , off-the-shelf propagation schemes can be used to naturally construct kernels for many graph types , including labeled , partially labeled , unlabeled , directed , and attributed graphs . Second , by leveraging existing efficient and informative propagation schemes , propagation kernels can be considerably faster than state-of-the-art approaches without sacrificing predictive performance . We will also show that if the $SEPB$ Recently , graph neural networks have revolutionized the field of graph representation learning through effectively learned node embeddings , and achieved state-of-the-art results in tasks such as node classification and link prediction . However , current GNN methods are inherently flat and do not learn hierarchical representations of graphs-a limitation that is especially problematic for the task of graph classification , where the goal is to predict the label associated with an entire graph . Here we propose DIFFPOOL , a differentiable graph pooling module that can generate hierarchical representations of graphs and can be combined with various graph neural network architectures in an end-to-end fashion . DIFFPOOL learns a differentiable soft cluster assignment for nodes at each layer of a deep GNN , mapping nodes to a
1	The standard SVR learning #CITE# , manifold learning #CITE# , and neural network learning #CITE# can be employed to obtain precise estimate of the location . $SEP$ Supervised machine learning has been widely used in context-aware wireless sensor networks to discover context descriptions from sensor data . However , collecting a lot of labeled training data in order to guarantee good performance requires much cost and time . For this reason , the semisupervised learning has been recently developed due to its superior performance despite using only a small amount of the labeled data . In this paper , we extend the standard support vector regression to the semisupervised SVR by employing manifold regularization , which we call Laplacian SVR . The LapSVR is compared with the standard SVR and the semisupervised least square algorithm that is another recently developed semisupervised regression algorithm . The algorithms are evaluated for location awareness of multiple mobile robots in a WSN . The experimental results show that the proposed algorithm yields more accurate location estimates than the other algorithms . $SEP$ We show that the coarse-grained and fine-grained localization problems for ad hoc sensor networks can be posed and solved as a pattern recognition problem using kernel methods from statistical learning theory . This stems from an observation that the kernel function , which is a similarity measure critical to the effectiveness of a kernel-based learning algorithm , can be naturally defined in terms of the matrix of signal strengths received by the sensors . Thus we work in the natural coordinate system provided by the physical devices . This not only allows us to sidestep the difficult ranging procedure required by many existing localization algorithms in the literature , but also enables us to derive a simple and effective localization algorithm . The algorithm is particularly suitable for $SEPB$ If a dense network of static wireless sensors is deployed to measure an time-varying isotropic random field , then sensor data itself , rather than range measurements using specialized hardware , can be used to estimate a map of sensor locations . Furthermore , distributed and scalable sensor localization algorithms can be derived . We apply the manifold learning algorithms Isomap , Locally Linear Embedding , and Hessian LLE . The HLLEbased estimator demonstrates the best bias and variance performance , but may not be robust for all random sensor deployments . $FULLTEXT$ Emerging applications of wireless sensor networks will depend on automatic and accurate location of thousands of sensors . However , device cost will also be a key factor . By eliminating the need for additional
1	Neural Machine Translation . $SEP$ Multilingual Neural Machine Translation models are capable of translating between multiple source and target languages . Despite various approaches to train such models , they have difficulty with zero-shot translation : translating between language pairs that were not together seen during training . In this paper we first diagnose why state-of-the-art multilingual NMT models that rely purely on parameter sharing , fail to generalize to unseen language pairs . We then propose auxiliary losses on the NMT encoder that impose representational invariance across languages . Our simple approach vastly improves zero-shot translation quality without regressing on supervised directions . For the first time , on WMT14 English-FrenchGerman , we achieve zero-shot performance that is on par with pivoting . We also demonstrate the easy scalability of our approach to multiple languages on the IWSLT 2017 shared task . $SEP$ Deep Neural Networks are powerful models that have achieved excellent performance on difficult learning tasks . Although DNNs work well whenever large labeled training sets are available , they can not be used to map sequences to sequences . In this paper , we present a general end-to-end approach to sequence learning that makes minimal assumptions on the sequence structure . Our method uses a multilayered Long Short-Term Memory to map the input sequence to a vector of a fixed dimensionality , and then another deep LSTM to decode the target sequence from the vector . Our main result is that on an English to French translation task from the WMT-14 dataset , the translations produced by the LSTM achieve a BLEU score of 34 .8 on the $SEPB$ In this paper , we investigate the problem of learning a machine translation model that can simultaneously translate sentences from one source language to multiple target languages . Our solution is inspired by the recently proposed neural machine translation model which generalizes machine translation as a sequence learning problem . We extend the neural machine translation to a multi-task learning framework which shares source language representation and separates the modeling of different target language translation . Our framework can be applied to situations where either large amounts of parallel data or limited parallel data is available .Experiments show that our multi-task learning model is able to achieve significantly higher translation quality over individually learned model in both situations on the data sets publicly available . $FULLTEXT$ Translation from $SEPB$ Sequence to sequence learning has recently emerged as a new paradigm in supervised learning . To date , most of its applications focused on only one task and not much work explored this framework for multiple tasks . This paper examines three multi-task learning settings for sequence to sequence models : the oneto-many setting -where the encoder is shared between several tasks such as machine translation and syntactic parsing , the many-to-one setting -useful when only the decoder can be shared , as in the case of translation and image caption generation , and the many-to-many setting -where multiple encoders and decoders are shared , which is the case with unsupervised objectives and translation . Our results show that training on a small amount of parsing and image $SEPB$ We propose multi-way , multilingual neural machine translation . The proposed approach enables a single neural translation model to translate between multiple languages , with a number of parameters that grows only linearly with the number of languages . This is made possible by having a single attention mechanism that is shared across all language pairs . We train the proposed multiway , multilingual model on ten language pairs from WMT'15 simultaneously and observe clear performance improvements over models trained on only one language pair . In particular , we observe that the proposed model significantly improves the translation quality of low-resource language pairs . $FULLTEXT$ Neural Machine Translation It has been shown that a deep neural network can successfully learn a complex mapping between variablelength input and $SEPB$ We propose a simple solution to use a single Neural Machine Translation model to translate between multiple languages . Our solution requires no changes to the model architecture from a standard NMT system but instead introduces an artificial token at the beginning of the input sentence to specify the required target language . Using a shared wordpiece vocabulary , our approach enables Multilingual NMT systems using a single model . On the WMT'14 benchmarks , a single multilingual model achieves comparable performance for English→French and surpasses state-of-theart results for English→German . Similarly , a single multilingual model surpasses stateof-the-art results for French→English and German→English on WMT'14 and WMT'15 benchmarks , respectively . On production corpora , multilingual models of up to twelve language pairs allow for better translation
1	Deep Learning has been applied successfully to Automatic Speech Recognition #CITE# , where the main focus of research has been designing better network architectures , for example , DNNs #CITE# , CNNs #CITE# , RNNs #CITE# and end-to-end models #CITE# . $SEP$ We present SpecAugment , a simple data augmentation method for speech recognition . SpecAugment is applied directly to the feature inputs of a neural network . The augmentation policy consists of warping the features , masking blocks of frequency channels , and masking blocks of time steps . We apply SpecAugment on Listen , Attend and Spell networks for end-to-end speech recognition tasks . We achieve state-of-the-art performance on the LibriSpeech 960h and Swichboard 300h tasks , outperforming all prior work . On LibriSpeech , we achieve 6 .8 % WER on test-other without the use of a language model , and 5 .8 % WER with shallow fusion with a language model . This compares to the previous stateof-the-art hybrid system of 7 .5 % WER . For Switchboard , we achieve 7 .2 % /14 .6 % on the Switchboard/CallHome portion of the Hub5'00 test set without the use of a language model , and 6 .8 % /14 .1 % with shallow fusion , which compares to the previous state-of-the-art hybrid system at 8 .3 % /17 .3 % WER . $SEP$ Recurrent neural networks are a powerful model for sequential data . End-to-end training methods such as Connectionist Temporal Classification make it possible to train RNNs for sequence labelling problems where the input-output alignment is unknown . The combination of these methods with the Long Short-term Memory RNN architecture has proved particularly fruitful , delivering state-of-the-art results in cursive handwriting recognition . However RNN performance in speech recognition has so far been disappointing , with better results returned by deep feedforward networks . This paper investigates deep recurrent neural networks , which combine the multiple levels of representation that have proved so effective in deep networks with the flexible use of long range context that empowers RNNs . When trained end-to-end with suitable regularisation , we find that deep $SEPB$ Many state-of-the-art Large Vocabulary Continuous Speech Recognition Systems are hybrids of neural networks and Hidden Markov Models . Recently , more direct end-to-end methods have been investigated , in which neural architectures were trained to model sequences of characters . To our knowledge , all these approaches relied on Connectionist Temporal Classification modules . We investigate an alternative method for sequence modelling based on an attention mechanism that allows a Recurrent Neural Network to learn alignments between sequences of input frames and output labels . We show how this setup can be applied to LVCSR by integrating the decoding RNN with an n-gram language model and by speeding up its operation by constraining selections made by the attention mechanism and by reducing the source sequence lengths by pooling
1	For instance , outstanding results have been achieved in speech and image understanding #CITE# , and medical image analysis #CITE# . $SEP$ We introduce a new , rigorously-formulated Bayesian meta-learning algorithm that learns a probability distribution of model parameter prior for few-shot learning . The proposed algorithm employs a gradient-based variational inference to infer the posterior of model parameters to a new task . Our algorithm can be applied to any model architecture and can be implemented in various machine learning paradigms , including regression and classification . We show that the models trained with our proposed meta-learning algorithm are well calibrated and accurate , with state-of-the-art calibration and classification results on two few-shot classification benchmarks , and competitive results in a multi-modal task-distribution regression . $SEP$ Recurrent neural networks are a powerful model for sequential data . End-to-end training methods such as Connectionist Temporal Classification make it possible to train RNNs for sequence labelling problems where the input-output alignment is unknown . The combination of these methods with the Long Short-term Memory RNN architecture has proved particularly fruitful , delivering state-of-the-art results in cursive handwriting recognition . However RNN performance in speech recognition has so far been disappointing , with better results returned by deep feedforward networks . This paper investigates deep recurrent neural networks , which combine the multiple levels of representation that have proved so effective in deep networks with the flexible use of long range context that empowers RNNs . When trained end-to-end with suitable regularisation , we find that deep $SEPB$ We trained a large , deep convolutional neural network to classify the 1 .2 million high-resolution images in the ImageNet LSVRC-2010 contest into the 1000 different classes . On the test data , we achieved top-1 and top-5 error rates of 37 .5 % and 17 .0 % , respectively , which is considerably better than the previous state-of-the-art . The neural network , which has 60 million parameters and 650 ,000 neurons , consists of five convolutional layers , some of which are followed by max-pooling layers , and three fully connected layers with a final 1000-way softmax . To make training faster , we used nonsaturating neurons and a very efficient GPU implementation of the convolution operation . To reduce overfitting in the fully connected layers $SEPB$ In this work we investigate the effect of the convolutional network depth on its accuracy in the large-scale image recognition setting . Our main contribution is a thorough evaluation of networks of increasing depth , which shows that a significant improvement on the prior-art configurations can be achieved by pushing the depth to 16-19 weight layers . These findings were the basis of our ImageNet Challenge 2014 submission , where our team secured the first and the second places in the localisation and classification tracks respectively . We also show that our representations generalise well to other datasets , where they achieve the stateof-the-art results . Importantly , we have made our two best-performing ConvNet models publicly available to facilitate further research on the use of deep visual $SEPB$ In this paper , we present a fully automatic brain tumor segmentation method based on Deep Neural Networks . The proposed networks are tailored to glioblastomas pictured in MR images . By their very nature , these tumors can appear anywhere in the brain and have almost any kind of shape , size , and contrast . These reasons motivate our exploration of a machine learning solution that exploits a flexible , high capacity DNN while being extremely efficient . Here , we give a description of different model choices that we 've found to be necessary for obtaining competitive performance . We explore in particular different architectures based on Convolutional Neural Networks , i .e . DNNs specifically adapted to image data .We present a novel CNN
1	A traditional OMR system typically consists of multiple parts: score pre-processing , staff line identification and removal , musical object location , object classification and score reconstruction #CITE# . More recently , there has been a trend towards less segmented systems involving machine learning methods , such as OMR without staffline removal #CITE# or without symbol segmentation #CITE# . $SEP$ Optical Music Recognition is an important technology within Music Information Retrieval . Deep learning models show promising results on OMR tasks , but symbol-level annotated data sets of sufficient size to train such models are not available and difficult to develop . We present a deep learning architecture called a Convolutional Sequence-to-Sequence model to both move towards an end-to-end trainable OMR pipeline , and apply a learning process that trains on full sentences of sheet music instead of individually labeled symbols . The model is trained and evaluated on a human generated data set , with various image augmentations based on real-world scenarios . This data set is the first publicly available set in OMR research with sufficient size to train and evaluate deep learning models . With the introduced augmentations a pitch recognition accuracy of 81 % and a duration accuracy of 94 % is achieved , resulting in a note level accuracy of 80 % . Finally , the model is compared to commercially available methods , showing a large improvements over these applications . $SEP$ Abstract For centuries , music has been shared and remembered by two traditions : aural transmission and in the form of written documents normally called musical scores . Many of these scores exist in the form of unpublished manuscripts and hence they are in danger of being lost through the normal ravages of time . To preserve the music some form of typesetting or , ideally , a computer system that can automatically decode the symbolic images and create new scores is required . Programs analogous to optical character recognition systems called optical music recognition systems have been under intensive development for many years . However , the results to date are far from ideal . Each of the proposed methods emphasizes different properties and therefore makes it $SEPB$ Image-based sequence recognition has been a long-standing research topic in computer vision . In this paper , we investigate the problem of scene text recognition , which is among the most important and challenging tasks in imagebased sequence recognition . A novel neural network architecture , which integrates feature extraction , sequence modeling and transcription into a unified framework , is proposed . Compared with previous systems for scene text recognition , the proposed architecture possesses four distinctive properties : It is end-to-end trainable , in contrast to most of the existing algorithms whose components are separately trained and tuned . It naturally handles sequences in arbitrary lengths , involving no character segmentation or horizontal scale normalization . It is not confined to any predefined lexicon and achieves
0	Studies on the trajectory data collected using GPS sensors have always been important topics for many location-based applications such as mobile navigation system #CITE# , itinerary suggestion #CITE# , urban traffic analysis #CITE# , and tracking of hurricanes or animals #CITE# . $SEP$ With the increasing use of GPS-enabled mobile phones , geotagging , which refers to adding GPS information to media such as micro-blogging messages or photos , has seen a surge in popularity recently . This enables us to not only browse information based on locations , but also discover patterns in the location-based behaviors of users . Many techniques have been developed to find the patterns of people 's movements using GPS data , but latent topics in text messages posted with local contexts have not been utilized effectively . In this paper , we present a latent topic-based clustering algorithm to discover patterns in the trajectories of geo-tagged text messages . We propose a novel probabilistic model to capture the semantic regions where people post messages with a coherent topic as well as the patterns of movement between the semantic regions . Based on the model , we develop an efficient inference algorithm to calculate model parameters . By exploiting the estimated model , we next devise a clustering algorithm to find the significant movement patterns that appear frequently in data . Our experiments on real-life data sets show that the proposed algorithm finds diverse and interesting trajectory patterns $SEP$ The increasing pervasiveness of location-acquisition technologies is leading to the collection of large spatio-temporal datasets and to the opportunity of discovering usable knowledge about movement behaviour , which fosters novel applications and services . In this paper , we move towards this direction and develop an extension of the sequential pattern mining paradigm that analyzes the trajectories of moving objects . We introduce trajectory patterns as concise descriptions of frequent behaviours , in terms of both space and time . In this setting , we provide a general formal statement of the novel mining problem and then study several different instantiations of different complexity . The various approaches are then empirically evaluated over real data and synthetic benchmarks , comparing their strengths and weaknesses . $FULLTEXT$ Spatio-temporal patterns $SEPB$ The increasing availability of GPS-enabled devices is changing the way people interact with the Web , and brings us a large amount of GPS trajectories representing people 's location histories . In this paper , based on multiple users ' GPS trajectories , we aim to mine interesting locations and classical travel sequences in a given geospatial region . Here , interesting locations mean the culturally important places , such as Tiananmen Square in Beijing , and frequented public areas , like shopping malls and restaurants , etc . Such information can help users understand surrounding locations , and would enable travel recommendation . In this work , we first model multiple individuals ' location histories with a tree-based hierarchical graph . Second , based on the TBHG
2	To integrate some aspects of the temporal evolution of motion , some works define pose-metrics that explicitly include dynamic features #CITE# , or use short-time windows around the frame of interest , that are temporally aligned using DTW #CITE# , or uniform scaling #CITE# . $SEP$ Our motion signatures are defined using a deep analysis of motion words and selection of motion-motifs . Each signature is represented by a horizontal bar that shows the frequency of motion-motifs using color coding from red through blue to gray . Note that the signatures represent distributions and not time evolution -the horizontal axis is not temporal . Three signatures of sequences are shown for each motion type -as can be seen , motions of similar type produce similar signatures where many motifs align . The rectangles in the sequence of motion to the left of the signatures illustrate motion words associated with the motifs shown by the corresponding arrow above the signature . Many analysis tasks for human motion rely on high-level similarity between sequences of motions , that are not an exact matches in joint angles , timing , or ordering of actions . Even the same movements performed by the same person can vary in duration and speed . Similar motions are characterized by similar sets of actions that appear frequently . In this paper we introduce motion motifs and motion signatures that are a succinct but descriptive representation of motion sequences . We first break the $SEP$ Fast similarity searching in large time-sequence databases has typically used Euclidean distance a s a dissimilarity metric . However , for several applications , including matching of voice , audio and medical signalseg , electrocardiograms , one is required t o p ermit local accelerations and decelerations in the rate of sequences , leading to a popular , eld-tested dissimilarity metric called the time warping '' distance .From the indexing viewpoint this metric presents two major challenges : a it does not lead to any natural indexable features '' , and b comparing two sequences requires time quadratic in the sequence length . To address each problem , we propose to use : a a modi cation of the so-called F astMap '' , to map sequences into $SEPB$ Data-driven animation has become the industry standard for computer games and many animated movies and special effects . In particular , motion capture data recorded from live actors , is the most promising approach offered thus far for animating realistic human characters . However , the manipulation of such data for general use and re-use is not yet a solved problem . Many of the existing techniques dealing with editing motion rely on indexing for annotation , segmentation , and re-ordering of the data . Euclidean distance is inappropriate for solving these indexing problems because of the inherent variability found in human motion . The limitations of Euclidean distance stems from the fact that it is very sensitive to distortions in the time axis . A partial solution
2	One of these , first introduced by Simonyan and Zisserman #CITE# , utilizes the pretrained weights derived from networks of less depth to set the weights of very deep networks . $SEP$ Abstract-Increasing depth of convolutional neural networks is a highly promising method of increasing the accuracy of the . Increased CNN depth will also result in increased layer count , leading to a slow backpropagation convergence prone to overfitting . We trained our model to classify very largescale scene datasets MIT Places 205 , and MIT Places 365-Standard . The outcome result from the two datasets proved our proposed model effectively handled the slow convergence , overfitting , and degradation . CNNs that include deep supervision add supplementary branches to the deep convolutional neural network in specified layers by calculating vanishing , effectively addressing delayed convergence and overfitting . Nevertheless , does n't resolve degradation ; hence , we add residual learning to the in certain layers after studying the best place in which to add it . With this approach we overcome degradation in the very deep network . We have built two models , and . Moreover , we tested our models on two large-scale datasets , and we compared our results with other recently introduced cutting-edge networks in the domain of top-1 and top-5 classification accuracy . As a result , both of models have shown good improvement $SEP$ In this work we investigate the effect of the convolutional network depth on its accuracy in the large-scale image recognition setting . Our main contribution is a thorough evaluation of networks of increasing depth , which shows that a significant improvement on the prior-art configurations can be achieved by pushing the depth to 16-19 weight layers . These findings were the basis of our ImageNet Challenge 2014 submission , where our team secured the first and the second places in the localisation and classification tracks respectively . We also show that our representations generalise well to other datasets , where they achieve the stateof-the-art results . Importantly , we have made our two best-performing ConvNet models publicly available to facilitate further research on the use of deep visual
1	Supervised learning is adapted to intrusion detection and has been successfully applied to various detection problems: Android applications #CITE# , PDF files #CITE# , botnets #CITE# , Windows audit logs #CITE# , portable executable files #CITE# . $SEP$ Acquiring a representative labelled dataset is a hurdle that has to be overcome to learn a supervised detection model . Labelling a dataset is particularly expensive in computer security as expert knowledge is required to perform the annotations . In this paper , we introduce ILAB , a novel interactive labelling strategy that helps experts label large datasets for intrusion detection with a reduced workload . First , we compare ILAB with two state-of-the-art labelling strategies on public labelled datasets and demonstrate it is both an effective and a scalable solution . Second , we show ILAB is workable with a real-world annotation project carried out on a large unlabelled NetFlow dataset originating from a production environment . We provide an open source implementation to allow security experts to label their own datasets and researchers to compare labelling strategies . $SEP$ Owed to their versatile functionality and widespread adoption , PDF documents have become a popular avenue for user exploitation ranging from large-scale phishing attacks to targeted attacks . In this paper , we present a framework for robust detection of malicious documents through machine learning . Our approach is based on features extracted from document metadata and structure . Using real-world datasets , we demonstrate the the adequacy of these document properties for malware detection and the durability of these features across new malware variants . Our analysis shows that the Random Forests classification method , an ensemble classifier that randomly selects features for each individual classification tree , yields the best detection rates , even on previously unseen malware .Indeed , using multiple datasets containing an aggregate $SEPB$ As antivirus and network intrusion detection systems have increasingly proven insufficient to detect advanced threats , large security operations centers have moved to deploy endpoint-based sensors that provide deeper visibility into lowlevel events across their enterprises . Unfortunately , for many organizations in government and industry , the installation , maintenance , and resource requirements of these newer solutions pose barriers to adoption and are perceived as risks to organizations ' missions .To mitigate this problem we investigated the utility of agentless detection of malicious endpoint behavior , using only the standard built-in Windows audit logging facility as our signal . We found that Windows audit logs , while emitting manageable sized data streams on the endpoints , provide enough information to allow robust detection of malicious behavior $SEPB$ Recent work demonstrated hardware-based online malware detection using only low-level features . This detector is envisioned as a first line of defense that prioritizes the application of more expensive and more accurate software detectors . Critical to such a framework is the detection performance of the hardware detector . In this paper , we explore the use of both specialized detectors and ensemble learning techniques to improve performance of the hardware detector . The proposed detectors reduce the false positive rate by more than half compared to a single detector , while increasing the detection rate . We also contribute approximate metrics to quantify the detection overhead , and show that the proposed detectors achieve more than 11x reduction in overhead compared to a software only detector ,